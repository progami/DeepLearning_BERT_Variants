{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.978877489438744,
  "eval_steps": 500,
  "global_step": 33000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007543753771876886,
      "grad_norm": 0.22198736667633057,
      "learning_rate": 2.995473747736874e-05,
      "loss": 1.5654,
      "step": 50
    },
    {
      "epoch": 0.015087507543753771,
      "grad_norm": 1.4745219945907593,
      "learning_rate": 2.9909474954737477e-05,
      "loss": 0.3082,
      "step": 100
    },
    {
      "epoch": 0.022631261315630657,
      "grad_norm": 0.16226442158222198,
      "learning_rate": 2.986421243210622e-05,
      "loss": 0.2494,
      "step": 150
    },
    {
      "epoch": 0.030175015087507542,
      "grad_norm": 2.6717116832733154,
      "learning_rate": 2.9818949909474957e-05,
      "loss": 0.4174,
      "step": 200
    },
    {
      "epoch": 0.03771876885938443,
      "grad_norm": 0.13632617890834808,
      "learning_rate": 2.9773687386843695e-05,
      "loss": 0.3086,
      "step": 250
    },
    {
      "epoch": 0.045262522631261314,
      "grad_norm": 2.029993772506714,
      "learning_rate": 2.9728424864212433e-05,
      "loss": 0.4172,
      "step": 300
    },
    {
      "epoch": 0.0528062764031382,
      "grad_norm": 0.5465909838676453,
      "learning_rate": 2.968316234158117e-05,
      "loss": 0.3094,
      "step": 350
    },
    {
      "epoch": 0.060350030175015085,
      "grad_norm": 0.34178870916366577,
      "learning_rate": 2.9637899818949912e-05,
      "loss": 0.2692,
      "step": 400
    },
    {
      "epoch": 0.06789378394689197,
      "grad_norm": 0.29782193899154663,
      "learning_rate": 2.959263729631865e-05,
      "loss": 0.2512,
      "step": 450
    },
    {
      "epoch": 0.07543753771876886,
      "grad_norm": 0.383680522441864,
      "learning_rate": 2.954737477368739e-05,
      "loss": 0.2904,
      "step": 500
    },
    {
      "epoch": 0.08298129149064574,
      "grad_norm": 0.27744853496551514,
      "learning_rate": 2.9502112251056127e-05,
      "loss": 0.223,
      "step": 550
    },
    {
      "epoch": 0.09052504526252263,
      "grad_norm": 2.3194401264190674,
      "learning_rate": 2.9456849728424865e-05,
      "loss": 0.3277,
      "step": 600
    },
    {
      "epoch": 0.09806879903439952,
      "grad_norm": 0.39633312821388245,
      "learning_rate": 2.9411587205793606e-05,
      "loss": 0.2213,
      "step": 650
    },
    {
      "epoch": 0.1056125528062764,
      "grad_norm": 0.3060483932495117,
      "learning_rate": 2.9366324683162344e-05,
      "loss": 0.2367,
      "step": 700
    },
    {
      "epoch": 0.11315630657815329,
      "grad_norm": 0.18506476283073425,
      "learning_rate": 2.9321062160531082e-05,
      "loss": 0.2256,
      "step": 750
    },
    {
      "epoch": 0.12070006035003017,
      "grad_norm": 0.28940707445144653,
      "learning_rate": 2.927579963789982e-05,
      "loss": 0.2062,
      "step": 800
    },
    {
      "epoch": 0.12824381412190705,
      "grad_norm": 0.16693086922168732,
      "learning_rate": 2.923053711526856e-05,
      "loss": 0.2761,
      "step": 850
    },
    {
      "epoch": 0.13578756789378393,
      "grad_norm": 0.52367103099823,
      "learning_rate": 2.9185274592637297e-05,
      "loss": 0.4435,
      "step": 900
    },
    {
      "epoch": 0.14333132166566084,
      "grad_norm": 0.14869926869869232,
      "learning_rate": 2.9140012070006038e-05,
      "loss": 0.3542,
      "step": 950
    },
    {
      "epoch": 0.15087507543753773,
      "grad_norm": 2.3119349479675293,
      "learning_rate": 2.9094749547374776e-05,
      "loss": 0.2634,
      "step": 1000
    },
    {
      "epoch": 0.1584188292094146,
      "grad_norm": 0.22711731493473053,
      "learning_rate": 2.9049487024743514e-05,
      "loss": 0.2645,
      "step": 1050
    },
    {
      "epoch": 0.1659625829812915,
      "grad_norm": 0.44719111919403076,
      "learning_rate": 2.9004224502112252e-05,
      "loss": 0.2189,
      "step": 1100
    },
    {
      "epoch": 0.17350633675316837,
      "grad_norm": 0.24218927323818207,
      "learning_rate": 2.895896197948099e-05,
      "loss": 0.2048,
      "step": 1150
    },
    {
      "epoch": 0.18105009052504525,
      "grad_norm": 3.7878260612487793,
      "learning_rate": 2.8913699456849732e-05,
      "loss": 0.3209,
      "step": 1200
    },
    {
      "epoch": 0.18859384429692214,
      "grad_norm": 0.9236574769020081,
      "learning_rate": 2.886843693421847e-05,
      "loss": 0.2752,
      "step": 1250
    },
    {
      "epoch": 0.19613759806879905,
      "grad_norm": 0.21026600897312164,
      "learning_rate": 2.8823174411587205e-05,
      "loss": 0.2581,
      "step": 1300
    },
    {
      "epoch": 0.20368135184067593,
      "grad_norm": 6.250354766845703,
      "learning_rate": 2.8777911888955943e-05,
      "loss": 0.3186,
      "step": 1350
    },
    {
      "epoch": 0.2112251056125528,
      "grad_norm": 7.192033290863037,
      "learning_rate": 2.873264936632468e-05,
      "loss": 0.3082,
      "step": 1400
    },
    {
      "epoch": 0.2187688593844297,
      "grad_norm": 0.24421647191047668,
      "learning_rate": 2.8687386843693422e-05,
      "loss": 0.26,
      "step": 1450
    },
    {
      "epoch": 0.22631261315630657,
      "grad_norm": 0.16422925889492035,
      "learning_rate": 2.864212432106216e-05,
      "loss": 0.2768,
      "step": 1500
    },
    {
      "epoch": 0.23385636692818346,
      "grad_norm": 0.5325750112533569,
      "learning_rate": 2.85968617984309e-05,
      "loss": 0.2456,
      "step": 1550
    },
    {
      "epoch": 0.24140012070006034,
      "grad_norm": 7.648998260498047,
      "learning_rate": 2.8551599275799637e-05,
      "loss": 0.2013,
      "step": 1600
    },
    {
      "epoch": 0.24894387447193725,
      "grad_norm": 0.418351411819458,
      "learning_rate": 2.8506336753168375e-05,
      "loss": 0.223,
      "step": 1650
    },
    {
      "epoch": 0.2564876282438141,
      "grad_norm": 0.0676615759730339,
      "learning_rate": 2.8461074230537116e-05,
      "loss": 0.2646,
      "step": 1700
    },
    {
      "epoch": 0.264031382015691,
      "grad_norm": 0.35124707221984863,
      "learning_rate": 2.8415811707905854e-05,
      "loss": 0.2798,
      "step": 1750
    },
    {
      "epoch": 0.27157513578756787,
      "grad_norm": 6.548856735229492,
      "learning_rate": 2.8370549185274593e-05,
      "loss": 0.2698,
      "step": 1800
    },
    {
      "epoch": 0.2791188895594448,
      "grad_norm": 1.586928367614746,
      "learning_rate": 2.832528666264333e-05,
      "loss": 0.2977,
      "step": 1850
    },
    {
      "epoch": 0.2866626433313217,
      "grad_norm": 0.5875115990638733,
      "learning_rate": 2.828002414001207e-05,
      "loss": 0.1842,
      "step": 1900
    },
    {
      "epoch": 0.29420639710319857,
      "grad_norm": 8.059385299682617,
      "learning_rate": 2.823476161738081e-05,
      "loss": 0.1633,
      "step": 1950
    },
    {
      "epoch": 0.30175015087507545,
      "grad_norm": 0.5252354145050049,
      "learning_rate": 2.8189499094749548e-05,
      "loss": 0.1767,
      "step": 2000
    },
    {
      "epoch": 0.30929390464695233,
      "grad_norm": 0.0750712975859642,
      "learning_rate": 2.8144236572118286e-05,
      "loss": 0.1868,
      "step": 2050
    },
    {
      "epoch": 0.3168376584188292,
      "grad_norm": 0.07830820977687836,
      "learning_rate": 2.8098974049487024e-05,
      "loss": 0.1586,
      "step": 2100
    },
    {
      "epoch": 0.3243814121907061,
      "grad_norm": 6.789068222045898,
      "learning_rate": 2.8053711526855763e-05,
      "loss": 0.2496,
      "step": 2150
    },
    {
      "epoch": 0.331925165962583,
      "grad_norm": 4.900165557861328,
      "learning_rate": 2.80084490042245e-05,
      "loss": 0.2126,
      "step": 2200
    },
    {
      "epoch": 0.33946891973445986,
      "grad_norm": 0.0393710732460022,
      "learning_rate": 2.7963186481593242e-05,
      "loss": 0.2137,
      "step": 2250
    },
    {
      "epoch": 0.34701267350633674,
      "grad_norm": 0.4258614480495453,
      "learning_rate": 2.791792395896198e-05,
      "loss": 0.1537,
      "step": 2300
    },
    {
      "epoch": 0.3545564272782136,
      "grad_norm": 0.08733434975147247,
      "learning_rate": 2.787266143633072e-05,
      "loss": 0.2168,
      "step": 2350
    },
    {
      "epoch": 0.3621001810500905,
      "grad_norm": 8.772778511047363,
      "learning_rate": 2.7827398913699456e-05,
      "loss": 0.1863,
      "step": 2400
    },
    {
      "epoch": 0.3696439348219674,
      "grad_norm": 0.7558802962303162,
      "learning_rate": 2.7782136391068195e-05,
      "loss": 0.181,
      "step": 2450
    },
    {
      "epoch": 0.3771876885938443,
      "grad_norm": 9.61387825012207,
      "learning_rate": 2.7736873868436936e-05,
      "loss": 0.1464,
      "step": 2500
    },
    {
      "epoch": 0.3847314423657212,
      "grad_norm": 1.8504853248596191,
      "learning_rate": 2.7691611345805674e-05,
      "loss": 0.1922,
      "step": 2550
    },
    {
      "epoch": 0.3922751961375981,
      "grad_norm": 3.7255921363830566,
      "learning_rate": 2.7646348823174412e-05,
      "loss": 0.1747,
      "step": 2600
    },
    {
      "epoch": 0.399818949909475,
      "grad_norm": 3.1758580207824707,
      "learning_rate": 2.760108630054315e-05,
      "loss": 0.1529,
      "step": 2650
    },
    {
      "epoch": 0.40736270368135186,
      "grad_norm": 0.15615613758563995,
      "learning_rate": 2.755582377791189e-05,
      "loss": 0.2316,
      "step": 2700
    },
    {
      "epoch": 0.41490645745322874,
      "grad_norm": 0.1904214471578598,
      "learning_rate": 2.751056125528063e-05,
      "loss": 0.1476,
      "step": 2750
    },
    {
      "epoch": 0.4224502112251056,
      "grad_norm": 3.371203660964966,
      "learning_rate": 2.7465298732649368e-05,
      "loss": 0.1592,
      "step": 2800
    },
    {
      "epoch": 0.4299939649969825,
      "grad_norm": 2.21256160736084,
      "learning_rate": 2.7420036210018106e-05,
      "loss": 0.2097,
      "step": 2850
    },
    {
      "epoch": 0.4375377187688594,
      "grad_norm": 0.26308995485305786,
      "learning_rate": 2.7374773687386844e-05,
      "loss": 0.2197,
      "step": 2900
    },
    {
      "epoch": 0.44508147254073627,
      "grad_norm": 0.6285094022750854,
      "learning_rate": 2.7329511164755582e-05,
      "loss": 0.1462,
      "step": 2950
    },
    {
      "epoch": 0.45262522631261315,
      "grad_norm": 0.023251527920365334,
      "learning_rate": 2.7284248642124324e-05,
      "loss": 0.1218,
      "step": 3000
    },
    {
      "epoch": 0.46016898008449003,
      "grad_norm": 0.12035732716321945,
      "learning_rate": 2.7238986119493062e-05,
      "loss": 0.1801,
      "step": 3050
    },
    {
      "epoch": 0.4677127338563669,
      "grad_norm": 4.544079303741455,
      "learning_rate": 2.71937235968618e-05,
      "loss": 0.2279,
      "step": 3100
    },
    {
      "epoch": 0.4752564876282438,
      "grad_norm": 0.22570191323757172,
      "learning_rate": 2.7148461074230538e-05,
      "loss": 0.1765,
      "step": 3150
    },
    {
      "epoch": 0.4828002414001207,
      "grad_norm": 0.015005282126367092,
      "learning_rate": 2.7103198551599276e-05,
      "loss": 0.0717,
      "step": 3200
    },
    {
      "epoch": 0.49034399517199756,
      "grad_norm": 0.06395920366048813,
      "learning_rate": 2.7057936028968018e-05,
      "loss": 0.1385,
      "step": 3250
    },
    {
      "epoch": 0.4978877489438745,
      "grad_norm": 3.8300528526306152,
      "learning_rate": 2.7012673506336756e-05,
      "loss": 0.1945,
      "step": 3300
    },
    {
      "epoch": 0.5054315027157513,
      "grad_norm": 2.635483741760254,
      "learning_rate": 2.6967410983705494e-05,
      "loss": 0.1561,
      "step": 3350
    },
    {
      "epoch": 0.5129752564876282,
      "grad_norm": 0.3049306273460388,
      "learning_rate": 2.6922148461074232e-05,
      "loss": 0.1182,
      "step": 3400
    },
    {
      "epoch": 0.5205190102595051,
      "grad_norm": 1.4241214990615845,
      "learning_rate": 2.687688593844297e-05,
      "loss": 0.1535,
      "step": 3450
    },
    {
      "epoch": 0.528062764031382,
      "grad_norm": 3.660552740097046,
      "learning_rate": 2.683162341581171e-05,
      "loss": 0.1478,
      "step": 3500
    },
    {
      "epoch": 0.5356065178032589,
      "grad_norm": 1.1650372743606567,
      "learning_rate": 2.678636089318045e-05,
      "loss": 0.1732,
      "step": 3550
    },
    {
      "epoch": 0.5431502715751357,
      "grad_norm": 0.7767267823219299,
      "learning_rate": 2.6741098370549188e-05,
      "loss": 0.2137,
      "step": 3600
    },
    {
      "epoch": 0.5506940253470127,
      "grad_norm": 0.06807611137628555,
      "learning_rate": 2.6695835847917926e-05,
      "loss": 0.1219,
      "step": 3650
    },
    {
      "epoch": 0.5582377791188896,
      "grad_norm": 0.04866759851574898,
      "learning_rate": 2.6650573325286664e-05,
      "loss": 0.1547,
      "step": 3700
    },
    {
      "epoch": 0.5657815328907665,
      "grad_norm": 7.313088417053223,
      "learning_rate": 2.6605310802655402e-05,
      "loss": 0.1598,
      "step": 3750
    },
    {
      "epoch": 0.5733252866626434,
      "grad_norm": 0.062349893152713776,
      "learning_rate": 2.6560048280024143e-05,
      "loss": 0.2153,
      "step": 3800
    },
    {
      "epoch": 0.5808690404345203,
      "grad_norm": 5.744300842285156,
      "learning_rate": 2.6514785757392878e-05,
      "loss": 0.1801,
      "step": 3850
    },
    {
      "epoch": 0.5884127942063971,
      "grad_norm": 9.668076515197754,
      "learning_rate": 2.6469523234761616e-05,
      "loss": 0.1443,
      "step": 3900
    },
    {
      "epoch": 0.595956547978274,
      "grad_norm": 6.519026756286621,
      "learning_rate": 2.6424260712130354e-05,
      "loss": 0.1509,
      "step": 3950
    },
    {
      "epoch": 0.6035003017501509,
      "grad_norm": 0.023347584530711174,
      "learning_rate": 2.6378998189499092e-05,
      "loss": 0.0838,
      "step": 4000
    },
    {
      "epoch": 0.6110440555220278,
      "grad_norm": 0.03550393506884575,
      "learning_rate": 2.6333735666867834e-05,
      "loss": 0.2522,
      "step": 4050
    },
    {
      "epoch": 0.6185878092939047,
      "grad_norm": 25.85175323486328,
      "learning_rate": 2.6288473144236572e-05,
      "loss": 0.1589,
      "step": 4100
    },
    {
      "epoch": 0.6261315630657815,
      "grad_norm": 0.07257935404777527,
      "learning_rate": 2.624321062160531e-05,
      "loss": 0.1233,
      "step": 4150
    },
    {
      "epoch": 0.6336753168376584,
      "grad_norm": 0.06615618616342545,
      "learning_rate": 2.6197948098974048e-05,
      "loss": 0.1272,
      "step": 4200
    },
    {
      "epoch": 0.6412190706095353,
      "grad_norm": 7.193171501159668,
      "learning_rate": 2.6152685576342786e-05,
      "loss": 0.1502,
      "step": 4250
    },
    {
      "epoch": 0.6487628243814122,
      "grad_norm": 0.15833812952041626,
      "learning_rate": 2.6107423053711528e-05,
      "loss": 0.1828,
      "step": 4300
    },
    {
      "epoch": 0.6563065781532891,
      "grad_norm": 0.03231288865208626,
      "learning_rate": 2.6062160531080266e-05,
      "loss": 0.1243,
      "step": 4350
    },
    {
      "epoch": 0.663850331925166,
      "grad_norm": 7.273394584655762,
      "learning_rate": 2.6016898008449004e-05,
      "loss": 0.1704,
      "step": 4400
    },
    {
      "epoch": 0.6713940856970428,
      "grad_norm": 0.042952217161655426,
      "learning_rate": 2.5971635485817742e-05,
      "loss": 0.1736,
      "step": 4450
    },
    {
      "epoch": 0.6789378394689197,
      "grad_norm": 8.724858283996582,
      "learning_rate": 2.592637296318648e-05,
      "loss": 0.1729,
      "step": 4500
    },
    {
      "epoch": 0.6864815932407966,
      "grad_norm": 0.42453238368034363,
      "learning_rate": 2.588111044055522e-05,
      "loss": 0.1947,
      "step": 4550
    },
    {
      "epoch": 0.6940253470126735,
      "grad_norm": 0.9779781103134155,
      "learning_rate": 2.583584791792396e-05,
      "loss": 0.1671,
      "step": 4600
    },
    {
      "epoch": 0.7015691007845504,
      "grad_norm": 7.108254909515381,
      "learning_rate": 2.5790585395292698e-05,
      "loss": 0.1466,
      "step": 4650
    },
    {
      "epoch": 0.7091128545564273,
      "grad_norm": 1.6094722747802734,
      "learning_rate": 2.5745322872661436e-05,
      "loss": 0.1917,
      "step": 4700
    },
    {
      "epoch": 0.7166566083283041,
      "grad_norm": 1.0180089473724365,
      "learning_rate": 2.5700060350030174e-05,
      "loss": 0.135,
      "step": 4750
    },
    {
      "epoch": 0.724200362100181,
      "grad_norm": 0.10435909777879715,
      "learning_rate": 2.5654797827398916e-05,
      "loss": 0.1412,
      "step": 4800
    },
    {
      "epoch": 0.7317441158720579,
      "grad_norm": 0.026092762127518654,
      "learning_rate": 2.5609535304767654e-05,
      "loss": 0.1423,
      "step": 4850
    },
    {
      "epoch": 0.7392878696439348,
      "grad_norm": 0.09996870160102844,
      "learning_rate": 2.5564272782136392e-05,
      "loss": 0.1618,
      "step": 4900
    },
    {
      "epoch": 0.7468316234158117,
      "grad_norm": 0.015580776147544384,
      "learning_rate": 2.551901025950513e-05,
      "loss": 0.1276,
      "step": 4950
    },
    {
      "epoch": 0.7543753771876885,
      "grad_norm": 0.02713172324001789,
      "learning_rate": 2.5473747736873868e-05,
      "loss": 0.2079,
      "step": 5000
    },
    {
      "epoch": 0.7619191309595654,
      "grad_norm": 0.08311334997415543,
      "learning_rate": 2.542848521424261e-05,
      "loss": 0.181,
      "step": 5050
    },
    {
      "epoch": 0.7694628847314424,
      "grad_norm": 0.03317703679203987,
      "learning_rate": 2.5383222691611347e-05,
      "loss": 0.164,
      "step": 5100
    },
    {
      "epoch": 0.7770066385033193,
      "grad_norm": 4.9494194984436035,
      "learning_rate": 2.5337960168980086e-05,
      "loss": 0.1848,
      "step": 5150
    },
    {
      "epoch": 0.7845503922751962,
      "grad_norm": 12.615166664123535,
      "learning_rate": 2.5292697646348824e-05,
      "loss": 0.1261,
      "step": 5200
    },
    {
      "epoch": 0.7920941460470731,
      "grad_norm": 6.449697494506836,
      "learning_rate": 2.5247435123717562e-05,
      "loss": 0.1257,
      "step": 5250
    },
    {
      "epoch": 0.79963789981895,
      "grad_norm": 0.027552003040909767,
      "learning_rate": 2.52021726010863e-05,
      "loss": 0.1314,
      "step": 5300
    },
    {
      "epoch": 0.8071816535908268,
      "grad_norm": 4.600676536560059,
      "learning_rate": 2.515691007845504e-05,
      "loss": 0.1305,
      "step": 5350
    },
    {
      "epoch": 0.8147254073627037,
      "grad_norm": 3.779459238052368,
      "learning_rate": 2.511164755582378e-05,
      "loss": 0.141,
      "step": 5400
    },
    {
      "epoch": 0.8222691611345806,
      "grad_norm": 13.91197681427002,
      "learning_rate": 2.5066385033192518e-05,
      "loss": 0.1398,
      "step": 5450
    },
    {
      "epoch": 0.8298129149064575,
      "grad_norm": 0.04338529706001282,
      "learning_rate": 2.5021122510561256e-05,
      "loss": 0.1735,
      "step": 5500
    },
    {
      "epoch": 0.8373566686783344,
      "grad_norm": 0.017509762197732925,
      "learning_rate": 2.4975859987929994e-05,
      "loss": 0.19,
      "step": 5550
    },
    {
      "epoch": 0.8449004224502112,
      "grad_norm": 0.10864754021167755,
      "learning_rate": 2.4930597465298735e-05,
      "loss": 0.1561,
      "step": 5600
    },
    {
      "epoch": 0.8524441762220881,
      "grad_norm": 1.1307709217071533,
      "learning_rate": 2.4885334942667473e-05,
      "loss": 0.1507,
      "step": 5650
    },
    {
      "epoch": 0.859987929993965,
      "grad_norm": 12.664376258850098,
      "learning_rate": 2.484007242003621e-05,
      "loss": 0.2213,
      "step": 5700
    },
    {
      "epoch": 0.8675316837658419,
      "grad_norm": 0.10346853733062744,
      "learning_rate": 2.479480989740495e-05,
      "loss": 0.1221,
      "step": 5750
    },
    {
      "epoch": 0.8750754375377188,
      "grad_norm": 0.018111931160092354,
      "learning_rate": 2.4749547374773688e-05,
      "loss": 0.1467,
      "step": 5800
    },
    {
      "epoch": 0.8826191913095957,
      "grad_norm": 14.228630065917969,
      "learning_rate": 2.470428485214243e-05,
      "loss": 0.1785,
      "step": 5850
    },
    {
      "epoch": 0.8901629450814725,
      "grad_norm": 0.7157444357872009,
      "learning_rate": 2.4659022329511167e-05,
      "loss": 0.1328,
      "step": 5900
    },
    {
      "epoch": 0.8977066988533494,
      "grad_norm": 5.969328880310059,
      "learning_rate": 2.4613759806879905e-05,
      "loss": 0.1855,
      "step": 5950
    },
    {
      "epoch": 0.9052504526252263,
      "grad_norm": 8.25949764251709,
      "learning_rate": 2.4568497284248643e-05,
      "loss": 0.1644,
      "step": 6000
    },
    {
      "epoch": 0.9127942063971032,
      "grad_norm": 5.695501327514648,
      "learning_rate": 2.452323476161738e-05,
      "loss": 0.126,
      "step": 6050
    },
    {
      "epoch": 0.9203379601689801,
      "grad_norm": 1.2575862407684326,
      "learning_rate": 2.4477972238986123e-05,
      "loss": 0.212,
      "step": 6100
    },
    {
      "epoch": 0.927881713940857,
      "grad_norm": 0.02246960811316967,
      "learning_rate": 2.443270971635486e-05,
      "loss": 0.1607,
      "step": 6150
    },
    {
      "epoch": 0.9354254677127338,
      "grad_norm": 0.5542894005775452,
      "learning_rate": 2.43874471937236e-05,
      "loss": 0.167,
      "step": 6200
    },
    {
      "epoch": 0.9429692214846107,
      "grad_norm": 0.02966354973614216,
      "learning_rate": 2.4342184671092337e-05,
      "loss": 0.1541,
      "step": 6250
    },
    {
      "epoch": 0.9505129752564876,
      "grad_norm": 3.8111183643341064,
      "learning_rate": 2.4296922148461075e-05,
      "loss": 0.1211,
      "step": 6300
    },
    {
      "epoch": 0.9580567290283645,
      "grad_norm": 19.1656494140625,
      "learning_rate": 2.4251659625829817e-05,
      "loss": 0.1271,
      "step": 6350
    },
    {
      "epoch": 0.9656004828002414,
      "grad_norm": 0.492620587348938,
      "learning_rate": 2.420639710319855e-05,
      "loss": 0.1208,
      "step": 6400
    },
    {
      "epoch": 0.9731442365721182,
      "grad_norm": 11.773756980895996,
      "learning_rate": 2.416113458056729e-05,
      "loss": 0.1489,
      "step": 6450
    },
    {
      "epoch": 0.9806879903439951,
      "grad_norm": 0.05659754201769829,
      "learning_rate": 2.4115872057936028e-05,
      "loss": 0.1483,
      "step": 6500
    },
    {
      "epoch": 0.9882317441158721,
      "grad_norm": 0.02934982255101204,
      "learning_rate": 2.4070609535304766e-05,
      "loss": 0.1214,
      "step": 6550
    },
    {
      "epoch": 0.995775497887749,
      "grad_norm": 5.2800116539001465,
      "learning_rate": 2.4025347012673504e-05,
      "loss": 0.1607,
      "step": 6600
    },
    {
      "epoch": 1.0,
      "eval_runtime": 38.8132,
      "eval_samples_per_second": 695.536,
      "eval_steps_per_second": 43.49,
      "step": 6628
    },
    {
      "epoch": 1.0033192516596259,
      "grad_norm": 2.4960544109344482,
      "learning_rate": 2.3980084490042245e-05,
      "loss": 0.1193,
      "step": 6650
    },
    {
      "epoch": 1.0108630054315026,
      "grad_norm": 20.250484466552734,
      "learning_rate": 2.3934821967410983e-05,
      "loss": 0.1208,
      "step": 6700
    },
    {
      "epoch": 1.0184067592033796,
      "grad_norm": 8.661333084106445,
      "learning_rate": 2.388955944477972e-05,
      "loss": 0.1108,
      "step": 6750
    },
    {
      "epoch": 1.0259505129752564,
      "grad_norm": 16.253429412841797,
      "learning_rate": 2.384429692214846e-05,
      "loss": 0.1465,
      "step": 6800
    },
    {
      "epoch": 1.0334942667471334,
      "grad_norm": 0.07916968315839767,
      "learning_rate": 2.3799034399517198e-05,
      "loss": 0.151,
      "step": 6850
    },
    {
      "epoch": 1.0410380205190102,
      "grad_norm": 0.007931631989777088,
      "learning_rate": 2.375377187688594e-05,
      "loss": 0.1219,
      "step": 6900
    },
    {
      "epoch": 1.0485817742908872,
      "grad_norm": 0.012297822162508965,
      "learning_rate": 2.3708509354254677e-05,
      "loss": 0.1181,
      "step": 6950
    },
    {
      "epoch": 1.056125528062764,
      "grad_norm": 8.017355918884277,
      "learning_rate": 2.3663246831623415e-05,
      "loss": 0.083,
      "step": 7000
    },
    {
      "epoch": 1.063669281834641,
      "grad_norm": 0.008391543291509151,
      "learning_rate": 2.3617984308992154e-05,
      "loss": 0.0611,
      "step": 7050
    },
    {
      "epoch": 1.0712130356065177,
      "grad_norm": 3.3591606616973877,
      "learning_rate": 2.357272178636089e-05,
      "loss": 0.1007,
      "step": 7100
    },
    {
      "epoch": 1.0787567893783947,
      "grad_norm": 1.9385122060775757,
      "learning_rate": 2.3527459263729633e-05,
      "loss": 0.1322,
      "step": 7150
    },
    {
      "epoch": 1.0863005431502715,
      "grad_norm": 0.4189237058162689,
      "learning_rate": 2.348219674109837e-05,
      "loss": 0.1286,
      "step": 7200
    },
    {
      "epoch": 1.0938442969221485,
      "grad_norm": 2.3496580123901367,
      "learning_rate": 2.343693421846711e-05,
      "loss": 0.1084,
      "step": 7250
    },
    {
      "epoch": 1.1013880506940255,
      "grad_norm": 0.021081479266285896,
      "learning_rate": 2.3391671695835847e-05,
      "loss": 0.0967,
      "step": 7300
    },
    {
      "epoch": 1.1089318044659022,
      "grad_norm": 5.542721271514893,
      "learning_rate": 2.3346409173204585e-05,
      "loss": 0.0814,
      "step": 7350
    },
    {
      "epoch": 1.1164755582377792,
      "grad_norm": 0.01937798038125038,
      "learning_rate": 2.3301146650573327e-05,
      "loss": 0.066,
      "step": 7400
    },
    {
      "epoch": 1.124019312009656,
      "grad_norm": 0.11190593987703323,
      "learning_rate": 2.3255884127942065e-05,
      "loss": 0.105,
      "step": 7450
    },
    {
      "epoch": 1.131563065781533,
      "grad_norm": 8.87205696105957,
      "learning_rate": 2.3210621605310803e-05,
      "loss": 0.0609,
      "step": 7500
    },
    {
      "epoch": 1.1391068195534098,
      "grad_norm": 6.191610813140869,
      "learning_rate": 2.316535908267954e-05,
      "loss": 0.1063,
      "step": 7550
    },
    {
      "epoch": 1.1466505733252867,
      "grad_norm": 0.06344769150018692,
      "learning_rate": 2.312009656004828e-05,
      "loss": 0.1217,
      "step": 7600
    },
    {
      "epoch": 1.1541943270971635,
      "grad_norm": 17.585857391357422,
      "learning_rate": 2.307483403741702e-05,
      "loss": 0.1042,
      "step": 7650
    },
    {
      "epoch": 1.1617380808690405,
      "grad_norm": 9.391764640808105,
      "learning_rate": 2.302957151478576e-05,
      "loss": 0.1255,
      "step": 7700
    },
    {
      "epoch": 1.1692818346409173,
      "grad_norm": 0.05928453430533409,
      "learning_rate": 2.2984308992154497e-05,
      "loss": 0.122,
      "step": 7750
    },
    {
      "epoch": 1.1768255884127943,
      "grad_norm": 0.30138957500457764,
      "learning_rate": 2.2939046469523235e-05,
      "loss": 0.089,
      "step": 7800
    },
    {
      "epoch": 1.184369342184671,
      "grad_norm": 1.1880816221237183,
      "learning_rate": 2.2893783946891973e-05,
      "loss": 0.1359,
      "step": 7850
    },
    {
      "epoch": 1.191913095956548,
      "grad_norm": 0.020996036008000374,
      "learning_rate": 2.2848521424260715e-05,
      "loss": 0.111,
      "step": 7900
    },
    {
      "epoch": 1.1994568497284248,
      "grad_norm": 1.5408496856689453,
      "learning_rate": 2.2803258901629453e-05,
      "loss": 0.1251,
      "step": 7950
    },
    {
      "epoch": 1.2070006035003018,
      "grad_norm": 14.653556823730469,
      "learning_rate": 2.275799637899819e-05,
      "loss": 0.1077,
      "step": 8000
    },
    {
      "epoch": 1.2145443572721786,
      "grad_norm": 0.05209934338927269,
      "learning_rate": 2.271273385636693e-05,
      "loss": 0.1565,
      "step": 8050
    },
    {
      "epoch": 1.2220881110440556,
      "grad_norm": 0.736650824546814,
      "learning_rate": 2.2667471333735667e-05,
      "loss": 0.0865,
      "step": 8100
    },
    {
      "epoch": 1.2296318648159323,
      "grad_norm": 0.021445464342832565,
      "learning_rate": 2.2622208811104405e-05,
      "loss": 0.129,
      "step": 8150
    },
    {
      "epoch": 1.2371756185878093,
      "grad_norm": 6.583346843719482,
      "learning_rate": 2.2576946288473147e-05,
      "loss": 0.0978,
      "step": 8200
    },
    {
      "epoch": 1.244719372359686,
      "grad_norm": 0.20010359585285187,
      "learning_rate": 2.2531683765841885e-05,
      "loss": 0.1629,
      "step": 8250
    },
    {
      "epoch": 1.252263126131563,
      "grad_norm": 0.1421794593334198,
      "learning_rate": 2.2486421243210623e-05,
      "loss": 0.0801,
      "step": 8300
    },
    {
      "epoch": 1.2598068799034399,
      "grad_norm": 10.49496078491211,
      "learning_rate": 2.244115872057936e-05,
      "loss": 0.1671,
      "step": 8350
    },
    {
      "epoch": 1.2673506336753169,
      "grad_norm": 2.1519012451171875,
      "learning_rate": 2.23958961979481e-05,
      "loss": 0.1364,
      "step": 8400
    },
    {
      "epoch": 1.2748943874471936,
      "grad_norm": 16.456113815307617,
      "learning_rate": 2.235063367531684e-05,
      "loss": 0.1148,
      "step": 8450
    },
    {
      "epoch": 1.2824381412190706,
      "grad_norm": 0.014447268098592758,
      "learning_rate": 2.230537115268558e-05,
      "loss": 0.1109,
      "step": 8500
    },
    {
      "epoch": 1.2899818949909476,
      "grad_norm": 0.012181206606328487,
      "learning_rate": 2.2260108630054317e-05,
      "loss": 0.1204,
      "step": 8550
    },
    {
      "epoch": 1.2975256487628244,
      "grad_norm": 11.818634033203125,
      "learning_rate": 2.2214846107423055e-05,
      "loss": 0.1236,
      "step": 8600
    },
    {
      "epoch": 1.3050694025347012,
      "grad_norm": 4.675588130950928,
      "learning_rate": 2.2169583584791793e-05,
      "loss": 0.0993,
      "step": 8650
    },
    {
      "epoch": 1.3126131563065782,
      "grad_norm": 14.370654106140137,
      "learning_rate": 2.2124321062160534e-05,
      "loss": 0.1111,
      "step": 8700
    },
    {
      "epoch": 1.3201569100784551,
      "grad_norm": 13.479423522949219,
      "learning_rate": 2.2079058539529272e-05,
      "loss": 0.1027,
      "step": 8750
    },
    {
      "epoch": 1.327700663850332,
      "grad_norm": 2.1527252197265625,
      "learning_rate": 2.203379601689801e-05,
      "loss": 0.0969,
      "step": 8800
    },
    {
      "epoch": 1.3352444176222087,
      "grad_norm": 6.275818347930908,
      "learning_rate": 2.198853349426675e-05,
      "loss": 0.09,
      "step": 8850
    },
    {
      "epoch": 1.3427881713940857,
      "grad_norm": 0.2399773895740509,
      "learning_rate": 2.1943270971635487e-05,
      "loss": 0.1145,
      "step": 8900
    },
    {
      "epoch": 1.3503319251659627,
      "grad_norm": 0.012249243445694447,
      "learning_rate": 2.1898008449004225e-05,
      "loss": 0.1224,
      "step": 8950
    },
    {
      "epoch": 1.3578756789378394,
      "grad_norm": 6.759600639343262,
      "learning_rate": 2.1852745926372963e-05,
      "loss": 0.0978,
      "step": 9000
    },
    {
      "epoch": 1.3654194327097162,
      "grad_norm": 0.24215829372406006,
      "learning_rate": 2.18074834037417e-05,
      "loss": 0.1012,
      "step": 9050
    },
    {
      "epoch": 1.3729631864815932,
      "grad_norm": 0.01247221790254116,
      "learning_rate": 2.176222088111044e-05,
      "loss": 0.0829,
      "step": 9100
    },
    {
      "epoch": 1.3805069402534702,
      "grad_norm": 0.15071694552898407,
      "learning_rate": 2.1716958358479177e-05,
      "loss": 0.1487,
      "step": 9150
    },
    {
      "epoch": 1.388050694025347,
      "grad_norm": 0.12218324095010757,
      "learning_rate": 2.167169583584792e-05,
      "loss": 0.1329,
      "step": 9200
    },
    {
      "epoch": 1.395594447797224,
      "grad_norm": 5.791837215423584,
      "learning_rate": 2.1626433313216657e-05,
      "loss": 0.1132,
      "step": 9250
    },
    {
      "epoch": 1.4031382015691007,
      "grad_norm": 0.05335117131471634,
      "learning_rate": 2.1581170790585395e-05,
      "loss": 0.1158,
      "step": 9300
    },
    {
      "epoch": 1.4106819553409777,
      "grad_norm": 0.04368698596954346,
      "learning_rate": 2.1535908267954133e-05,
      "loss": 0.1138,
      "step": 9350
    },
    {
      "epoch": 1.4182257091128545,
      "grad_norm": 0.039818473160266876,
      "learning_rate": 2.149064574532287e-05,
      "loss": 0.0988,
      "step": 9400
    },
    {
      "epoch": 1.4257694628847315,
      "grad_norm": 0.009527942165732384,
      "learning_rate": 2.144538322269161e-05,
      "loss": 0.1034,
      "step": 9450
    },
    {
      "epoch": 1.4333132166566083,
      "grad_norm": 11.253132820129395,
      "learning_rate": 2.140012070006035e-05,
      "loss": 0.1215,
      "step": 9500
    },
    {
      "epoch": 1.4408569704284853,
      "grad_norm": 0.3204297721385956,
      "learning_rate": 2.135485817742909e-05,
      "loss": 0.1179,
      "step": 9550
    },
    {
      "epoch": 1.448400724200362,
      "grad_norm": 0.009723792783915997,
      "learning_rate": 2.1309595654797827e-05,
      "loss": 0.1227,
      "step": 9600
    },
    {
      "epoch": 1.455944477972239,
      "grad_norm": 0.03206299990415573,
      "learning_rate": 2.1264333132166565e-05,
      "loss": 0.1193,
      "step": 9650
    },
    {
      "epoch": 1.4634882317441158,
      "grad_norm": 0.09139034152030945,
      "learning_rate": 2.1219070609535303e-05,
      "loss": 0.0981,
      "step": 9700
    },
    {
      "epoch": 1.4710319855159928,
      "grad_norm": 0.04913060739636421,
      "learning_rate": 2.1173808086904045e-05,
      "loss": 0.1187,
      "step": 9750
    },
    {
      "epoch": 1.4785757392878696,
      "grad_norm": 18.759029388427734,
      "learning_rate": 2.1128545564272783e-05,
      "loss": 0.1149,
      "step": 9800
    },
    {
      "epoch": 1.4861194930597466,
      "grad_norm": 0.015483072027564049,
      "learning_rate": 2.108328304164152e-05,
      "loss": 0.1471,
      "step": 9850
    },
    {
      "epoch": 1.4936632468316233,
      "grad_norm": 24.16370964050293,
      "learning_rate": 2.103802051901026e-05,
      "loss": 0.0692,
      "step": 9900
    },
    {
      "epoch": 1.5012070006035003,
      "grad_norm": 0.05489274114370346,
      "learning_rate": 2.0992757996378997e-05,
      "loss": 0.0924,
      "step": 9950
    },
    {
      "epoch": 1.5087507543753773,
      "grad_norm": 5.023098468780518,
      "learning_rate": 2.094749547374774e-05,
      "loss": 0.1218,
      "step": 10000
    },
    {
      "epoch": 1.516294508147254,
      "grad_norm": 1.1777609586715698,
      "learning_rate": 2.0902232951116477e-05,
      "loss": 0.1055,
      "step": 10050
    },
    {
      "epoch": 1.5238382619191309,
      "grad_norm": 15.815078735351562,
      "learning_rate": 2.0856970428485215e-05,
      "loss": 0.0855,
      "step": 10100
    },
    {
      "epoch": 1.5313820156910078,
      "grad_norm": 0.01081320270895958,
      "learning_rate": 2.0811707905853953e-05,
      "loss": 0.108,
      "step": 10150
    },
    {
      "epoch": 1.5389257694628848,
      "grad_norm": 4.146021366119385,
      "learning_rate": 2.076644538322269e-05,
      "loss": 0.0985,
      "step": 10200
    },
    {
      "epoch": 1.5464695232347616,
      "grad_norm": 13.140997886657715,
      "learning_rate": 2.0721182860591432e-05,
      "loss": 0.0775,
      "step": 10250
    },
    {
      "epoch": 1.5540132770066384,
      "grad_norm": 0.08416013419628143,
      "learning_rate": 2.067592033796017e-05,
      "loss": 0.0824,
      "step": 10300
    },
    {
      "epoch": 1.5615570307785154,
      "grad_norm": 20.010860443115234,
      "learning_rate": 2.063065781532891e-05,
      "loss": 0.093,
      "step": 10350
    },
    {
      "epoch": 1.5691007845503924,
      "grad_norm": 0.018246660009026527,
      "learning_rate": 2.0585395292697647e-05,
      "loss": 0.099,
      "step": 10400
    },
    {
      "epoch": 1.5766445383222691,
      "grad_norm": 21.16761589050293,
      "learning_rate": 2.0540132770066385e-05,
      "loss": 0.0752,
      "step": 10450
    },
    {
      "epoch": 1.584188292094146,
      "grad_norm": 2.0573036670684814,
      "learning_rate": 2.0494870247435126e-05,
      "loss": 0.1205,
      "step": 10500
    },
    {
      "epoch": 1.591732045866023,
      "grad_norm": 16.714445114135742,
      "learning_rate": 2.0449607724803864e-05,
      "loss": 0.0798,
      "step": 10550
    },
    {
      "epoch": 1.5992757996379,
      "grad_norm": 0.011484694667160511,
      "learning_rate": 2.0404345202172602e-05,
      "loss": 0.1161,
      "step": 10600
    },
    {
      "epoch": 1.6068195534097767,
      "grad_norm": 0.040399301797151566,
      "learning_rate": 2.035908267954134e-05,
      "loss": 0.1112,
      "step": 10650
    },
    {
      "epoch": 1.6143633071816534,
      "grad_norm": 2.445566177368164,
      "learning_rate": 2.031382015691008e-05,
      "loss": 0.09,
      "step": 10700
    },
    {
      "epoch": 1.6219070609535304,
      "grad_norm": 0.2832179367542267,
      "learning_rate": 2.026855763427882e-05,
      "loss": 0.1048,
      "step": 10750
    },
    {
      "epoch": 1.6294508147254074,
      "grad_norm": 4.052447319030762,
      "learning_rate": 2.0223295111647558e-05,
      "loss": 0.0678,
      "step": 10800
    },
    {
      "epoch": 1.6369945684972842,
      "grad_norm": 0.0023371181450784206,
      "learning_rate": 2.0178032589016296e-05,
      "loss": 0.0957,
      "step": 10850
    },
    {
      "epoch": 1.644538322269161,
      "grad_norm": 25.973922729492188,
      "learning_rate": 2.0132770066385034e-05,
      "loss": 0.1741,
      "step": 10900
    },
    {
      "epoch": 1.652082076041038,
      "grad_norm": 0.03517499938607216,
      "learning_rate": 2.0087507543753772e-05,
      "loss": 0.1221,
      "step": 10950
    },
    {
      "epoch": 1.659625829812915,
      "grad_norm": 0.0065060267224907875,
      "learning_rate": 2.004224502112251e-05,
      "loss": 0.0824,
      "step": 11000
    },
    {
      "epoch": 1.667169583584792,
      "grad_norm": 0.007756824139505625,
      "learning_rate": 1.9996982498491252e-05,
      "loss": 0.1275,
      "step": 11050
    },
    {
      "epoch": 1.6747133373566687,
      "grad_norm": 0.9531862735748291,
      "learning_rate": 1.995171997585999e-05,
      "loss": 0.1394,
      "step": 11100
    },
    {
      "epoch": 1.6822570911285455,
      "grad_norm": 0.023913748562335968,
      "learning_rate": 1.9906457453228728e-05,
      "loss": 0.0924,
      "step": 11150
    },
    {
      "epoch": 1.6898008449004225,
      "grad_norm": 0.03475457802414894,
      "learning_rate": 1.9861194930597466e-05,
      "loss": 0.1025,
      "step": 11200
    },
    {
      "epoch": 1.6973445986722995,
      "grad_norm": 0.05918309837579727,
      "learning_rate": 1.9815932407966204e-05,
      "loss": 0.0972,
      "step": 11250
    },
    {
      "epoch": 1.7048883524441762,
      "grad_norm": 3.4392950534820557,
      "learning_rate": 1.9770669885334946e-05,
      "loss": 0.0915,
      "step": 11300
    },
    {
      "epoch": 1.712432106216053,
      "grad_norm": 12.955547332763672,
      "learning_rate": 1.9725407362703684e-05,
      "loss": 0.1625,
      "step": 11350
    },
    {
      "epoch": 1.71997585998793,
      "grad_norm": 10.138205528259277,
      "learning_rate": 1.9680144840072422e-05,
      "loss": 0.0898,
      "step": 11400
    },
    {
      "epoch": 1.727519613759807,
      "grad_norm": 0.050467174500226974,
      "learning_rate": 1.963488231744116e-05,
      "loss": 0.0972,
      "step": 11450
    },
    {
      "epoch": 1.7350633675316838,
      "grad_norm": 3.6248931884765625,
      "learning_rate": 1.9589619794809895e-05,
      "loss": 0.1002,
      "step": 11500
    },
    {
      "epoch": 1.7426071213035605,
      "grad_norm": 0.024079110473394394,
      "learning_rate": 1.9544357272178636e-05,
      "loss": 0.0915,
      "step": 11550
    },
    {
      "epoch": 1.7501508750754375,
      "grad_norm": 13.448497772216797,
      "learning_rate": 1.9499094749547374e-05,
      "loss": 0.0877,
      "step": 11600
    },
    {
      "epoch": 1.7576946288473145,
      "grad_norm": 0.7203137278556824,
      "learning_rate": 1.9453832226916113e-05,
      "loss": 0.1209,
      "step": 11650
    },
    {
      "epoch": 1.7652383826191913,
      "grad_norm": 0.16115699708461761,
      "learning_rate": 1.940856970428485e-05,
      "loss": 0.0697,
      "step": 11700
    },
    {
      "epoch": 1.772782136391068,
      "grad_norm": 19.83539581298828,
      "learning_rate": 1.936330718165359e-05,
      "loss": 0.0939,
      "step": 11750
    },
    {
      "epoch": 1.780325890162945,
      "grad_norm": 11.330073356628418,
      "learning_rate": 1.931804465902233e-05,
      "loss": 0.1017,
      "step": 11800
    },
    {
      "epoch": 1.787869643934822,
      "grad_norm": 0.04015402868390083,
      "learning_rate": 1.9272782136391068e-05,
      "loss": 0.1144,
      "step": 11850
    },
    {
      "epoch": 1.7954133977066988,
      "grad_norm": 1.1533292531967163,
      "learning_rate": 1.9227519613759806e-05,
      "loss": 0.0899,
      "step": 11900
    },
    {
      "epoch": 1.8029571514785756,
      "grad_norm": 0.0404493547976017,
      "learning_rate": 1.9182257091128544e-05,
      "loss": 0.0736,
      "step": 11950
    },
    {
      "epoch": 1.8105009052504526,
      "grad_norm": 7.708094596862793,
      "learning_rate": 1.9136994568497283e-05,
      "loss": 0.1127,
      "step": 12000
    },
    {
      "epoch": 1.8180446590223296,
      "grad_norm": 5.2249836921691895,
      "learning_rate": 1.9091732045866024e-05,
      "loss": 0.1208,
      "step": 12050
    },
    {
      "epoch": 1.8255884127942064,
      "grad_norm": 10.625285148620605,
      "learning_rate": 1.9046469523234762e-05,
      "loss": 0.1222,
      "step": 12100
    },
    {
      "epoch": 1.8331321665660831,
      "grad_norm": 9.041207313537598,
      "learning_rate": 1.90012070006035e-05,
      "loss": 0.1068,
      "step": 12150
    },
    {
      "epoch": 1.8406759203379601,
      "grad_norm": 0.01841459423303604,
      "learning_rate": 1.895594447797224e-05,
      "loss": 0.059,
      "step": 12200
    },
    {
      "epoch": 1.8482196741098371,
      "grad_norm": 0.16030438244342804,
      "learning_rate": 1.8910681955340976e-05,
      "loss": 0.0928,
      "step": 12250
    },
    {
      "epoch": 1.855763427881714,
      "grad_norm": 15.699475288391113,
      "learning_rate": 1.8865419432709718e-05,
      "loss": 0.0883,
      "step": 12300
    },
    {
      "epoch": 1.8633071816535907,
      "grad_norm": 16.419586181640625,
      "learning_rate": 1.8820156910078456e-05,
      "loss": 0.1356,
      "step": 12350
    },
    {
      "epoch": 1.8708509354254677,
      "grad_norm": 0.019140085205435753,
      "learning_rate": 1.8774894387447194e-05,
      "loss": 0.077,
      "step": 12400
    },
    {
      "epoch": 1.8783946891973446,
      "grad_norm": 0.010671702213585377,
      "learning_rate": 1.8729631864815932e-05,
      "loss": 0.1345,
      "step": 12450
    },
    {
      "epoch": 1.8859384429692216,
      "grad_norm": 6.822999477386475,
      "learning_rate": 1.868436934218467e-05,
      "loss": 0.1431,
      "step": 12500
    },
    {
      "epoch": 1.8934821967410984,
      "grad_norm": 0.008588340133428574,
      "learning_rate": 1.863910681955341e-05,
      "loss": 0.0721,
      "step": 12550
    },
    {
      "epoch": 1.9010259505129752,
      "grad_norm": 0.07235344499349594,
      "learning_rate": 1.859384429692215e-05,
      "loss": 0.1163,
      "step": 12600
    },
    {
      "epoch": 1.9085697042848522,
      "grad_norm": 0.0029241559095680714,
      "learning_rate": 1.8548581774290888e-05,
      "loss": 0.0904,
      "step": 12650
    },
    {
      "epoch": 1.9161134580567292,
      "grad_norm": 15.901558876037598,
      "learning_rate": 1.8503319251659626e-05,
      "loss": 0.1062,
      "step": 12700
    },
    {
      "epoch": 1.923657211828606,
      "grad_norm": 0.08822816610336304,
      "learning_rate": 1.8458056729028364e-05,
      "loss": 0.096,
      "step": 12750
    },
    {
      "epoch": 1.9312009656004827,
      "grad_norm": 0.052895355969667435,
      "learning_rate": 1.8412794206397102e-05,
      "loss": 0.1309,
      "step": 12800
    },
    {
      "epoch": 1.9387447193723597,
      "grad_norm": 2.293145179748535,
      "learning_rate": 1.8367531683765844e-05,
      "loss": 0.1026,
      "step": 12850
    },
    {
      "epoch": 1.9462884731442367,
      "grad_norm": 11.957054138183594,
      "learning_rate": 1.8322269161134582e-05,
      "loss": 0.1402,
      "step": 12900
    },
    {
      "epoch": 1.9538322269161135,
      "grad_norm": 16.83477210998535,
      "learning_rate": 1.827700663850332e-05,
      "loss": 0.0646,
      "step": 12950
    },
    {
      "epoch": 1.9613759806879902,
      "grad_norm": 14.194427490234375,
      "learning_rate": 1.8231744115872058e-05,
      "loss": 0.1466,
      "step": 13000
    },
    {
      "epoch": 1.9689197344598672,
      "grad_norm": 0.03358149901032448,
      "learning_rate": 1.8186481593240796e-05,
      "loss": 0.1001,
      "step": 13050
    },
    {
      "epoch": 1.9764634882317442,
      "grad_norm": 7.761601448059082,
      "learning_rate": 1.8141219070609538e-05,
      "loss": 0.1141,
      "step": 13100
    },
    {
      "epoch": 1.984007242003621,
      "grad_norm": 0.9278287291526794,
      "learning_rate": 1.8095956547978276e-05,
      "loss": 0.1057,
      "step": 13150
    },
    {
      "epoch": 1.9915509957754978,
      "grad_norm": 0.006598238833248615,
      "learning_rate": 1.8050694025347014e-05,
      "loss": 0.0511,
      "step": 13200
    },
    {
      "epoch": 1.9990947495473748,
      "grad_norm": 11.235706329345703,
      "learning_rate": 1.8005431502715752e-05,
      "loss": 0.1396,
      "step": 13250
    },
    {
      "epoch": 2.0,
      "eval_runtime": 38.7479,
      "eval_samples_per_second": 696.709,
      "eval_steps_per_second": 43.564,
      "step": 13256
    },
    {
      "epoch": 2.0066385033192518,
      "grad_norm": 7.912904739379883,
      "learning_rate": 1.796016898008449e-05,
      "loss": 0.0733,
      "step": 13300
    },
    {
      "epoch": 2.0141822570911287,
      "grad_norm": 2.376167058944702,
      "learning_rate": 1.791490645745323e-05,
      "loss": 0.085,
      "step": 13350
    },
    {
      "epoch": 2.0217260108630053,
      "grad_norm": 0.028345273807644844,
      "learning_rate": 1.786964393482197e-05,
      "loss": 0.0754,
      "step": 13400
    },
    {
      "epoch": 2.0292697646348823,
      "grad_norm": 0.21696485579013824,
      "learning_rate": 1.7824381412190708e-05,
      "loss": 0.1076,
      "step": 13450
    },
    {
      "epoch": 2.0368135184067593,
      "grad_norm": 0.009997817687690258,
      "learning_rate": 1.7779118889559446e-05,
      "loss": 0.0736,
      "step": 13500
    },
    {
      "epoch": 2.0443572721786363,
      "grad_norm": 8.59878158569336,
      "learning_rate": 1.7733856366928184e-05,
      "loss": 0.0294,
      "step": 13550
    },
    {
      "epoch": 2.051901025950513,
      "grad_norm": 0.035158753395080566,
      "learning_rate": 1.7688593844296925e-05,
      "loss": 0.037,
      "step": 13600
    },
    {
      "epoch": 2.05944477972239,
      "grad_norm": 0.003206227906048298,
      "learning_rate": 1.7643331321665663e-05,
      "loss": 0.0436,
      "step": 13650
    },
    {
      "epoch": 2.066988533494267,
      "grad_norm": 9.365239143371582,
      "learning_rate": 1.75980687990344e-05,
      "loss": 0.0312,
      "step": 13700
    },
    {
      "epoch": 2.074532287266144,
      "grad_norm": 22.958059310913086,
      "learning_rate": 1.755280627640314e-05,
      "loss": 0.078,
      "step": 13750
    },
    {
      "epoch": 2.0820760410380204,
      "grad_norm": 22.101978302001953,
      "learning_rate": 1.7507543753771878e-05,
      "loss": 0.0872,
      "step": 13800
    },
    {
      "epoch": 2.0896197948098973,
      "grad_norm": 0.025424301624298096,
      "learning_rate": 1.7462281231140616e-05,
      "loss": 0.0502,
      "step": 13850
    },
    {
      "epoch": 2.0971635485817743,
      "grad_norm": 0.21852119266986847,
      "learning_rate": 1.7417018708509357e-05,
      "loss": 0.0972,
      "step": 13900
    },
    {
      "epoch": 2.1047073023536513,
      "grad_norm": 0.1395748257637024,
      "learning_rate": 1.7371756185878095e-05,
      "loss": 0.0904,
      "step": 13950
    },
    {
      "epoch": 2.112251056125528,
      "grad_norm": 15.024514198303223,
      "learning_rate": 1.7326493663246833e-05,
      "loss": 0.0549,
      "step": 14000
    },
    {
      "epoch": 2.119794809897405,
      "grad_norm": 0.7588229775428772,
      "learning_rate": 1.7281231140615568e-05,
      "loss": 0.0585,
      "step": 14050
    },
    {
      "epoch": 2.127338563669282,
      "grad_norm": 0.012418189086019993,
      "learning_rate": 1.7235968617984306e-05,
      "loss": 0.0386,
      "step": 14100
    },
    {
      "epoch": 2.134882317441159,
      "grad_norm": 6.582065105438232,
      "learning_rate": 1.7190706095353048e-05,
      "loss": 0.0458,
      "step": 14150
    },
    {
      "epoch": 2.1424260712130354,
      "grad_norm": 14.273104667663574,
      "learning_rate": 1.7145443572721786e-05,
      "loss": 0.1118,
      "step": 14200
    },
    {
      "epoch": 2.1499698249849124,
      "grad_norm": 0.049938034266233444,
      "learning_rate": 1.7100181050090524e-05,
      "loss": 0.0751,
      "step": 14250
    },
    {
      "epoch": 2.1575135787567894,
      "grad_norm": 0.0358118861913681,
      "learning_rate": 1.7054918527459262e-05,
      "loss": 0.079,
      "step": 14300
    },
    {
      "epoch": 2.1650573325286664,
      "grad_norm": 29.125019073486328,
      "learning_rate": 1.7009656004828e-05,
      "loss": 0.0967,
      "step": 14350
    },
    {
      "epoch": 2.172601086300543,
      "grad_norm": 11.631349563598633,
      "learning_rate": 1.696439348219674e-05,
      "loss": 0.0393,
      "step": 14400
    },
    {
      "epoch": 2.18014484007242,
      "grad_norm": 23.700178146362305,
      "learning_rate": 1.691913095956548e-05,
      "loss": 0.0816,
      "step": 14450
    },
    {
      "epoch": 2.187688593844297,
      "grad_norm": 2.740227222442627,
      "learning_rate": 1.6873868436934218e-05,
      "loss": 0.0393,
      "step": 14500
    },
    {
      "epoch": 2.195232347616174,
      "grad_norm": 0.0019071593414992094,
      "learning_rate": 1.6828605914302956e-05,
      "loss": 0.0583,
      "step": 14550
    },
    {
      "epoch": 2.202776101388051,
      "grad_norm": 0.0038667782209813595,
      "learning_rate": 1.6783343391671694e-05,
      "loss": 0.0587,
      "step": 14600
    },
    {
      "epoch": 2.2103198551599275,
      "grad_norm": 0.0082136495038867,
      "learning_rate": 1.6738080869040435e-05,
      "loss": 0.0439,
      "step": 14650
    },
    {
      "epoch": 2.2178636089318045,
      "grad_norm": 0.0006938721635378897,
      "learning_rate": 1.6692818346409174e-05,
      "loss": 0.0541,
      "step": 14700
    },
    {
      "epoch": 2.2254073627036814,
      "grad_norm": 0.0426463820040226,
      "learning_rate": 1.664755582377791e-05,
      "loss": 0.0694,
      "step": 14750
    },
    {
      "epoch": 2.2329511164755584,
      "grad_norm": 0.06953640282154083,
      "learning_rate": 1.660229330114665e-05,
      "loss": 0.1058,
      "step": 14800
    },
    {
      "epoch": 2.240494870247435,
      "grad_norm": 0.029561586678028107,
      "learning_rate": 1.6557030778515388e-05,
      "loss": 0.0493,
      "step": 14850
    },
    {
      "epoch": 2.248038624019312,
      "grad_norm": 3.0884034633636475,
      "learning_rate": 1.651176825588413e-05,
      "loss": 0.0605,
      "step": 14900
    },
    {
      "epoch": 2.255582377791189,
      "grad_norm": 0.019994469359517097,
      "learning_rate": 1.6466505733252867e-05,
      "loss": 0.1013,
      "step": 14950
    },
    {
      "epoch": 2.263126131563066,
      "grad_norm": 4.076920509338379,
      "learning_rate": 1.6421243210621606e-05,
      "loss": 0.0676,
      "step": 15000
    },
    {
      "epoch": 2.2706698853349425,
      "grad_norm": 1.8910399675369263,
      "learning_rate": 1.6375980687990344e-05,
      "loss": 0.1241,
      "step": 15050
    },
    {
      "epoch": 2.2782136391068195,
      "grad_norm": 0.02571573667228222,
      "learning_rate": 1.6330718165359082e-05,
      "loss": 0.0718,
      "step": 15100
    },
    {
      "epoch": 2.2857573928786965,
      "grad_norm": 1.656019687652588,
      "learning_rate": 1.6285455642727823e-05,
      "loss": 0.0803,
      "step": 15150
    },
    {
      "epoch": 2.2933011466505735,
      "grad_norm": 0.010541065596044064,
      "learning_rate": 1.624019312009656e-05,
      "loss": 0.0851,
      "step": 15200
    },
    {
      "epoch": 2.30084490042245,
      "grad_norm": 17.122312545776367,
      "learning_rate": 1.61949305974653e-05,
      "loss": 0.0841,
      "step": 15250
    },
    {
      "epoch": 2.308388654194327,
      "grad_norm": 0.04574008658528328,
      "learning_rate": 1.6149668074834038e-05,
      "loss": 0.08,
      "step": 15300
    },
    {
      "epoch": 2.315932407966204,
      "grad_norm": 0.04090192914009094,
      "learning_rate": 1.6104405552202776e-05,
      "loss": 0.0472,
      "step": 15350
    },
    {
      "epoch": 2.323476161738081,
      "grad_norm": 8.333483695983887,
      "learning_rate": 1.6059143029571514e-05,
      "loss": 0.0908,
      "step": 15400
    },
    {
      "epoch": 2.3310199155099576,
      "grad_norm": 0.01773766055703163,
      "learning_rate": 1.6013880506940255e-05,
      "loss": 0.0993,
      "step": 15450
    },
    {
      "epoch": 2.3385636692818346,
      "grad_norm": 2.7569916248321533,
      "learning_rate": 1.5968617984308993e-05,
      "loss": 0.0698,
      "step": 15500
    },
    {
      "epoch": 2.3461074230537116,
      "grad_norm": 0.02577473782002926,
      "learning_rate": 1.592335546167773e-05,
      "loss": 0.0643,
      "step": 15550
    },
    {
      "epoch": 2.3536511768255886,
      "grad_norm": 0.02590714767575264,
      "learning_rate": 1.587809293904647e-05,
      "loss": 0.0849,
      "step": 15600
    },
    {
      "epoch": 2.361194930597465,
      "grad_norm": 0.02182452194392681,
      "learning_rate": 1.5832830416415208e-05,
      "loss": 0.0971,
      "step": 15650
    },
    {
      "epoch": 2.368738684369342,
      "grad_norm": 0.0049363430589437485,
      "learning_rate": 1.578756789378395e-05,
      "loss": 0.0744,
      "step": 15700
    },
    {
      "epoch": 2.376282438141219,
      "grad_norm": 0.02278914861381054,
      "learning_rate": 1.5742305371152687e-05,
      "loss": 0.0349,
      "step": 15750
    },
    {
      "epoch": 2.383826191913096,
      "grad_norm": 0.0036369869485497475,
      "learning_rate": 1.5697042848521425e-05,
      "loss": 0.0738,
      "step": 15800
    },
    {
      "epoch": 2.391369945684973,
      "grad_norm": 0.0227248203009367,
      "learning_rate": 1.5651780325890163e-05,
      "loss": 0.0668,
      "step": 15850
    },
    {
      "epoch": 2.3989136994568496,
      "grad_norm": 0.008839976042509079,
      "learning_rate": 1.56065178032589e-05,
      "loss": 0.0674,
      "step": 15900
    },
    {
      "epoch": 2.4064574532287266,
      "grad_norm": 12.688201904296875,
      "learning_rate": 1.5561255280627643e-05,
      "loss": 0.0897,
      "step": 15950
    },
    {
      "epoch": 2.4140012070006036,
      "grad_norm": 0.01868768408894539,
      "learning_rate": 1.551599275799638e-05,
      "loss": 0.069,
      "step": 16000
    },
    {
      "epoch": 2.42154496077248,
      "grad_norm": 3.514517307281494,
      "learning_rate": 1.547073023536512e-05,
      "loss": 0.0655,
      "step": 16050
    },
    {
      "epoch": 2.429088714544357,
      "grad_norm": 2.1001195907592773,
      "learning_rate": 1.5425467712733857e-05,
      "loss": 0.022,
      "step": 16100
    },
    {
      "epoch": 2.436632468316234,
      "grad_norm": 12.776299476623535,
      "learning_rate": 1.5380205190102595e-05,
      "loss": 0.0585,
      "step": 16150
    },
    {
      "epoch": 2.444176222088111,
      "grad_norm": 8.456706047058105,
      "learning_rate": 1.5334942667471337e-05,
      "loss": 0.0431,
      "step": 16200
    },
    {
      "epoch": 2.451719975859988,
      "grad_norm": 0.37333711981773376,
      "learning_rate": 1.5289680144840075e-05,
      "loss": 0.0681,
      "step": 16250
    },
    {
      "epoch": 2.4592637296318647,
      "grad_norm": 12.628178596496582,
      "learning_rate": 1.5244417622208811e-05,
      "loss": 0.0362,
      "step": 16300
    },
    {
      "epoch": 2.4668074834037417,
      "grad_norm": 0.025506863370537758,
      "learning_rate": 1.519915509957755e-05,
      "loss": 0.0893,
      "step": 16350
    },
    {
      "epoch": 2.4743512371756187,
      "grad_norm": 0.0060487608425319195,
      "learning_rate": 1.5153892576946287e-05,
      "loss": 0.0459,
      "step": 16400
    },
    {
      "epoch": 2.4818949909474957,
      "grad_norm": 0.08535907417535782,
      "learning_rate": 1.5108630054315029e-05,
      "loss": 0.073,
      "step": 16450
    },
    {
      "epoch": 2.489438744719372,
      "grad_norm": 0.06151195988059044,
      "learning_rate": 1.5063367531683767e-05,
      "loss": 0.0464,
      "step": 16500
    },
    {
      "epoch": 2.496982498491249,
      "grad_norm": 0.00908130593597889,
      "learning_rate": 1.5018105009052505e-05,
      "loss": 0.0439,
      "step": 16550
    },
    {
      "epoch": 2.504526252263126,
      "grad_norm": 29.664264678955078,
      "learning_rate": 1.4972842486421243e-05,
      "loss": 0.0634,
      "step": 16600
    },
    {
      "epoch": 2.512070006035003,
      "grad_norm": 0.001611256506294012,
      "learning_rate": 1.4927579963789983e-05,
      "loss": 0.0433,
      "step": 16650
    },
    {
      "epoch": 2.5196137598068797,
      "grad_norm": 0.0008426401764154434,
      "learning_rate": 1.4882317441158721e-05,
      "loss": 0.0308,
      "step": 16700
    },
    {
      "epoch": 2.5271575135787567,
      "grad_norm": 10.637429237365723,
      "learning_rate": 1.483705491852746e-05,
      "loss": 0.1051,
      "step": 16750
    },
    {
      "epoch": 2.5347012673506337,
      "grad_norm": 0.02639348804950714,
      "learning_rate": 1.4791792395896199e-05,
      "loss": 0.0409,
      "step": 16800
    },
    {
      "epoch": 2.5422450211225107,
      "grad_norm": 0.04149957373738289,
      "learning_rate": 1.4746529873264937e-05,
      "loss": 0.0819,
      "step": 16850
    },
    {
      "epoch": 2.5497887748943873,
      "grad_norm": 0.09892580658197403,
      "learning_rate": 1.4701267350633677e-05,
      "loss": 0.0696,
      "step": 16900
    },
    {
      "epoch": 2.5573325286662643,
      "grad_norm": 0.04598899185657501,
      "learning_rate": 1.4656004828002415e-05,
      "loss": 0.0699,
      "step": 16950
    },
    {
      "epoch": 2.5648762824381413,
      "grad_norm": 6.006977558135986,
      "learning_rate": 1.4610742305371153e-05,
      "loss": 0.0908,
      "step": 17000
    },
    {
      "epoch": 2.5724200362100182,
      "grad_norm": 0.009040312841534615,
      "learning_rate": 1.4565479782739893e-05,
      "loss": 0.0525,
      "step": 17050
    },
    {
      "epoch": 2.5799637899818952,
      "grad_norm": 3.363356113433838,
      "learning_rate": 1.4520217260108631e-05,
      "loss": 0.0473,
      "step": 17100
    },
    {
      "epoch": 2.587507543753772,
      "grad_norm": 0.04111796244978905,
      "learning_rate": 1.4474954737477369e-05,
      "loss": 0.0412,
      "step": 17150
    },
    {
      "epoch": 2.595051297525649,
      "grad_norm": 0.09009718149900436,
      "learning_rate": 1.4429692214846109e-05,
      "loss": 0.0828,
      "step": 17200
    },
    {
      "epoch": 2.6025950512975258,
      "grad_norm": 0.08177628368139267,
      "learning_rate": 1.4384429692214845e-05,
      "loss": 0.0622,
      "step": 17250
    },
    {
      "epoch": 2.6101388050694023,
      "grad_norm": 0.03880159929394722,
      "learning_rate": 1.4339167169583585e-05,
      "loss": 0.0692,
      "step": 17300
    },
    {
      "epoch": 2.6176825588412793,
      "grad_norm": 1.6727923154830933,
      "learning_rate": 1.4293904646952323e-05,
      "loss": 0.0601,
      "step": 17350
    },
    {
      "epoch": 2.6252263126131563,
      "grad_norm": 14.528267860412598,
      "learning_rate": 1.4248642124321061e-05,
      "loss": 0.1097,
      "step": 17400
    },
    {
      "epoch": 2.6327700663850333,
      "grad_norm": 0.00104412785731256,
      "learning_rate": 1.4203379601689801e-05,
      "loss": 0.0374,
      "step": 17450
    },
    {
      "epoch": 2.6403138201569103,
      "grad_norm": 0.017766784876585007,
      "learning_rate": 1.4158117079058539e-05,
      "loss": 0.0867,
      "step": 17500
    },
    {
      "epoch": 2.647857573928787,
      "grad_norm": 15.712960243225098,
      "learning_rate": 1.4112854556427279e-05,
      "loss": 0.0923,
      "step": 17550
    },
    {
      "epoch": 2.655401327700664,
      "grad_norm": 0.16821064054965973,
      "learning_rate": 1.4067592033796017e-05,
      "loss": 0.0714,
      "step": 17600
    },
    {
      "epoch": 2.662945081472541,
      "grad_norm": 0.1970718652009964,
      "learning_rate": 1.4022329511164755e-05,
      "loss": 0.0438,
      "step": 17650
    },
    {
      "epoch": 2.6704888352444174,
      "grad_norm": 0.7800621390342712,
      "learning_rate": 1.3977066988533495e-05,
      "loss": 0.0632,
      "step": 17700
    },
    {
      "epoch": 2.6780325890162944,
      "grad_norm": 0.0665782019495964,
      "learning_rate": 1.3931804465902233e-05,
      "loss": 0.0777,
      "step": 17750
    },
    {
      "epoch": 2.6855763427881714,
      "grad_norm": 0.1445406675338745,
      "learning_rate": 1.3886541943270973e-05,
      "loss": 0.0611,
      "step": 17800
    },
    {
      "epoch": 2.6931200965600484,
      "grad_norm": 0.129763662815094,
      "learning_rate": 1.3841279420639711e-05,
      "loss": 0.0725,
      "step": 17850
    },
    {
      "epoch": 2.7006638503319254,
      "grad_norm": 0.00277113588526845,
      "learning_rate": 1.3796016898008449e-05,
      "loss": 0.0669,
      "step": 17900
    },
    {
      "epoch": 2.708207604103802,
      "grad_norm": 0.02413128688931465,
      "learning_rate": 1.3750754375377189e-05,
      "loss": 0.0823,
      "step": 17950
    },
    {
      "epoch": 2.715751357875679,
      "grad_norm": 6.3337836265563965,
      "learning_rate": 1.3705491852745927e-05,
      "loss": 0.0168,
      "step": 18000
    },
    {
      "epoch": 2.723295111647556,
      "grad_norm": 3.1690101623535156,
      "learning_rate": 1.3660229330114665e-05,
      "loss": 0.06,
      "step": 18050
    },
    {
      "epoch": 2.7308388654194324,
      "grad_norm": 0.007360644638538361,
      "learning_rate": 1.3614966807483405e-05,
      "loss": 0.0654,
      "step": 18100
    },
    {
      "epoch": 2.7383826191913094,
      "grad_norm": 10.30168342590332,
      "learning_rate": 1.3569704284852143e-05,
      "loss": 0.0813,
      "step": 18150
    },
    {
      "epoch": 2.7459263729631864,
      "grad_norm": 0.005956105887889862,
      "learning_rate": 1.3524441762220883e-05,
      "loss": 0.0222,
      "step": 18200
    },
    {
      "epoch": 2.7534701267350634,
      "grad_norm": 0.013863400556147099,
      "learning_rate": 1.347917923958962e-05,
      "loss": 0.0546,
      "step": 18250
    },
    {
      "epoch": 2.7610138805069404,
      "grad_norm": 0.3544560968875885,
      "learning_rate": 1.3433916716958359e-05,
      "loss": 0.0372,
      "step": 18300
    },
    {
      "epoch": 2.7685576342788174,
      "grad_norm": 5.825692176818848,
      "learning_rate": 1.3388654194327099e-05,
      "loss": 0.0722,
      "step": 18350
    },
    {
      "epoch": 2.776101388050694,
      "grad_norm": 0.0015698878560215235,
      "learning_rate": 1.3343391671695837e-05,
      "loss": 0.0745,
      "step": 18400
    },
    {
      "epoch": 2.783645141822571,
      "grad_norm": 0.03789028152823448,
      "learning_rate": 1.3298129149064576e-05,
      "loss": 0.1145,
      "step": 18450
    },
    {
      "epoch": 2.791188895594448,
      "grad_norm": 24.55752182006836,
      "learning_rate": 1.3252866626433313e-05,
      "loss": 0.0567,
      "step": 18500
    },
    {
      "epoch": 2.7987326493663245,
      "grad_norm": 2.99892258644104,
      "learning_rate": 1.3207604103802051e-05,
      "loss": 0.0693,
      "step": 18550
    },
    {
      "epoch": 2.8062764031382015,
      "grad_norm": 12.907632827758789,
      "learning_rate": 1.316234158117079e-05,
      "loss": 0.084,
      "step": 18600
    },
    {
      "epoch": 2.8138201569100785,
      "grad_norm": 0.09173643589019775,
      "learning_rate": 1.3117079058539529e-05,
      "loss": 0.0672,
      "step": 18650
    },
    {
      "epoch": 2.8213639106819555,
      "grad_norm": 0.0021539446897804737,
      "learning_rate": 1.3071816535908267e-05,
      "loss": 0.0832,
      "step": 18700
    },
    {
      "epoch": 2.8289076644538325,
      "grad_norm": 0.0011931213084608316,
      "learning_rate": 1.3026554013277007e-05,
      "loss": 0.0385,
      "step": 18750
    },
    {
      "epoch": 2.836451418225709,
      "grad_norm": 38.27775955200195,
      "learning_rate": 1.2981291490645745e-05,
      "loss": 0.0711,
      "step": 18800
    },
    {
      "epoch": 2.843995171997586,
      "grad_norm": 0.027392137795686722,
      "learning_rate": 1.2936028968014485e-05,
      "loss": 0.049,
      "step": 18850
    },
    {
      "epoch": 2.851538925769463,
      "grad_norm": 14.259929656982422,
      "learning_rate": 1.2890766445383223e-05,
      "loss": 0.034,
      "step": 18900
    },
    {
      "epoch": 2.8590826795413395,
      "grad_norm": 0.0037863405887037516,
      "learning_rate": 1.284550392275196e-05,
      "loss": 0.0968,
      "step": 18950
    },
    {
      "epoch": 2.8666264333132165,
      "grad_norm": 0.003938834648579359,
      "learning_rate": 1.28002414001207e-05,
      "loss": 0.063,
      "step": 19000
    },
    {
      "epoch": 2.8741701870850935,
      "grad_norm": 0.0367879681289196,
      "learning_rate": 1.2754978877489439e-05,
      "loss": 0.0717,
      "step": 19050
    },
    {
      "epoch": 2.8817139408569705,
      "grad_norm": 7.7062177658081055,
      "learning_rate": 1.2709716354858178e-05,
      "loss": 0.0886,
      "step": 19100
    },
    {
      "epoch": 2.8892576946288475,
      "grad_norm": 17.765623092651367,
      "learning_rate": 1.2664453832226917e-05,
      "loss": 0.0432,
      "step": 19150
    },
    {
      "epoch": 2.896801448400724,
      "grad_norm": 0.021865636110305786,
      "learning_rate": 1.2619191309595655e-05,
      "loss": 0.0574,
      "step": 19200
    },
    {
      "epoch": 2.904345202172601,
      "grad_norm": 0.5667867064476013,
      "learning_rate": 1.2573928786964394e-05,
      "loss": 0.0389,
      "step": 19250
    },
    {
      "epoch": 2.911888955944478,
      "grad_norm": 9.86681842803955,
      "learning_rate": 1.2528666264333133e-05,
      "loss": 0.064,
      "step": 19300
    },
    {
      "epoch": 2.9194327097163546,
      "grad_norm": 6.734639644622803,
      "learning_rate": 1.248340374170187e-05,
      "loss": 0.0768,
      "step": 19350
    },
    {
      "epoch": 2.9269764634882316,
      "grad_norm": 28.917190551757812,
      "learning_rate": 1.243814121907061e-05,
      "loss": 0.1009,
      "step": 19400
    },
    {
      "epoch": 2.9345202172601086,
      "grad_norm": 0.021339448168873787,
      "learning_rate": 1.2392878696439349e-05,
      "loss": 0.0861,
      "step": 19450
    },
    {
      "epoch": 2.9420639710319856,
      "grad_norm": 0.005677042528986931,
      "learning_rate": 1.2347616173808088e-05,
      "loss": 0.0297,
      "step": 19500
    },
    {
      "epoch": 2.9496077248038626,
      "grad_norm": 0.055983833968639374,
      "learning_rate": 1.2302353651176826e-05,
      "loss": 0.0465,
      "step": 19550
    },
    {
      "epoch": 2.957151478575739,
      "grad_norm": 0.015546096488833427,
      "learning_rate": 1.2257091128545565e-05,
      "loss": 0.0394,
      "step": 19600
    },
    {
      "epoch": 2.964695232347616,
      "grad_norm": 11.629114151000977,
      "learning_rate": 1.2211828605914304e-05,
      "loss": 0.0869,
      "step": 19650
    },
    {
      "epoch": 2.972238986119493,
      "grad_norm": 10.701605796813965,
      "learning_rate": 1.2166566083283042e-05,
      "loss": 0.062,
      "step": 19700
    },
    {
      "epoch": 2.97978273989137,
      "grad_norm": 4.167055606842041,
      "learning_rate": 1.212130356065178e-05,
      "loss": 0.0264,
      "step": 19750
    },
    {
      "epoch": 2.9873264936632467,
      "grad_norm": 0.005413624458014965,
      "learning_rate": 1.2076041038020519e-05,
      "loss": 0.0518,
      "step": 19800
    },
    {
      "epoch": 2.9948702474351236,
      "grad_norm": 0.05168607458472252,
      "learning_rate": 1.2030778515389257e-05,
      "loss": 0.0809,
      "step": 19850
    },
    {
      "epoch": 3.0,
      "eval_runtime": 38.7562,
      "eval_samples_per_second": 696.559,
      "eval_steps_per_second": 43.554,
      "step": 19884
    },
    {
      "epoch": 3.0024140012070006,
      "grad_norm": 0.2974294126033783,
      "learning_rate": 1.1985515992757996e-05,
      "loss": 0.0558,
      "step": 19900
    },
    {
      "epoch": 3.0099577549788776,
      "grad_norm": 0.004557016305625439,
      "learning_rate": 1.1940253470126735e-05,
      "loss": 0.0307,
      "step": 19950
    },
    {
      "epoch": 3.017501508750754,
      "grad_norm": 17.817541122436523,
      "learning_rate": 1.1894990947495473e-05,
      "loss": 0.0464,
      "step": 20000
    },
    {
      "epoch": 3.025045262522631,
      "grad_norm": 0.010910921730101109,
      "learning_rate": 1.1849728424864212e-05,
      "loss": 0.0471,
      "step": 20050
    },
    {
      "epoch": 3.032589016294508,
      "grad_norm": 11.570843696594238,
      "learning_rate": 1.180446590223295e-05,
      "loss": 0.0323,
      "step": 20100
    },
    {
      "epoch": 3.040132770066385,
      "grad_norm": 0.02619103342294693,
      "learning_rate": 1.175920337960169e-05,
      "loss": 0.0244,
      "step": 20150
    },
    {
      "epoch": 3.0476765238382617,
      "grad_norm": 0.03356628865003586,
      "learning_rate": 1.1713940856970428e-05,
      "loss": 0.0691,
      "step": 20200
    },
    {
      "epoch": 3.0552202776101387,
      "grad_norm": 16.405773162841797,
      "learning_rate": 1.1668678334339167e-05,
      "loss": 0.0279,
      "step": 20250
    },
    {
      "epoch": 3.0627640313820157,
      "grad_norm": 0.002178460592404008,
      "learning_rate": 1.1623415811707906e-05,
      "loss": 0.0359,
      "step": 20300
    },
    {
      "epoch": 3.0703077851538927,
      "grad_norm": 0.0008215591078624129,
      "learning_rate": 1.1578153289076644e-05,
      "loss": 0.0214,
      "step": 20350
    },
    {
      "epoch": 3.0778515389257697,
      "grad_norm": 60.964942932128906,
      "learning_rate": 1.1532890766445384e-05,
      "loss": 0.0301,
      "step": 20400
    },
    {
      "epoch": 3.0853952926976462,
      "grad_norm": 0.0018982504261657596,
      "learning_rate": 1.1487628243814122e-05,
      "loss": 0.026,
      "step": 20450
    },
    {
      "epoch": 3.0929390464695232,
      "grad_norm": 33.452537536621094,
      "learning_rate": 1.144236572118286e-05,
      "loss": 0.0528,
      "step": 20500
    },
    {
      "epoch": 3.1004828002414,
      "grad_norm": 3.30741286277771,
      "learning_rate": 1.13971031985516e-05,
      "loss": 0.0694,
      "step": 20550
    },
    {
      "epoch": 3.108026554013277,
      "grad_norm": 0.15302985906600952,
      "learning_rate": 1.1351840675920338e-05,
      "loss": 0.0861,
      "step": 20600
    },
    {
      "epoch": 3.1155703077851538,
      "grad_norm": 4.21160364151001,
      "learning_rate": 1.1306578153289078e-05,
      "loss": 0.032,
      "step": 20650
    },
    {
      "epoch": 3.1231140615570308,
      "grad_norm": 0.021106263622641563,
      "learning_rate": 1.1261315630657816e-05,
      "loss": 0.0398,
      "step": 20700
    },
    {
      "epoch": 3.1306578153289077,
      "grad_norm": 14.315006256103516,
      "learning_rate": 1.1216053108026554e-05,
      "loss": 0.0421,
      "step": 20750
    },
    {
      "epoch": 3.1382015691007847,
      "grad_norm": 0.011939008720219135,
      "learning_rate": 1.1170790585395294e-05,
      "loss": 0.056,
      "step": 20800
    },
    {
      "epoch": 3.1457453228726613,
      "grad_norm": 0.27791833877563477,
      "learning_rate": 1.1125528062764032e-05,
      "loss": 0.0349,
      "step": 20850
    },
    {
      "epoch": 3.1532890766445383,
      "grad_norm": 4.807868003845215,
      "learning_rate": 1.108026554013277e-05,
      "loss": 0.0487,
      "step": 20900
    },
    {
      "epoch": 3.1608328304164153,
      "grad_norm": 11.564667701721191,
      "learning_rate": 1.103500301750151e-05,
      "loss": 0.0385,
      "step": 20950
    },
    {
      "epoch": 3.1683765841882923,
      "grad_norm": 0.19995367527008057,
      "learning_rate": 1.0989740494870248e-05,
      "loss": 0.0388,
      "step": 21000
    },
    {
      "epoch": 3.175920337960169,
      "grad_norm": 0.004513416439294815,
      "learning_rate": 1.0944477972238986e-05,
      "loss": 0.0262,
      "step": 21050
    },
    {
      "epoch": 3.183464091732046,
      "grad_norm": 0.000997692346572876,
      "learning_rate": 1.0899215449607724e-05,
      "loss": 0.0368,
      "step": 21100
    },
    {
      "epoch": 3.191007845503923,
      "grad_norm": 0.022362850606441498,
      "learning_rate": 1.0853952926976462e-05,
      "loss": 0.0596,
      "step": 21150
    },
    {
      "epoch": 3.1985515992758,
      "grad_norm": 0.0019367783097550273,
      "learning_rate": 1.0808690404345202e-05,
      "loss": 0.0532,
      "step": 21200
    },
    {
      "epoch": 3.2060953530476763,
      "grad_norm": 0.009372278116643429,
      "learning_rate": 1.076342788171394e-05,
      "loss": 0.0453,
      "step": 21250
    },
    {
      "epoch": 3.2136391068195533,
      "grad_norm": 0.015821659937500954,
      "learning_rate": 1.071816535908268e-05,
      "loss": 0.0169,
      "step": 21300
    },
    {
      "epoch": 3.2211828605914303,
      "grad_norm": 0.08418530970811844,
      "learning_rate": 1.0672902836451418e-05,
      "loss": 0.0711,
      "step": 21350
    },
    {
      "epoch": 3.2287266143633073,
      "grad_norm": 2.0743846893310547,
      "learning_rate": 1.0627640313820156e-05,
      "loss": 0.0701,
      "step": 21400
    },
    {
      "epoch": 3.236270368135184,
      "grad_norm": 0.002291559474542737,
      "learning_rate": 1.0582377791188896e-05,
      "loss": 0.0282,
      "step": 21450
    },
    {
      "epoch": 3.243814121907061,
      "grad_norm": 2.068986654281616,
      "learning_rate": 1.0537115268557634e-05,
      "loss": 0.0592,
      "step": 21500
    },
    {
      "epoch": 3.251357875678938,
      "grad_norm": 0.001444068388082087,
      "learning_rate": 1.0491852745926372e-05,
      "loss": 0.021,
      "step": 21550
    },
    {
      "epoch": 3.258901629450815,
      "grad_norm": 0.0013420296600088477,
      "learning_rate": 1.0446590223295112e-05,
      "loss": 0.0415,
      "step": 21600
    },
    {
      "epoch": 3.266445383222692,
      "grad_norm": 0.0034748553298413754,
      "learning_rate": 1.040132770066385e-05,
      "loss": 0.0579,
      "step": 21650
    },
    {
      "epoch": 3.2739891369945684,
      "grad_norm": 0.0025828666985034943,
      "learning_rate": 1.035606517803259e-05,
      "loss": 0.0434,
      "step": 21700
    },
    {
      "epoch": 3.2815328907664454,
      "grad_norm": 4.159502983093262,
      "learning_rate": 1.0310802655401328e-05,
      "loss": 0.0194,
      "step": 21750
    },
    {
      "epoch": 3.2890766445383224,
      "grad_norm": 0.0014871712774038315,
      "learning_rate": 1.0265540132770066e-05,
      "loss": 0.0665,
      "step": 21800
    },
    {
      "epoch": 3.296620398310199,
      "grad_norm": 0.009065132588148117,
      "learning_rate": 1.0220277610138806e-05,
      "loss": 0.0339,
      "step": 21850
    },
    {
      "epoch": 3.304164152082076,
      "grad_norm": 11.135087966918945,
      "learning_rate": 1.0175015087507544e-05,
      "loss": 0.026,
      "step": 21900
    },
    {
      "epoch": 3.311707905853953,
      "grad_norm": 2.4384095668792725,
      "learning_rate": 1.0129752564876284e-05,
      "loss": 0.0473,
      "step": 21950
    },
    {
      "epoch": 3.31925165962583,
      "grad_norm": 17.643766403198242,
      "learning_rate": 1.0084490042245022e-05,
      "loss": 0.0303,
      "step": 22000
    },
    {
      "epoch": 3.326795413397707,
      "grad_norm": 0.0006165483500808477,
      "learning_rate": 1.003922751961376e-05,
      "loss": 0.0255,
      "step": 22050
    },
    {
      "epoch": 3.3343391671695835,
      "grad_norm": 1.0437129735946655,
      "learning_rate": 9.9939649969825e-06,
      "loss": 0.0322,
      "step": 22100
    },
    {
      "epoch": 3.3418829209414604,
      "grad_norm": 17.963712692260742,
      "learning_rate": 9.948702474351238e-06,
      "loss": 0.0339,
      "step": 22150
    },
    {
      "epoch": 3.3494266747133374,
      "grad_norm": 0.012773691676557064,
      "learning_rate": 9.903439951719976e-06,
      "loss": 0.0434,
      "step": 22200
    },
    {
      "epoch": 3.3569704284852144,
      "grad_norm": 0.33758851885795593,
      "learning_rate": 9.858177429088716e-06,
      "loss": 0.0519,
      "step": 22250
    },
    {
      "epoch": 3.364514182257091,
      "grad_norm": 0.0012790565378963947,
      "learning_rate": 9.812914906457454e-06,
      "loss": 0.0193,
      "step": 22300
    },
    {
      "epoch": 3.372057936028968,
      "grad_norm": 0.015352882444858551,
      "learning_rate": 9.767652383826192e-06,
      "loss": 0.0563,
      "step": 22350
    },
    {
      "epoch": 3.379601689800845,
      "grad_norm": 0.00985037349164486,
      "learning_rate": 9.72238986119493e-06,
      "loss": 0.0499,
      "step": 22400
    },
    {
      "epoch": 3.387145443572722,
      "grad_norm": 0.09088508784770966,
      "learning_rate": 9.677127338563668e-06,
      "loss": 0.0313,
      "step": 22450
    },
    {
      "epoch": 3.3946891973445985,
      "grad_norm": 0.024330521002411842,
      "learning_rate": 9.631864815932408e-06,
      "loss": 0.054,
      "step": 22500
    },
    {
      "epoch": 3.4022329511164755,
      "grad_norm": 2.3801732063293457,
      "learning_rate": 9.586602293301146e-06,
      "loss": 0.0474,
      "step": 22550
    },
    {
      "epoch": 3.4097767048883525,
      "grad_norm": 0.023666180670261383,
      "learning_rate": 9.541339770669886e-06,
      "loss": 0.0405,
      "step": 22600
    },
    {
      "epoch": 3.4173204586602295,
      "grad_norm": 28.896520614624023,
      "learning_rate": 9.496077248038624e-06,
      "loss": 0.0231,
      "step": 22650
    },
    {
      "epoch": 3.424864212432106,
      "grad_norm": 0.003502464620396495,
      "learning_rate": 9.450814725407362e-06,
      "loss": 0.0389,
      "step": 22700
    },
    {
      "epoch": 3.432407966203983,
      "grad_norm": 0.15795516967773438,
      "learning_rate": 9.405552202776102e-06,
      "loss": 0.0445,
      "step": 22750
    },
    {
      "epoch": 3.43995171997586,
      "grad_norm": 3.5900940895080566,
      "learning_rate": 9.36028968014484e-06,
      "loss": 0.014,
      "step": 22800
    },
    {
      "epoch": 3.447495473747737,
      "grad_norm": 0.009267772547900677,
      "learning_rate": 9.31502715751358e-06,
      "loss": 0.0271,
      "step": 22850
    },
    {
      "epoch": 3.455039227519614,
      "grad_norm": 0.09288953989744186,
      "learning_rate": 9.269764634882318e-06,
      "loss": 0.0356,
      "step": 22900
    },
    {
      "epoch": 3.4625829812914906,
      "grad_norm": 0.026688234880566597,
      "learning_rate": 9.224502112251056e-06,
      "loss": 0.0281,
      "step": 22950
    },
    {
      "epoch": 3.4701267350633676,
      "grad_norm": 12.926639556884766,
      "learning_rate": 9.179239589619796e-06,
      "loss": 0.0438,
      "step": 23000
    },
    {
      "epoch": 3.4776704888352445,
      "grad_norm": 0.005698594730347395,
      "learning_rate": 9.133977066988534e-06,
      "loss": 0.0255,
      "step": 23050
    },
    {
      "epoch": 3.485214242607121,
      "grad_norm": 0.6160712242126465,
      "learning_rate": 9.088714544357272e-06,
      "loss": 0.0432,
      "step": 23100
    },
    {
      "epoch": 3.492757996378998,
      "grad_norm": 0.00386331370100379,
      "learning_rate": 9.043452021726012e-06,
      "loss": 0.0412,
      "step": 23150
    },
    {
      "epoch": 3.500301750150875,
      "grad_norm": 0.0019803643226623535,
      "learning_rate": 8.99818949909475e-06,
      "loss": 0.0456,
      "step": 23200
    },
    {
      "epoch": 3.507845503922752,
      "grad_norm": 0.02973278984427452,
      "learning_rate": 8.95292697646349e-06,
      "loss": 0.0507,
      "step": 23250
    },
    {
      "epoch": 3.515389257694629,
      "grad_norm": 0.0517258420586586,
      "learning_rate": 8.907664453832228e-06,
      "loss": 0.0378,
      "step": 23300
    },
    {
      "epoch": 3.5229330114665056,
      "grad_norm": 0.06937545537948608,
      "learning_rate": 8.862401931200966e-06,
      "loss": 0.0226,
      "step": 23350
    },
    {
      "epoch": 3.5304767652383826,
      "grad_norm": 0.011382256634533405,
      "learning_rate": 8.817139408569706e-06,
      "loss": 0.0511,
      "step": 23400
    },
    {
      "epoch": 3.5380205190102596,
      "grad_norm": 0.0011722545605152845,
      "learning_rate": 8.771876885938444e-06,
      "loss": 0.0248,
      "step": 23450
    },
    {
      "epoch": 3.545564272782136,
      "grad_norm": 0.0004615227226167917,
      "learning_rate": 8.726614363307183e-06,
      "loss": 0.046,
      "step": 23500
    },
    {
      "epoch": 3.553108026554013,
      "grad_norm": 15.956084251403809,
      "learning_rate": 8.681351840675922e-06,
      "loss": 0.036,
      "step": 23550
    },
    {
      "epoch": 3.56065178032589,
      "grad_norm": 24.1607666015625,
      "learning_rate": 8.636089318044658e-06,
      "loss": 0.023,
      "step": 23600
    },
    {
      "epoch": 3.568195534097767,
      "grad_norm": 0.004359512589871883,
      "learning_rate": 8.590826795413398e-06,
      "loss": 0.0191,
      "step": 23650
    },
    {
      "epoch": 3.575739287869644,
      "grad_norm": 0.043366387486457825,
      "learning_rate": 8.545564272782136e-06,
      "loss": 0.0595,
      "step": 23700
    },
    {
      "epoch": 3.5832830416415207,
      "grad_norm": 0.009402149356901646,
      "learning_rate": 8.500301750150874e-06,
      "loss": 0.05,
      "step": 23750
    },
    {
      "epoch": 3.5908267954133977,
      "grad_norm": 28.961023330688477,
      "learning_rate": 8.455039227519614e-06,
      "loss": 0.0298,
      "step": 23800
    },
    {
      "epoch": 3.5983705491852747,
      "grad_norm": 0.00667796703055501,
      "learning_rate": 8.409776704888352e-06,
      "loss": 0.0375,
      "step": 23850
    },
    {
      "epoch": 3.605914302957151,
      "grad_norm": 0.00042533493251539767,
      "learning_rate": 8.364514182257092e-06,
      "loss": 0.0067,
      "step": 23900
    },
    {
      "epoch": 3.613458056729028,
      "grad_norm": 0.013789637014269829,
      "learning_rate": 8.31925165962583e-06,
      "loss": 0.014,
      "step": 23950
    },
    {
      "epoch": 3.621001810500905,
      "grad_norm": 0.0010670294286683202,
      "learning_rate": 8.273989136994568e-06,
      "loss": 0.0264,
      "step": 24000
    },
    {
      "epoch": 3.628545564272782,
      "grad_norm": 0.00031609958386979997,
      "learning_rate": 8.228726614363308e-06,
      "loss": 0.0522,
      "step": 24050
    },
    {
      "epoch": 3.636089318044659,
      "grad_norm": 0.02010107785463333,
      "learning_rate": 8.183464091732046e-06,
      "loss": 0.0484,
      "step": 24100
    },
    {
      "epoch": 3.643633071816536,
      "grad_norm": 0.003617485985159874,
      "learning_rate": 8.138201569100785e-06,
      "loss": 0.0273,
      "step": 24150
    },
    {
      "epoch": 3.6511768255884127,
      "grad_norm": 0.0642995610833168,
      "learning_rate": 8.092939046469524e-06,
      "loss": 0.0644,
      "step": 24200
    },
    {
      "epoch": 3.6587205793602897,
      "grad_norm": 0.01989240013062954,
      "learning_rate": 8.047676523838262e-06,
      "loss": 0.0229,
      "step": 24250
    },
    {
      "epoch": 3.6662643331321667,
      "grad_norm": 0.0015144232893362641,
      "learning_rate": 8.002414001207001e-06,
      "loss": 0.0368,
      "step": 24300
    },
    {
      "epoch": 3.6738080869040433,
      "grad_norm": 0.056973010301589966,
      "learning_rate": 7.95715147857574e-06,
      "loss": 0.0306,
      "step": 24350
    },
    {
      "epoch": 3.6813518406759203,
      "grad_norm": 0.0011857696808874607,
      "learning_rate": 7.911888955944478e-06,
      "loss": 0.033,
      "step": 24400
    },
    {
      "epoch": 3.6888955944477972,
      "grad_norm": 0.001629559905268252,
      "learning_rate": 7.866626433313217e-06,
      "loss": 0.0218,
      "step": 24450
    },
    {
      "epoch": 3.6964393482196742,
      "grad_norm": 0.07404297590255737,
      "learning_rate": 7.821363910681955e-06,
      "loss": 0.0349,
      "step": 24500
    },
    {
      "epoch": 3.7039831019915512,
      "grad_norm": 0.32024773955345154,
      "learning_rate": 7.776101388050695e-06,
      "loss": 0.0274,
      "step": 24550
    },
    {
      "epoch": 3.711526855763428,
      "grad_norm": 0.00136937212664634,
      "learning_rate": 7.730838865419433e-06,
      "loss": 0.0529,
      "step": 24600
    },
    {
      "epoch": 3.7190706095353048,
      "grad_norm": 0.0010886846575886011,
      "learning_rate": 7.685576342788171e-06,
      "loss": 0.0224,
      "step": 24650
    },
    {
      "epoch": 3.7266143633071818,
      "grad_norm": 0.002613058779388666,
      "learning_rate": 7.640313820156911e-06,
      "loss": 0.0209,
      "step": 24700
    },
    {
      "epoch": 3.7341581170790583,
      "grad_norm": 0.17942281067371368,
      "learning_rate": 7.5950512975256485e-06,
      "loss": 0.0449,
      "step": 24750
    },
    {
      "epoch": 3.7417018708509353,
      "grad_norm": 0.0016297705005854368,
      "learning_rate": 7.549788774894388e-06,
      "loss": 0.0322,
      "step": 24800
    },
    {
      "epoch": 3.7492456246228123,
      "grad_norm": 0.10145694762468338,
      "learning_rate": 7.504526252263126e-06,
      "loss": 0.0247,
      "step": 24850
    },
    {
      "epoch": 3.7567893783946893,
      "grad_norm": 23.267248153686523,
      "learning_rate": 7.459263729631865e-06,
      "loss": 0.0742,
      "step": 24900
    },
    {
      "epoch": 3.7643331321665663,
      "grad_norm": 0.022242767736315727,
      "learning_rate": 7.414001207000603e-06,
      "loss": 0.026,
      "step": 24950
    },
    {
      "epoch": 3.771876885938443,
      "grad_norm": 0.0026560442056506872,
      "learning_rate": 7.368738684369342e-06,
      "loss": 0.0381,
      "step": 25000
    },
    {
      "epoch": 3.77942063971032,
      "grad_norm": 0.0006881954031996429,
      "learning_rate": 7.323476161738081e-06,
      "loss": 0.0204,
      "step": 25050
    },
    {
      "epoch": 3.786964393482197,
      "grad_norm": 0.0007773578399792314,
      "learning_rate": 7.27821363910682e-06,
      "loss": 0.0183,
      "step": 25100
    },
    {
      "epoch": 3.7945081472540734,
      "grad_norm": 8.560065269470215,
      "learning_rate": 7.232951116475559e-06,
      "loss": 0.0627,
      "step": 25150
    },
    {
      "epoch": 3.8020519010259504,
      "grad_norm": 11.260688781738281,
      "learning_rate": 7.1876885938442964e-06,
      "loss": 0.0418,
      "step": 25200
    },
    {
      "epoch": 3.8095956547978274,
      "grad_norm": 0.6624535918235779,
      "learning_rate": 7.142426071213035e-06,
      "loss": 0.0315,
      "step": 25250
    },
    {
      "epoch": 3.8171394085697044,
      "grad_norm": 0.0009289059671573341,
      "learning_rate": 7.097163548581774e-06,
      "loss": 0.022,
      "step": 25300
    },
    {
      "epoch": 3.8246831623415813,
      "grad_norm": 0.0702604353427887,
      "learning_rate": 7.051901025950513e-06,
      "loss": 0.0754,
      "step": 25350
    },
    {
      "epoch": 3.832226916113458,
      "grad_norm": 21.241056442260742,
      "learning_rate": 7.006638503319251e-06,
      "loss": 0.0215,
      "step": 25400
    },
    {
      "epoch": 3.839770669885335,
      "grad_norm": 0.000713569694198668,
      "learning_rate": 6.96137598068799e-06,
      "loss": 0.0329,
      "step": 25450
    },
    {
      "epoch": 3.847314423657212,
      "grad_norm": 0.010568841360509396,
      "learning_rate": 6.916113458056729e-06,
      "loss": 0.015,
      "step": 25500
    },
    {
      "epoch": 3.854858177429089,
      "grad_norm": 0.00480108754709363,
      "learning_rate": 6.870850935425468e-06,
      "loss": 0.0408,
      "step": 25550
    },
    {
      "epoch": 3.8624019312009654,
      "grad_norm": 0.07235290110111237,
      "learning_rate": 6.825588412794207e-06,
      "loss": 0.0553,
      "step": 25600
    },
    {
      "epoch": 3.8699456849728424,
      "grad_norm": 2.540008306503296,
      "learning_rate": 6.780325890162945e-06,
      "loss": 0.0384,
      "step": 25650
    },
    {
      "epoch": 3.8774894387447194,
      "grad_norm": 0.004937215708196163,
      "learning_rate": 6.735063367531684e-06,
      "loss": 0.0296,
      "step": 25700
    },
    {
      "epoch": 3.8850331925165964,
      "grad_norm": 0.043904613703489304,
      "learning_rate": 6.689800844900423e-06,
      "loss": 0.0628,
      "step": 25750
    },
    {
      "epoch": 3.8925769462884734,
      "grad_norm": 0.053986065089702606,
      "learning_rate": 6.644538322269162e-06,
      "loss": 0.0268,
      "step": 25800
    },
    {
      "epoch": 3.90012070006035,
      "grad_norm": 0.006314157973974943,
      "learning_rate": 6.599275799637899e-06,
      "loss": 0.0415,
      "step": 25850
    },
    {
      "epoch": 3.907664453832227,
      "grad_norm": 25.340484619140625,
      "learning_rate": 6.554013277006638e-06,
      "loss": 0.0112,
      "step": 25900
    },
    {
      "epoch": 3.915208207604104,
      "grad_norm": 0.0014309394173324108,
      "learning_rate": 6.508750754375377e-06,
      "loss": 0.0476,
      "step": 25950
    },
    {
      "epoch": 3.9227519613759805,
      "grad_norm": 0.014275669120252132,
      "learning_rate": 6.463488231744116e-06,
      "loss": 0.025,
      "step": 26000
    },
    {
      "epoch": 3.9302957151478575,
      "grad_norm": 0.004061646293848753,
      "learning_rate": 6.418225709112854e-06,
      "loss": 0.0639,
      "step": 26050
    },
    {
      "epoch": 3.9378394689197345,
      "grad_norm": 0.0009316023788414896,
      "learning_rate": 6.372963186481593e-06,
      "loss": 0.0131,
      "step": 26100
    },
    {
      "epoch": 3.9453832226916115,
      "grad_norm": 5.573128700256348,
      "learning_rate": 6.327700663850332e-06,
      "loss": 0.0322,
      "step": 26150
    },
    {
      "epoch": 3.9529269764634885,
      "grad_norm": 6.413852214813232,
      "learning_rate": 6.282438141219071e-06,
      "loss": 0.0468,
      "step": 26200
    },
    {
      "epoch": 3.960470730235365,
      "grad_norm": 51.362125396728516,
      "learning_rate": 6.23717561858781e-06,
      "loss": 0.024,
      "step": 26250
    },
    {
      "epoch": 3.968014484007242,
      "grad_norm": 0.00232720491476357,
      "learning_rate": 6.191913095956548e-06,
      "loss": 0.0353,
      "step": 26300
    },
    {
      "epoch": 3.975558237779119,
      "grad_norm": 0.0032831872813403606,
      "learning_rate": 6.146650573325287e-06,
      "loss": 0.0221,
      "step": 26350
    },
    {
      "epoch": 3.9831019915509955,
      "grad_norm": 0.0016520103672519326,
      "learning_rate": 6.101388050694026e-06,
      "loss": 0.0561,
      "step": 26400
    },
    {
      "epoch": 3.9906457453228725,
      "grad_norm": 0.004207182209938765,
      "learning_rate": 6.056125528062764e-06,
      "loss": 0.0411,
      "step": 26450
    },
    {
      "epoch": 3.9981894990947495,
      "grad_norm": 0.4985950291156769,
      "learning_rate": 6.010863005431502e-06,
      "loss": 0.0219,
      "step": 26500
    },
    {
      "epoch": 4.0,
      "eval_runtime": 38.8194,
      "eval_samples_per_second": 695.426,
      "eval_steps_per_second": 43.483,
      "step": 26512
    },
    {
      "epoch": 4.0057332528666265,
      "grad_norm": 0.03147834911942482,
      "learning_rate": 5.965600482800241e-06,
      "loss": 0.0289,
      "step": 26550
    },
    {
      "epoch": 4.0132770066385035,
      "grad_norm": 0.0024675335735082626,
      "learning_rate": 5.92033796016898e-06,
      "loss": 0.0282,
      "step": 26600
    },
    {
      "epoch": 4.0208207604103805,
      "grad_norm": 0.0067442781291902065,
      "learning_rate": 5.875075437537719e-06,
      "loss": 0.019,
      "step": 26650
    },
    {
      "epoch": 4.0283645141822575,
      "grad_norm": 0.03927016630768776,
      "learning_rate": 5.829812914906458e-06,
      "loss": 0.0257,
      "step": 26700
    },
    {
      "epoch": 4.035908267954134,
      "grad_norm": 0.00028380603180266917,
      "learning_rate": 5.784550392275196e-06,
      "loss": 0.0212,
      "step": 26750
    },
    {
      "epoch": 4.043452021726011,
      "grad_norm": 0.0008902240660972893,
      "learning_rate": 5.739287869643935e-06,
      "loss": 0.0198,
      "step": 26800
    },
    {
      "epoch": 4.050995775497888,
      "grad_norm": 0.03295537084341049,
      "learning_rate": 5.694025347012674e-06,
      "loss": 0.0222,
      "step": 26850
    },
    {
      "epoch": 4.058539529269765,
      "grad_norm": 0.0004854988947045058,
      "learning_rate": 5.648762824381413e-06,
      "loss": 0.0225,
      "step": 26900
    },
    {
      "epoch": 4.066083283041642,
      "grad_norm": 0.0003718778898473829,
      "learning_rate": 5.603500301750151e-06,
      "loss": 0.0149,
      "step": 26950
    },
    {
      "epoch": 4.073627036813519,
      "grad_norm": 0.00045789795694872737,
      "learning_rate": 5.55823777911889e-06,
      "loss": 0.0091,
      "step": 27000
    },
    {
      "epoch": 4.081170790585396,
      "grad_norm": 0.014634821563959122,
      "learning_rate": 5.512975256487629e-06,
      "loss": 0.0218,
      "step": 27050
    },
    {
      "epoch": 4.0887145443572726,
      "grad_norm": 0.00019904815417248756,
      "learning_rate": 5.467712733856367e-06,
      "loss": 0.0177,
      "step": 27100
    },
    {
      "epoch": 4.096258298129149,
      "grad_norm": 3.002558469772339,
      "learning_rate": 5.422450211225105e-06,
      "loss": 0.0214,
      "step": 27150
    },
    {
      "epoch": 4.103802051901026,
      "grad_norm": 17.165613174438477,
      "learning_rate": 5.377187688593844e-06,
      "loss": 0.0357,
      "step": 27200
    },
    {
      "epoch": 4.111345805672903,
      "grad_norm": 0.000869446259457618,
      "learning_rate": 5.331925165962583e-06,
      "loss": 0.0171,
      "step": 27250
    },
    {
      "epoch": 4.11888955944478,
      "grad_norm": 0.002803297946229577,
      "learning_rate": 5.286662643331322e-06,
      "loss": 0.0401,
      "step": 27300
    },
    {
      "epoch": 4.126433313216657,
      "grad_norm": 0.0059907627291977406,
      "learning_rate": 5.241400120700061e-06,
      "loss": 0.0119,
      "step": 27350
    },
    {
      "epoch": 4.133977066988534,
      "grad_norm": 0.009844387881457806,
      "learning_rate": 5.196137598068799e-06,
      "loss": 0.0217,
      "step": 27400
    },
    {
      "epoch": 4.141520820760411,
      "grad_norm": 35.32555389404297,
      "learning_rate": 5.150875075437538e-06,
      "loss": 0.0292,
      "step": 27450
    },
    {
      "epoch": 4.149064574532288,
      "grad_norm": 0.00029364117654040456,
      "learning_rate": 5.105612552806277e-06,
      "loss": 0.0018,
      "step": 27500
    },
    {
      "epoch": 4.156608328304165,
      "grad_norm": 0.0005504169967025518,
      "learning_rate": 5.060350030175016e-06,
      "loss": 0.0199,
      "step": 27550
    },
    {
      "epoch": 4.164152082076041,
      "grad_norm": 0.0024482186418026686,
      "learning_rate": 5.015087507543754e-06,
      "loss": 0.0165,
      "step": 27600
    },
    {
      "epoch": 4.171695835847918,
      "grad_norm": 0.0007622211123816669,
      "learning_rate": 4.969824984912493e-06,
      "loss": 0.0381,
      "step": 27650
    },
    {
      "epoch": 4.179239589619795,
      "grad_norm": 0.10681849718093872,
      "learning_rate": 4.924562462281232e-06,
      "loss": 0.0255,
      "step": 27700
    },
    {
      "epoch": 4.186783343391672,
      "grad_norm": 0.06073771044611931,
      "learning_rate": 4.87929993964997e-06,
      "loss": 0.0068,
      "step": 27750
    },
    {
      "epoch": 4.194327097163549,
      "grad_norm": 0.00021662570361513644,
      "learning_rate": 4.834037417018708e-06,
      "loss": 0.0242,
      "step": 27800
    },
    {
      "epoch": 4.201870850935426,
      "grad_norm": 0.0038410001434385777,
      "learning_rate": 4.788774894387447e-06,
      "loss": 0.0415,
      "step": 27850
    },
    {
      "epoch": 4.209414604707303,
      "grad_norm": 0.0021065871696919203,
      "learning_rate": 4.743512371756186e-06,
      "loss": 0.0189,
      "step": 27900
    },
    {
      "epoch": 4.21695835847918,
      "grad_norm": 0.013755649328231812,
      "learning_rate": 4.698249849124925e-06,
      "loss": 0.0298,
      "step": 27950
    },
    {
      "epoch": 4.224502112251056,
      "grad_norm": 0.0010568239958956838,
      "learning_rate": 4.652987326493664e-06,
      "loss": 0.0251,
      "step": 28000
    },
    {
      "epoch": 4.232045866022933,
      "grad_norm": 8.796552658081055,
      "learning_rate": 4.607724803862402e-06,
      "loss": 0.0254,
      "step": 28050
    },
    {
      "epoch": 4.23958961979481,
      "grad_norm": 0.0008742142235860229,
      "learning_rate": 4.562462281231141e-06,
      "loss": 0.0293,
      "step": 28100
    },
    {
      "epoch": 4.247133373566687,
      "grad_norm": 0.012439215555787086,
      "learning_rate": 4.51719975859988e-06,
      "loss": 0.0263,
      "step": 28150
    },
    {
      "epoch": 4.254677127338564,
      "grad_norm": 0.0005400591180659831,
      "learning_rate": 4.471937235968619e-06,
      "loss": 0.0071,
      "step": 28200
    },
    {
      "epoch": 4.262220881110441,
      "grad_norm": 0.425005167722702,
      "learning_rate": 4.426674713337357e-06,
      "loss": 0.0172,
      "step": 28250
    },
    {
      "epoch": 4.269764634882318,
      "grad_norm": 1.862489104270935,
      "learning_rate": 4.381412190706096e-06,
      "loss": 0.0199,
      "step": 28300
    },
    {
      "epoch": 4.277308388654195,
      "grad_norm": 0.006323918234556913,
      "learning_rate": 4.3361496680748346e-06,
      "loss": 0.0334,
      "step": 28350
    },
    {
      "epoch": 4.284852142426071,
      "grad_norm": 0.00044195580994710326,
      "learning_rate": 4.290887145443573e-06,
      "loss": 0.0338,
      "step": 28400
    },
    {
      "epoch": 4.292395896197948,
      "grad_norm": 0.0028066840022802353,
      "learning_rate": 4.245624622812312e-06,
      "loss": 0.0203,
      "step": 28450
    },
    {
      "epoch": 4.299939649969825,
      "grad_norm": 0.00043141550850123167,
      "learning_rate": 4.20036210018105e-06,
      "loss": 0.0264,
      "step": 28500
    },
    {
      "epoch": 4.307483403741702,
      "grad_norm": 0.46526414155960083,
      "learning_rate": 4.155099577549789e-06,
      "loss": 0.0125,
      "step": 28550
    },
    {
      "epoch": 4.315027157513579,
      "grad_norm": 0.000394379225326702,
      "learning_rate": 4.109837054918528e-06,
      "loss": 0.0219,
      "step": 28600
    },
    {
      "epoch": 4.322570911285456,
      "grad_norm": 0.03850072622299194,
      "learning_rate": 4.0645745322872665e-06,
      "loss": 0.0309,
      "step": 28650
    },
    {
      "epoch": 4.330114665057333,
      "grad_norm": 0.00023126130690798163,
      "learning_rate": 4.019312009656005e-06,
      "loss": 0.0149,
      "step": 28700
    },
    {
      "epoch": 4.33765841882921,
      "grad_norm": 0.002212406834587455,
      "learning_rate": 3.9740494870247436e-06,
      "loss": 0.0485,
      "step": 28750
    },
    {
      "epoch": 4.345202172601086,
      "grad_norm": 0.0006574220606125891,
      "learning_rate": 3.9287869643934825e-06,
      "loss": 0.0281,
      "step": 28800
    },
    {
      "epoch": 4.352745926372963,
      "grad_norm": 0.0012795100919902325,
      "learning_rate": 3.8835244417622214e-06,
      "loss": 0.0149,
      "step": 28850
    },
    {
      "epoch": 4.36028968014484,
      "grad_norm": 0.00041723009780980647,
      "learning_rate": 3.8382619191309595e-06,
      "loss": 0.0332,
      "step": 28900
    },
    {
      "epoch": 4.367833433916717,
      "grad_norm": 3.3195102214813232,
      "learning_rate": 3.792999396499698e-06,
      "loss": 0.0359,
      "step": 28950
    },
    {
      "epoch": 4.375377187688594,
      "grad_norm": 0.0004659858241211623,
      "learning_rate": 3.747736873868437e-06,
      "loss": 0.017,
      "step": 29000
    },
    {
      "epoch": 4.382920941460471,
      "grad_norm": 28.706151962280273,
      "learning_rate": 3.702474351237176e-06,
      "loss": 0.0102,
      "step": 29050
    },
    {
      "epoch": 4.390464695232348,
      "grad_norm": 0.0002987022162415087,
      "learning_rate": 3.6572118286059145e-06,
      "loss": 0.0316,
      "step": 29100
    },
    {
      "epoch": 4.398008449004225,
      "grad_norm": 0.0013281565625220537,
      "learning_rate": 3.6119493059746534e-06,
      "loss": 0.0024,
      "step": 29150
    },
    {
      "epoch": 4.405552202776102,
      "grad_norm": 0.0014700355241075158,
      "learning_rate": 3.5666867833433915e-06,
      "loss": 0.0204,
      "step": 29200
    },
    {
      "epoch": 4.413095956547978,
      "grad_norm": 0.0025377022102475166,
      "learning_rate": 3.5214242607121304e-06,
      "loss": 0.0327,
      "step": 29250
    },
    {
      "epoch": 4.420639710319855,
      "grad_norm": 0.4021594822406769,
      "learning_rate": 3.476161738080869e-06,
      "loss": 0.0192,
      "step": 29300
    },
    {
      "epoch": 4.428183464091732,
      "grad_norm": 0.017008261755108833,
      "learning_rate": 3.430899215449608e-06,
      "loss": 0.017,
      "step": 29350
    },
    {
      "epoch": 4.435727217863609,
      "grad_norm": 0.0004145853454247117,
      "learning_rate": 3.3856366928183464e-06,
      "loss": 0.0227,
      "step": 29400
    },
    {
      "epoch": 4.443270971635486,
      "grad_norm": 0.0015590605325996876,
      "learning_rate": 3.3403741701870854e-06,
      "loss": 0.0082,
      "step": 29450
    },
    {
      "epoch": 4.450814725407363,
      "grad_norm": 0.0017028441652655602,
      "learning_rate": 3.295111647555824e-06,
      "loss": 0.015,
      "step": 29500
    },
    {
      "epoch": 4.45835847917924,
      "grad_norm": 0.41904085874557495,
      "learning_rate": 3.2498491249245624e-06,
      "loss": 0.0232,
      "step": 29550
    },
    {
      "epoch": 4.465902232951117,
      "grad_norm": 0.0004474706365726888,
      "learning_rate": 3.2045866022933013e-06,
      "loss": 0.0277,
      "step": 29600
    },
    {
      "epoch": 4.473445986722993,
      "grad_norm": 0.00027452255017124116,
      "learning_rate": 3.15932407966204e-06,
      "loss": 0.017,
      "step": 29650
    },
    {
      "epoch": 4.48098974049487,
      "grad_norm": 0.00033595264540053904,
      "learning_rate": 3.114061557030779e-06,
      "loss": 0.0257,
      "step": 29700
    },
    {
      "epoch": 4.488533494266747,
      "grad_norm": 0.0005250965477898717,
      "learning_rate": 3.0687990343995173e-06,
      "loss": 0.0079,
      "step": 29750
    },
    {
      "epoch": 4.496077248038624,
      "grad_norm": 0.00033846369478851557,
      "learning_rate": 3.023536511768256e-06,
      "loss": 0.0103,
      "step": 29800
    },
    {
      "epoch": 4.503621001810501,
      "grad_norm": 0.0033917000982910395,
      "learning_rate": 2.9782739891369944e-06,
      "loss": 0.0503,
      "step": 29850
    },
    {
      "epoch": 4.511164755582378,
      "grad_norm": 0.029787031933665276,
      "learning_rate": 2.9330114665057333e-06,
      "loss": 0.0114,
      "step": 29900
    },
    {
      "epoch": 4.518708509354255,
      "grad_norm": 0.05145004764199257,
      "learning_rate": 2.887748943874472e-06,
      "loss": 0.0327,
      "step": 29950
    },
    {
      "epoch": 4.526252263126132,
      "grad_norm": 0.0036620432510972023,
      "learning_rate": 2.8424864212432108e-06,
      "loss": 0.0401,
      "step": 30000
    },
    {
      "epoch": 4.533796016898009,
      "grad_norm": 0.00022135682229418308,
      "learning_rate": 2.7972238986119497e-06,
      "loss": 0.0065,
      "step": 30050
    },
    {
      "epoch": 4.541339770669885,
      "grad_norm": 0.018526591360569,
      "learning_rate": 2.7519613759806882e-06,
      "loss": 0.0212,
      "step": 30100
    },
    {
      "epoch": 4.548883524441762,
      "grad_norm": 0.02749984711408615,
      "learning_rate": 2.7066988533494267e-06,
      "loss": 0.0097,
      "step": 30150
    },
    {
      "epoch": 4.556427278213639,
      "grad_norm": 0.0018844060832634568,
      "learning_rate": 2.6614363307181653e-06,
      "loss": 0.014,
      "step": 30200
    },
    {
      "epoch": 4.563971031985516,
      "grad_norm": 0.005155262537300587,
      "learning_rate": 2.616173808086904e-06,
      "loss": 0.0191,
      "step": 30250
    },
    {
      "epoch": 4.571514785757393,
      "grad_norm": 0.007997502572834492,
      "learning_rate": 2.5709112854556427e-06,
      "loss": 0.0394,
      "step": 30300
    },
    {
      "epoch": 4.57905853952927,
      "grad_norm": 15.400834083557129,
      "learning_rate": 2.5256487628243817e-06,
      "loss": 0.0127,
      "step": 30350
    },
    {
      "epoch": 4.586602293301147,
      "grad_norm": 0.002528777811676264,
      "learning_rate": 2.48038624019312e-06,
      "loss": 0.0086,
      "step": 30400
    },
    {
      "epoch": 4.594146047073023,
      "grad_norm": 0.0008684293716214597,
      "learning_rate": 2.4351237175618587e-06,
      "loss": 0.0165,
      "step": 30450
    },
    {
      "epoch": 4.6016898008449,
      "grad_norm": 0.00037975949817337096,
      "learning_rate": 2.3898611949305972e-06,
      "loss": 0.0343,
      "step": 30500
    },
    {
      "epoch": 4.609233554616777,
      "grad_norm": 0.000516002532094717,
      "learning_rate": 2.344598672299336e-06,
      "loss": 0.0131,
      "step": 30550
    },
    {
      "epoch": 4.616777308388654,
      "grad_norm": 0.0003392669023014605,
      "learning_rate": 2.299336149668075e-06,
      "loss": 0.0402,
      "step": 30600
    },
    {
      "epoch": 4.624321062160531,
      "grad_norm": 0.0037740806583315134,
      "learning_rate": 2.2540736270368136e-06,
      "loss": 0.0163,
      "step": 30650
    },
    {
      "epoch": 4.631864815932408,
      "grad_norm": 16.771520614624023,
      "learning_rate": 2.2088111044055526e-06,
      "loss": 0.0393,
      "step": 30700
    },
    {
      "epoch": 4.639408569704285,
      "grad_norm": 0.05458066985011101,
      "learning_rate": 2.163548581774291e-06,
      "loss": 0.0162,
      "step": 30750
    },
    {
      "epoch": 4.646952323476162,
      "grad_norm": 6.999848365783691,
      "learning_rate": 2.1182860591430296e-06,
      "loss": 0.0244,
      "step": 30800
    },
    {
      "epoch": 4.654496077248039,
      "grad_norm": 0.000578376988414675,
      "learning_rate": 2.073023536511768e-06,
      "loss": 0.0201,
      "step": 30850
    },
    {
      "epoch": 4.662039831019915,
      "grad_norm": 0.0003877392446156591,
      "learning_rate": 2.027761013880507e-06,
      "loss": 0.0421,
      "step": 30900
    },
    {
      "epoch": 4.669583584791792,
      "grad_norm": 0.0015097773866727948,
      "learning_rate": 1.9824984912492456e-06,
      "loss": 0.0099,
      "step": 30950
    },
    {
      "epoch": 4.677127338563669,
      "grad_norm": 0.1358793079853058,
      "learning_rate": 1.9372359686179845e-06,
      "loss": 0.0252,
      "step": 31000
    },
    {
      "epoch": 4.684671092335546,
      "grad_norm": 0.00042081272113136947,
      "learning_rate": 1.8919734459867228e-06,
      "loss": 0.0218,
      "step": 31050
    },
    {
      "epoch": 4.692214846107423,
      "grad_norm": 0.0008118675323203206,
      "learning_rate": 1.8467109233554618e-06,
      "loss": 0.0199,
      "step": 31100
    },
    {
      "epoch": 4.6997585998793,
      "grad_norm": 0.000351626833435148,
      "learning_rate": 1.8014484007242003e-06,
      "loss": 0.0186,
      "step": 31150
    },
    {
      "epoch": 4.707302353651177,
      "grad_norm": 0.03592024743556976,
      "learning_rate": 1.756185878092939e-06,
      "loss": 0.0273,
      "step": 31200
    },
    {
      "epoch": 4.714846107423053,
      "grad_norm": 0.779563844203949,
      "learning_rate": 1.7109233554616778e-06,
      "loss": 0.0057,
      "step": 31250
    },
    {
      "epoch": 4.72238986119493,
      "grad_norm": 0.0005764092784374952,
      "learning_rate": 1.6656608328304165e-06,
      "loss": 0.0084,
      "step": 31300
    },
    {
      "epoch": 4.729933614966807,
      "grad_norm": 0.0042462036944925785,
      "learning_rate": 1.620398310199155e-06,
      "loss": 0.0108,
      "step": 31350
    },
    {
      "epoch": 4.737477368738684,
      "grad_norm": 9.396621704101562,
      "learning_rate": 1.5751357875678937e-06,
      "loss": 0.016,
      "step": 31400
    },
    {
      "epoch": 4.745021122510561,
      "grad_norm": 0.0009149696561507881,
      "learning_rate": 1.5298732649366327e-06,
      "loss": 0.0229,
      "step": 31450
    },
    {
      "epoch": 4.752564876282438,
      "grad_norm": 0.0003863151650875807,
      "learning_rate": 1.4846107423053712e-06,
      "loss": 0.0167,
      "step": 31500
    },
    {
      "epoch": 4.760108630054315,
      "grad_norm": 1.6907824277877808,
      "learning_rate": 1.43934821967411e-06,
      "loss": 0.0325,
      "step": 31550
    },
    {
      "epoch": 4.767652383826192,
      "grad_norm": 0.0004556968924589455,
      "learning_rate": 1.3940856970428487e-06,
      "loss": 0.0143,
      "step": 31600
    },
    {
      "epoch": 4.775196137598069,
      "grad_norm": 0.015366112813353539,
      "learning_rate": 1.3488231744115872e-06,
      "loss": 0.0282,
      "step": 31650
    },
    {
      "epoch": 4.782739891369946,
      "grad_norm": 38.30854415893555,
      "learning_rate": 1.303560651780326e-06,
      "loss": 0.0293,
      "step": 31700
    },
    {
      "epoch": 4.790283645141822,
      "grad_norm": 1.555522084236145,
      "learning_rate": 1.2582981291490646e-06,
      "loss": 0.0054,
      "step": 31750
    },
    {
      "epoch": 4.797827398913699,
      "grad_norm": 0.1297227293252945,
      "learning_rate": 1.2130356065178032e-06,
      "loss": 0.0225,
      "step": 31800
    },
    {
      "epoch": 4.805371152685576,
      "grad_norm": 0.48069706559181213,
      "learning_rate": 1.1677730838865419e-06,
      "loss": 0.0109,
      "step": 31850
    },
    {
      "epoch": 4.812914906457453,
      "grad_norm": 0.03262431547045708,
      "learning_rate": 1.1225105612552806e-06,
      "loss": 0.0176,
      "step": 31900
    },
    {
      "epoch": 4.82045866022933,
      "grad_norm": 0.010389873757958412,
      "learning_rate": 1.0772480386240191e-06,
      "loss": 0.0253,
      "step": 31950
    },
    {
      "epoch": 4.828002414001207,
      "grad_norm": 0.0007063400116749108,
      "learning_rate": 1.031985515992758e-06,
      "loss": 0.0211,
      "step": 32000
    },
    {
      "epoch": 4.835546167773084,
      "grad_norm": 0.0005687877419404685,
      "learning_rate": 9.867229933614968e-07,
      "loss": 0.0227,
      "step": 32050
    },
    {
      "epoch": 4.84308992154496,
      "grad_norm": 0.0005453982739709318,
      "learning_rate": 9.414604707302354e-07,
      "loss": 0.0126,
      "step": 32100
    },
    {
      "epoch": 4.850633675316837,
      "grad_norm": 0.0017956673400476575,
      "learning_rate": 8.961979480989741e-07,
      "loss": 0.0392,
      "step": 32150
    },
    {
      "epoch": 4.858177429088714,
      "grad_norm": 0.0006414392264559865,
      "learning_rate": 8.509354254677128e-07,
      "loss": 0.0237,
      "step": 32200
    },
    {
      "epoch": 4.865721182860591,
      "grad_norm": 10.276601791381836,
      "learning_rate": 8.056729028364514e-07,
      "loss": 0.01,
      "step": 32250
    },
    {
      "epoch": 4.873264936632468,
      "grad_norm": 0.00033680821070447564,
      "learning_rate": 7.604103802051902e-07,
      "loss": 0.0201,
      "step": 32300
    },
    {
      "epoch": 4.880808690404345,
      "grad_norm": 0.0023196772672235966,
      "learning_rate": 7.151478575739288e-07,
      "loss": 0.0175,
      "step": 32350
    },
    {
      "epoch": 4.888352444176222,
      "grad_norm": 0.0010892144637182355,
      "learning_rate": 6.698853349426675e-07,
      "loss": 0.0219,
      "step": 32400
    },
    {
      "epoch": 4.895896197948099,
      "grad_norm": 0.09755352139472961,
      "learning_rate": 6.246228123114062e-07,
      "loss": 0.0467,
      "step": 32450
    },
    {
      "epoch": 4.903439951719976,
      "grad_norm": 0.0013779328437522054,
      "learning_rate": 5.793602896801449e-07,
      "loss": 0.02,
      "step": 32500
    },
    {
      "epoch": 4.910983705491852,
      "grad_norm": 0.03295178338885307,
      "learning_rate": 5.340977670488835e-07,
      "loss": 0.015,
      "step": 32550
    },
    {
      "epoch": 4.918527459263729,
      "grad_norm": 0.00027506769401952624,
      "learning_rate": 4.888352444176222e-07,
      "loss": 0.0276,
      "step": 32600
    },
    {
      "epoch": 4.926071213035606,
      "grad_norm": 0.0018745806301012635,
      "learning_rate": 4.435727217863609e-07,
      "loss": 0.0133,
      "step": 32650
    },
    {
      "epoch": 4.933614966807483,
      "grad_norm": 0.00047315226402133703,
      "learning_rate": 3.9831019915509957e-07,
      "loss": 0.0445,
      "step": 32700
    },
    {
      "epoch": 4.94115872057936,
      "grad_norm": 0.0014912150800228119,
      "learning_rate": 3.530476765238383e-07,
      "loss": 0.0311,
      "step": 32750
    },
    {
      "epoch": 4.948702474351237,
      "grad_norm": 0.6321888566017151,
      "learning_rate": 3.07785153892577e-07,
      "loss": 0.0218,
      "step": 32800
    },
    {
      "epoch": 4.956246228123114,
      "grad_norm": 0.0014778525801375508,
      "learning_rate": 2.625226312613156e-07,
      "loss": 0.013,
      "step": 32850
    },
    {
      "epoch": 4.963789981894991,
      "grad_norm": 31.183080673217773,
      "learning_rate": 2.172601086300543e-07,
      "loss": 0.0304,
      "step": 32900
    },
    {
      "epoch": 4.971333735666867,
      "grad_norm": 0.012157571502029896,
      "learning_rate": 1.7199758599879301e-07,
      "loss": 0.0043,
      "step": 32950
    },
    {
      "epoch": 4.978877489438744,
      "grad_norm": 0.008876699954271317,
      "learning_rate": 1.267350633675317e-07,
      "loss": 0.0413,
      "step": 33000
    }
  ],
  "logging_steps": 50,
  "max_steps": 33140,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.8982342156288e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
