{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.933960831941703,
  "eval_steps": 500,
  "global_step": 32500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007590708972218006,
      "grad_norm": 1.0005580186843872,
      "learning_rate": 2.995445574616669e-05,
      "loss": 1.1013,
      "step": 50
    },
    {
      "epoch": 0.015181417944436011,
      "grad_norm": 1.2245584726333618,
      "learning_rate": 2.9908911492333385e-05,
      "loss": 0.2132,
      "step": 100
    },
    {
      "epoch": 0.022772126916654017,
      "grad_norm": 0.22679993510246277,
      "learning_rate": 2.9863367238500076e-05,
      "loss": 0.1512,
      "step": 150
    },
    {
      "epoch": 0.030362835888872022,
      "grad_norm": 1.96134614944458,
      "learning_rate": 2.981782298466677e-05,
      "loss": 0.2911,
      "step": 200
    },
    {
      "epoch": 0.037953544861090024,
      "grad_norm": 4.8828935623168945,
      "learning_rate": 2.977227873083346e-05,
      "loss": 0.3067,
      "step": 250
    },
    {
      "epoch": 0.045544253833308034,
      "grad_norm": 0.2804880738258362,
      "learning_rate": 2.9726734477000154e-05,
      "loss": 0.2637,
      "step": 300
    },
    {
      "epoch": 0.053134962805526036,
      "grad_norm": 0.4478475749492645,
      "learning_rate": 2.9681190223166845e-05,
      "loss": 0.3111,
      "step": 350
    },
    {
      "epoch": 0.060725671777744045,
      "grad_norm": 5.153872013092041,
      "learning_rate": 2.963564596933354e-05,
      "loss": 0.2568,
      "step": 400
    },
    {
      "epoch": 0.06831638074996205,
      "grad_norm": 2.6621294021606445,
      "learning_rate": 2.959010171550023e-05,
      "loss": 0.3144,
      "step": 450
    },
    {
      "epoch": 0.07590708972218005,
      "grad_norm": 2.0812928676605225,
      "learning_rate": 2.954455746166692e-05,
      "loss": 0.2958,
      "step": 500
    },
    {
      "epoch": 0.08349779869439805,
      "grad_norm": 0.649292528629303,
      "learning_rate": 2.9499013207833614e-05,
      "loss": 0.2385,
      "step": 550
    },
    {
      "epoch": 0.09108850766661607,
      "grad_norm": 0.07929323613643646,
      "learning_rate": 2.9453468954000304e-05,
      "loss": 0.3038,
      "step": 600
    },
    {
      "epoch": 0.09867921663883407,
      "grad_norm": 0.8779211640357971,
      "learning_rate": 2.9407924700166998e-05,
      "loss": 0.2851,
      "step": 650
    },
    {
      "epoch": 0.10626992561105207,
      "grad_norm": 5.750625133514404,
      "learning_rate": 2.936238044633369e-05,
      "loss": 0.2763,
      "step": 700
    },
    {
      "epoch": 0.11386063458327007,
      "grad_norm": 0.2309071570634842,
      "learning_rate": 2.9316836192500382e-05,
      "loss": 0.2934,
      "step": 750
    },
    {
      "epoch": 0.12145134355548809,
      "grad_norm": 3.4190633296966553,
      "learning_rate": 2.9271291938667073e-05,
      "loss": 0.2225,
      "step": 800
    },
    {
      "epoch": 0.1290420525277061,
      "grad_norm": 3.05902099609375,
      "learning_rate": 2.9225747684833767e-05,
      "loss": 0.2691,
      "step": 850
    },
    {
      "epoch": 0.1366327614999241,
      "grad_norm": 0.8665591478347778,
      "learning_rate": 2.9180203431000457e-05,
      "loss": 0.3286,
      "step": 900
    },
    {
      "epoch": 0.1442234704721421,
      "grad_norm": 0.14845490455627441,
      "learning_rate": 2.9134659177167148e-05,
      "loss": 0.2046,
      "step": 950
    },
    {
      "epoch": 0.1518141794443601,
      "grad_norm": 8.942172050476074,
      "learning_rate": 2.9089114923333842e-05,
      "loss": 0.2064,
      "step": 1000
    },
    {
      "epoch": 0.1594048884165781,
      "grad_norm": 0.947409987449646,
      "learning_rate": 2.9043570669500532e-05,
      "loss": 0.2166,
      "step": 1050
    },
    {
      "epoch": 0.1669955973887961,
      "grad_norm": 3.003574848175049,
      "learning_rate": 2.8998026415667226e-05,
      "loss": 0.1906,
      "step": 1100
    },
    {
      "epoch": 0.17458630636101413,
      "grad_norm": 3.3647496700286865,
      "learning_rate": 2.8952482161833917e-05,
      "loss": 0.2337,
      "step": 1150
    },
    {
      "epoch": 0.18217701533323213,
      "grad_norm": 0.2121383249759674,
      "learning_rate": 2.890693790800061e-05,
      "loss": 0.2017,
      "step": 1200
    },
    {
      "epoch": 0.18976772430545014,
      "grad_norm": 7.677606105804443,
      "learning_rate": 2.88613936541673e-05,
      "loss": 0.2267,
      "step": 1250
    },
    {
      "epoch": 0.19735843327766814,
      "grad_norm": 2.2644448280334473,
      "learning_rate": 2.8815849400333992e-05,
      "loss": 0.2002,
      "step": 1300
    },
    {
      "epoch": 0.20494914224988614,
      "grad_norm": 0.08768187463283539,
      "learning_rate": 2.8770305146500682e-05,
      "loss": 0.2065,
      "step": 1350
    },
    {
      "epoch": 0.21253985122210414,
      "grad_norm": 3.8325440883636475,
      "learning_rate": 2.8724760892667373e-05,
      "loss": 0.1632,
      "step": 1400
    },
    {
      "epoch": 0.22013056019432214,
      "grad_norm": 0.1195606142282486,
      "learning_rate": 2.8679216638834067e-05,
      "loss": 0.1642,
      "step": 1450
    },
    {
      "epoch": 0.22772126916654015,
      "grad_norm": 0.4408233165740967,
      "learning_rate": 2.8633672385000757e-05,
      "loss": 0.1663,
      "step": 1500
    },
    {
      "epoch": 0.23531197813875815,
      "grad_norm": 0.30877920985221863,
      "learning_rate": 2.858812813116745e-05,
      "loss": 0.2227,
      "step": 1550
    },
    {
      "epoch": 0.24290268711097618,
      "grad_norm": 4.6050591468811035,
      "learning_rate": 2.8542583877334142e-05,
      "loss": 0.2303,
      "step": 1600
    },
    {
      "epoch": 0.25049339608319415,
      "grad_norm": 0.17888863384723663,
      "learning_rate": 2.8497039623500836e-05,
      "loss": 0.149,
      "step": 1650
    },
    {
      "epoch": 0.2580841050554122,
      "grad_norm": 0.05330091714859009,
      "learning_rate": 2.8451495369667526e-05,
      "loss": 0.1419,
      "step": 1700
    },
    {
      "epoch": 0.26567481402763016,
      "grad_norm": 5.922901153564453,
      "learning_rate": 2.840595111583422e-05,
      "loss": 0.1311,
      "step": 1750
    },
    {
      "epoch": 0.2732655229998482,
      "grad_norm": 0.1250111311674118,
      "learning_rate": 2.836040686200091e-05,
      "loss": 0.1845,
      "step": 1800
    },
    {
      "epoch": 0.2808562319720662,
      "grad_norm": 0.711267352104187,
      "learning_rate": 2.83148626081676e-05,
      "loss": 0.1992,
      "step": 1850
    },
    {
      "epoch": 0.2884469409442842,
      "grad_norm": 0.03887880593538284,
      "learning_rate": 2.8269318354334295e-05,
      "loss": 0.1636,
      "step": 1900
    },
    {
      "epoch": 0.2960376499165022,
      "grad_norm": 2.992190361022949,
      "learning_rate": 2.8223774100500986e-05,
      "loss": 0.1988,
      "step": 1950
    },
    {
      "epoch": 0.3036283588887202,
      "grad_norm": 5.340306758880615,
      "learning_rate": 2.817822984666768e-05,
      "loss": 0.1653,
      "step": 2000
    },
    {
      "epoch": 0.3112190678609382,
      "grad_norm": 10.6412935256958,
      "learning_rate": 2.813268559283437e-05,
      "loss": 0.1674,
      "step": 2050
    },
    {
      "epoch": 0.3188097768331562,
      "grad_norm": 4.629552364349365,
      "learning_rate": 2.8087141339001064e-05,
      "loss": 0.173,
      "step": 2100
    },
    {
      "epoch": 0.32640048580537423,
      "grad_norm": 6.187066078186035,
      "learning_rate": 2.8041597085167755e-05,
      "loss": 0.1926,
      "step": 2150
    },
    {
      "epoch": 0.3339911947775922,
      "grad_norm": 15.405292510986328,
      "learning_rate": 2.799605283133445e-05,
      "loss": 0.2177,
      "step": 2200
    },
    {
      "epoch": 0.34158190374981023,
      "grad_norm": 0.07935415953397751,
      "learning_rate": 2.795050857750114e-05,
      "loss": 0.1662,
      "step": 2250
    },
    {
      "epoch": 0.34917261272202826,
      "grad_norm": 2.2039217948913574,
      "learning_rate": 2.790496432366783e-05,
      "loss": 0.166,
      "step": 2300
    },
    {
      "epoch": 0.35676332169424624,
      "grad_norm": 4.246438503265381,
      "learning_rate": 2.7859420069834523e-05,
      "loss": 0.1859,
      "step": 2350
    },
    {
      "epoch": 0.36435403066646427,
      "grad_norm": 7.52484655380249,
      "learning_rate": 2.7813875816001214e-05,
      "loss": 0.1137,
      "step": 2400
    },
    {
      "epoch": 0.37194473963868224,
      "grad_norm": 0.057591263204813004,
      "learning_rate": 2.7768331562167908e-05,
      "loss": 0.1837,
      "step": 2450
    },
    {
      "epoch": 0.3795354486109003,
      "grad_norm": 6.15707540512085,
      "learning_rate": 2.77227873083346e-05,
      "loss": 0.1995,
      "step": 2500
    },
    {
      "epoch": 0.38712615758311825,
      "grad_norm": 0.1518324464559555,
      "learning_rate": 2.7677243054501292e-05,
      "loss": 0.1486,
      "step": 2550
    },
    {
      "epoch": 0.3947168665553363,
      "grad_norm": 3.7846972942352295,
      "learning_rate": 2.7631698800667983e-05,
      "loss": 0.1217,
      "step": 2600
    },
    {
      "epoch": 0.40230757552755425,
      "grad_norm": 2.7060272693634033,
      "learning_rate": 2.7586154546834677e-05,
      "loss": 0.19,
      "step": 2650
    },
    {
      "epoch": 0.4098982844997723,
      "grad_norm": 3.5665600299835205,
      "learning_rate": 2.7540610293001367e-05,
      "loss": 0.2129,
      "step": 2700
    },
    {
      "epoch": 0.4174889934719903,
      "grad_norm": 4.859052658081055,
      "learning_rate": 2.7495066039168058e-05,
      "loss": 0.1487,
      "step": 2750
    },
    {
      "epoch": 0.4250797024442083,
      "grad_norm": 2.5820701122283936,
      "learning_rate": 2.7449521785334752e-05,
      "loss": 0.1675,
      "step": 2800
    },
    {
      "epoch": 0.4326704114164263,
      "grad_norm": 2.5533671379089355,
      "learning_rate": 2.7403977531501442e-05,
      "loss": 0.1518,
      "step": 2850
    },
    {
      "epoch": 0.4402611203886443,
      "grad_norm": 0.08833935856819153,
      "learning_rate": 2.7358433277668136e-05,
      "loss": 0.2083,
      "step": 2900
    },
    {
      "epoch": 0.4478518293608623,
      "grad_norm": 6.591603755950928,
      "learning_rate": 2.7312889023834827e-05,
      "loss": 0.2143,
      "step": 2950
    },
    {
      "epoch": 0.4554425383330803,
      "grad_norm": 0.009771411307156086,
      "learning_rate": 2.726734477000152e-05,
      "loss": 0.1301,
      "step": 3000
    },
    {
      "epoch": 0.4630332473052983,
      "grad_norm": 0.051289938390254974,
      "learning_rate": 2.722180051616821e-05,
      "loss": 0.1832,
      "step": 3050
    },
    {
      "epoch": 0.4706239562775163,
      "grad_norm": 0.4414966404438019,
      "learning_rate": 2.7176256262334905e-05,
      "loss": 0.1594,
      "step": 3100
    },
    {
      "epoch": 0.4782146652497343,
      "grad_norm": 4.096536636352539,
      "learning_rate": 2.7130712008501596e-05,
      "loss": 0.1846,
      "step": 3150
    },
    {
      "epoch": 0.48580537422195236,
      "grad_norm": 0.09732707589864731,
      "learning_rate": 2.7085167754668286e-05,
      "loss": 0.1981,
      "step": 3200
    },
    {
      "epoch": 0.49339608319417033,
      "grad_norm": 2.7816178798675537,
      "learning_rate": 2.703962350083498e-05,
      "loss": 0.2002,
      "step": 3250
    },
    {
      "epoch": 0.5009867921663883,
      "grad_norm": 0.054581593722105026,
      "learning_rate": 2.699407924700167e-05,
      "loss": 0.149,
      "step": 3300
    },
    {
      "epoch": 0.5085775011386063,
      "grad_norm": 0.06616917997598648,
      "learning_rate": 2.6948534993168365e-05,
      "loss": 0.1565,
      "step": 3350
    },
    {
      "epoch": 0.5161682101108244,
      "grad_norm": 4.897763252258301,
      "learning_rate": 2.6902990739335055e-05,
      "loss": 0.1867,
      "step": 3400
    },
    {
      "epoch": 0.5237589190830424,
      "grad_norm": 0.05512877553701401,
      "learning_rate": 2.685744648550175e-05,
      "loss": 0.1753,
      "step": 3450
    },
    {
      "epoch": 0.5313496280552603,
      "grad_norm": 4.49123477935791,
      "learning_rate": 2.681190223166844e-05,
      "loss": 0.1656,
      "step": 3500
    },
    {
      "epoch": 0.5389403370274783,
      "grad_norm": 4.8561882972717285,
      "learning_rate": 2.6766357977835133e-05,
      "loss": 0.1804,
      "step": 3550
    },
    {
      "epoch": 0.5465310459996964,
      "grad_norm": 5.232765197753906,
      "learning_rate": 2.6720813724001824e-05,
      "loss": 0.1828,
      "step": 3600
    },
    {
      "epoch": 0.5541217549719144,
      "grad_norm": 2.626970052719116,
      "learning_rate": 2.6675269470168514e-05,
      "loss": 0.1509,
      "step": 3650
    },
    {
      "epoch": 0.5617124639441324,
      "grad_norm": 0.07494815438985825,
      "learning_rate": 2.662972521633521e-05,
      "loss": 0.1718,
      "step": 3700
    },
    {
      "epoch": 0.5693031729163504,
      "grad_norm": 12.896800994873047,
      "learning_rate": 2.65841809625019e-05,
      "loss": 0.2187,
      "step": 3750
    },
    {
      "epoch": 0.5768938818885684,
      "grad_norm": 14.420843124389648,
      "learning_rate": 2.653863670866859e-05,
      "loss": 0.1825,
      "step": 3800
    },
    {
      "epoch": 0.5844845908607864,
      "grad_norm": 2.8592302799224854,
      "learning_rate": 2.649309245483528e-05,
      "loss": 0.1749,
      "step": 3850
    },
    {
      "epoch": 0.5920752998330044,
      "grad_norm": 0.3552565276622772,
      "learning_rate": 2.6447548201001974e-05,
      "loss": 0.2241,
      "step": 3900
    },
    {
      "epoch": 0.5996660088052224,
      "grad_norm": 4.725596904754639,
      "learning_rate": 2.6402003947168664e-05,
      "loss": 0.1778,
      "step": 3950
    },
    {
      "epoch": 0.6072567177774404,
      "grad_norm": 5.796738147735596,
      "learning_rate": 2.635645969333536e-05,
      "loss": 0.1556,
      "step": 4000
    },
    {
      "epoch": 0.6148474267496584,
      "grad_norm": 0.037575699388980865,
      "learning_rate": 2.631091543950205e-05,
      "loss": 0.1779,
      "step": 4050
    },
    {
      "epoch": 0.6224381357218765,
      "grad_norm": 0.016078758984804153,
      "learning_rate": 2.626537118566874e-05,
      "loss": 0.1549,
      "step": 4100
    },
    {
      "epoch": 0.6300288446940945,
      "grad_norm": 5.0050811767578125,
      "learning_rate": 2.6219826931835433e-05,
      "loss": 0.186,
      "step": 4150
    },
    {
      "epoch": 0.6376195536663124,
      "grad_norm": 0.04475501924753189,
      "learning_rate": 2.6174282678002124e-05,
      "loss": 0.1898,
      "step": 4200
    },
    {
      "epoch": 0.6452102626385304,
      "grad_norm": 0.011193038895726204,
      "learning_rate": 2.6128738424168818e-05,
      "loss": 0.1485,
      "step": 4250
    },
    {
      "epoch": 0.6528009716107485,
      "grad_norm": 0.6637229919433594,
      "learning_rate": 2.6083194170335508e-05,
      "loss": 0.1241,
      "step": 4300
    },
    {
      "epoch": 0.6603916805829665,
      "grad_norm": 0.03446582704782486,
      "learning_rate": 2.6037649916502202e-05,
      "loss": 0.1876,
      "step": 4350
    },
    {
      "epoch": 0.6679823895551844,
      "grad_norm": 11.771044731140137,
      "learning_rate": 2.5992105662668893e-05,
      "loss": 0.1402,
      "step": 4400
    },
    {
      "epoch": 0.6755730985274024,
      "grad_norm": 0.1943792700767517,
      "learning_rate": 2.5946561408835587e-05,
      "loss": 0.1493,
      "step": 4450
    },
    {
      "epoch": 0.6831638074996205,
      "grad_norm": 4.007392406463623,
      "learning_rate": 2.5901017155002277e-05,
      "loss": 0.1521,
      "step": 4500
    },
    {
      "epoch": 0.6907545164718385,
      "grad_norm": 0.04256526753306389,
      "learning_rate": 2.5855472901168968e-05,
      "loss": 0.1768,
      "step": 4550
    },
    {
      "epoch": 0.6983452254440565,
      "grad_norm": 7.30681848526001,
      "learning_rate": 2.580992864733566e-05,
      "loss": 0.1307,
      "step": 4600
    },
    {
      "epoch": 0.7059359344162744,
      "grad_norm": 12.261075019836426,
      "learning_rate": 2.5764384393502352e-05,
      "loss": 0.1524,
      "step": 4650
    },
    {
      "epoch": 0.7135266433884925,
      "grad_norm": 0.016289010643959045,
      "learning_rate": 2.5718840139669046e-05,
      "loss": 0.1037,
      "step": 4700
    },
    {
      "epoch": 0.7211173523607105,
      "grad_norm": 4.224881172180176,
      "learning_rate": 2.5673295885835737e-05,
      "loss": 0.2003,
      "step": 4750
    },
    {
      "epoch": 0.7287080613329285,
      "grad_norm": 5.196871280670166,
      "learning_rate": 2.562775163200243e-05,
      "loss": 0.1682,
      "step": 4800
    },
    {
      "epoch": 0.7362987703051465,
      "grad_norm": 0.16122682392597198,
      "learning_rate": 2.558220737816912e-05,
      "loss": 0.1396,
      "step": 4850
    },
    {
      "epoch": 0.7438894792773645,
      "grad_norm": 3.612950563430786,
      "learning_rate": 2.5536663124335815e-05,
      "loss": 0.116,
      "step": 4900
    },
    {
      "epoch": 0.7514801882495825,
      "grad_norm": 5.272387981414795,
      "learning_rate": 2.5491118870502506e-05,
      "loss": 0.0863,
      "step": 4950
    },
    {
      "epoch": 0.7590708972218005,
      "grad_norm": 5.89856481552124,
      "learning_rate": 2.5445574616669196e-05,
      "loss": 0.1717,
      "step": 5000
    },
    {
      "epoch": 0.7666616061940186,
      "grad_norm": 0.03417288139462471,
      "learning_rate": 2.540003036283589e-05,
      "loss": 0.1032,
      "step": 5050
    },
    {
      "epoch": 0.7742523151662365,
      "grad_norm": 0.17722366750240326,
      "learning_rate": 2.535448610900258e-05,
      "loss": 0.1703,
      "step": 5100
    },
    {
      "epoch": 0.7818430241384545,
      "grad_norm": 4.589255332946777,
      "learning_rate": 2.5308941855169274e-05,
      "loss": 0.1919,
      "step": 5150
    },
    {
      "epoch": 0.7894337331106726,
      "grad_norm": 6.199318885803223,
      "learning_rate": 2.5263397601335965e-05,
      "loss": 0.2026,
      "step": 5200
    },
    {
      "epoch": 0.7970244420828906,
      "grad_norm": 0.08511263877153397,
      "learning_rate": 2.521785334750266e-05,
      "loss": 0.1683,
      "step": 5250
    },
    {
      "epoch": 0.8046151510551085,
      "grad_norm": 0.009908787906169891,
      "learning_rate": 2.517230909366935e-05,
      "loss": 0.1915,
      "step": 5300
    },
    {
      "epoch": 0.8122058600273265,
      "grad_norm": 0.11079860478639603,
      "learning_rate": 2.5126764839836043e-05,
      "loss": 0.1732,
      "step": 5350
    },
    {
      "epoch": 0.8197965689995446,
      "grad_norm": 0.44461995363235474,
      "learning_rate": 2.5081220586002734e-05,
      "loss": 0.2376,
      "step": 5400
    },
    {
      "epoch": 0.8273872779717626,
      "grad_norm": 0.051283594220876694,
      "learning_rate": 2.5035676332169424e-05,
      "loss": 0.098,
      "step": 5450
    },
    {
      "epoch": 0.8349779869439806,
      "grad_norm": 25.729162216186523,
      "learning_rate": 2.4990132078336118e-05,
      "loss": 0.1407,
      "step": 5500
    },
    {
      "epoch": 0.8425686959161985,
      "grad_norm": 7.625317096710205,
      "learning_rate": 2.494458782450281e-05,
      "loss": 0.1592,
      "step": 5550
    },
    {
      "epoch": 0.8501594048884166,
      "grad_norm": 10.417091369628906,
      "learning_rate": 2.4899043570669503e-05,
      "loss": 0.16,
      "step": 5600
    },
    {
      "epoch": 0.8577501138606346,
      "grad_norm": 0.089413121342659,
      "learning_rate": 2.4853499316836193e-05,
      "loss": 0.1616,
      "step": 5650
    },
    {
      "epoch": 0.8653408228328526,
      "grad_norm": 14.831265449523926,
      "learning_rate": 2.4807955063002887e-05,
      "loss": 0.1982,
      "step": 5700
    },
    {
      "epoch": 0.8729315318050705,
      "grad_norm": 0.09910574555397034,
      "learning_rate": 2.4762410809169578e-05,
      "loss": 0.1641,
      "step": 5750
    },
    {
      "epoch": 0.8805222407772886,
      "grad_norm": 0.05554156377911568,
      "learning_rate": 2.471686655533627e-05,
      "loss": 0.1633,
      "step": 5800
    },
    {
      "epoch": 0.8881129497495066,
      "grad_norm": 0.11201748996973038,
      "learning_rate": 2.4671322301502962e-05,
      "loss": 0.1554,
      "step": 5850
    },
    {
      "epoch": 0.8957036587217246,
      "grad_norm": 5.413712978363037,
      "learning_rate": 2.4625778047669653e-05,
      "loss": 0.1357,
      "step": 5900
    },
    {
      "epoch": 0.9032943676939427,
      "grad_norm": 6.314820766448975,
      "learning_rate": 2.4580233793836347e-05,
      "loss": 0.1037,
      "step": 5950
    },
    {
      "epoch": 0.9108850766661606,
      "grad_norm": 0.03235161677002907,
      "learning_rate": 2.4534689540003037e-05,
      "loss": 0.1213,
      "step": 6000
    },
    {
      "epoch": 0.9184757856383786,
      "grad_norm": 0.35668236017227173,
      "learning_rate": 2.448914528616973e-05,
      "loss": 0.1573,
      "step": 6050
    },
    {
      "epoch": 0.9260664946105966,
      "grad_norm": 0.025385331362485886,
      "learning_rate": 2.444360103233642e-05,
      "loss": 0.093,
      "step": 6100
    },
    {
      "epoch": 0.9336572035828147,
      "grad_norm": 0.025202205404639244,
      "learning_rate": 2.4398056778503115e-05,
      "loss": 0.0883,
      "step": 6150
    },
    {
      "epoch": 0.9412479125550326,
      "grad_norm": 0.3691650331020355,
      "learning_rate": 2.4352512524669806e-05,
      "loss": 0.1175,
      "step": 6200
    },
    {
      "epoch": 0.9488386215272506,
      "grad_norm": 0.1549271047115326,
      "learning_rate": 2.4306968270836497e-05,
      "loss": 0.1775,
      "step": 6250
    },
    {
      "epoch": 0.9564293304994687,
      "grad_norm": 0.14324301481246948,
      "learning_rate": 2.4261424017003187e-05,
      "loss": 0.1987,
      "step": 6300
    },
    {
      "epoch": 0.9640200394716867,
      "grad_norm": 4.0795135498046875,
      "learning_rate": 2.4215879763169878e-05,
      "loss": 0.1643,
      "step": 6350
    },
    {
      "epoch": 0.9716107484439047,
      "grad_norm": 0.05272815376520157,
      "learning_rate": 2.417033550933657e-05,
      "loss": 0.1483,
      "step": 6400
    },
    {
      "epoch": 0.9792014574161226,
      "grad_norm": 0.24993325769901276,
      "learning_rate": 2.4124791255503262e-05,
      "loss": 0.1484,
      "step": 6450
    },
    {
      "epoch": 0.9867921663883407,
      "grad_norm": 2.0697224140167236,
      "learning_rate": 2.4079247001669956e-05,
      "loss": 0.1255,
      "step": 6500
    },
    {
      "epoch": 0.9943828753605587,
      "grad_norm": 14.77547836303711,
      "learning_rate": 2.4033702747836646e-05,
      "loss": 0.1616,
      "step": 6550
    },
    {
      "epoch": 1.0,
      "eval_runtime": 38.0756,
      "eval_samples_per_second": 702.523,
      "eval_steps_per_second": 43.913,
      "step": 6587
    },
    {
      "epoch": 1.0019735843327766,
      "grad_norm": 6.410021781921387,
      "learning_rate": 2.398815849400334e-05,
      "loss": 0.156,
      "step": 6600
    },
    {
      "epoch": 1.0095642933049946,
      "grad_norm": 4.8935160636901855,
      "learning_rate": 2.394261424017003e-05,
      "loss": 0.1356,
      "step": 6650
    },
    {
      "epoch": 1.0171550022772127,
      "grad_norm": 14.717199325561523,
      "learning_rate": 2.3897069986336725e-05,
      "loss": 0.1254,
      "step": 6700
    },
    {
      "epoch": 1.0247457112494307,
      "grad_norm": 1.7089195251464844,
      "learning_rate": 2.3851525732503415e-05,
      "loss": 0.1108,
      "step": 6750
    },
    {
      "epoch": 1.0323364202216487,
      "grad_norm": 2.4161314964294434,
      "learning_rate": 2.3805981478670106e-05,
      "loss": 0.1003,
      "step": 6800
    },
    {
      "epoch": 1.0399271291938668,
      "grad_norm": 0.009657520800828934,
      "learning_rate": 2.37604372248368e-05,
      "loss": 0.0988,
      "step": 6850
    },
    {
      "epoch": 1.0475178381660848,
      "grad_norm": 0.8473531603813171,
      "learning_rate": 2.371489297100349e-05,
      "loss": 0.1105,
      "step": 6900
    },
    {
      "epoch": 1.0551085471383028,
      "grad_norm": 0.031508058309555054,
      "learning_rate": 2.3669348717170184e-05,
      "loss": 0.1088,
      "step": 6950
    },
    {
      "epoch": 1.0626992561105206,
      "grad_norm": 9.410764694213867,
      "learning_rate": 2.3623804463336875e-05,
      "loss": 0.1177,
      "step": 7000
    },
    {
      "epoch": 1.0702899650827387,
      "grad_norm": 0.021808812394738197,
      "learning_rate": 2.357826020950357e-05,
      "loss": 0.1065,
      "step": 7050
    },
    {
      "epoch": 1.0778806740549567,
      "grad_norm": 0.00434934813529253,
      "learning_rate": 2.353271595567026e-05,
      "loss": 0.0436,
      "step": 7100
    },
    {
      "epoch": 1.0854713830271747,
      "grad_norm": 8.99357795715332,
      "learning_rate": 2.3487171701836953e-05,
      "loss": 0.0899,
      "step": 7150
    },
    {
      "epoch": 1.0930620919993927,
      "grad_norm": 0.01539010088890791,
      "learning_rate": 2.3441627448003644e-05,
      "loss": 0.1219,
      "step": 7200
    },
    {
      "epoch": 1.1006528009716108,
      "grad_norm": 0.017549367621541023,
      "learning_rate": 2.3396083194170334e-05,
      "loss": 0.1211,
      "step": 7250
    },
    {
      "epoch": 1.1082435099438288,
      "grad_norm": 2.239684820175171,
      "learning_rate": 2.3350538940337028e-05,
      "loss": 0.1074,
      "step": 7300
    },
    {
      "epoch": 1.1158342189160468,
      "grad_norm": 0.014737199060618877,
      "learning_rate": 2.330499468650372e-05,
      "loss": 0.0881,
      "step": 7350
    },
    {
      "epoch": 1.1234249278882649,
      "grad_norm": 0.026023371145129204,
      "learning_rate": 2.3259450432670413e-05,
      "loss": 0.1119,
      "step": 7400
    },
    {
      "epoch": 1.1310156368604827,
      "grad_norm": 5.8050432205200195,
      "learning_rate": 2.3213906178837103e-05,
      "loss": 0.141,
      "step": 7450
    },
    {
      "epoch": 1.1386063458327007,
      "grad_norm": 8.943338394165039,
      "learning_rate": 2.3168361925003797e-05,
      "loss": 0.1369,
      "step": 7500
    },
    {
      "epoch": 1.1461970548049187,
      "grad_norm": 0.4082181453704834,
      "learning_rate": 2.3122817671170488e-05,
      "loss": 0.1323,
      "step": 7550
    },
    {
      "epoch": 1.1537877637771368,
      "grad_norm": 8.209169387817383,
      "learning_rate": 2.307727341733718e-05,
      "loss": 0.0895,
      "step": 7600
    },
    {
      "epoch": 1.1613784727493548,
      "grad_norm": 0.044543519616127014,
      "learning_rate": 2.3031729163503872e-05,
      "loss": 0.1123,
      "step": 7650
    },
    {
      "epoch": 1.1689691817215728,
      "grad_norm": 11.047051429748535,
      "learning_rate": 2.2986184909670563e-05,
      "loss": 0.1008,
      "step": 7700
    },
    {
      "epoch": 1.1765598906937909,
      "grad_norm": 2.6620888710021973,
      "learning_rate": 2.2940640655837256e-05,
      "loss": 0.096,
      "step": 7750
    },
    {
      "epoch": 1.1841505996660089,
      "grad_norm": 0.6505450010299683,
      "learning_rate": 2.2895096402003947e-05,
      "loss": 0.135,
      "step": 7800
    },
    {
      "epoch": 1.191741308638227,
      "grad_norm": 1.8489999771118164,
      "learning_rate": 2.284955214817064e-05,
      "loss": 0.0943,
      "step": 7850
    },
    {
      "epoch": 1.1993320176104447,
      "grad_norm": 0.006122444290667772,
      "learning_rate": 2.280400789433733e-05,
      "loss": 0.0736,
      "step": 7900
    },
    {
      "epoch": 1.2069227265826628,
      "grad_norm": 1.2961082458496094,
      "learning_rate": 2.2758463640504025e-05,
      "loss": 0.0832,
      "step": 7950
    },
    {
      "epoch": 1.2145134355548808,
      "grad_norm": 4.393985748291016,
      "learning_rate": 2.2712919386670716e-05,
      "loss": 0.1227,
      "step": 8000
    },
    {
      "epoch": 1.2221041445270988,
      "grad_norm": 0.028961336240172386,
      "learning_rate": 2.266737513283741e-05,
      "loss": 0.0751,
      "step": 8050
    },
    {
      "epoch": 1.2296948534993168,
      "grad_norm": 0.010072540491819382,
      "learning_rate": 2.26218308790041e-05,
      "loss": 0.1034,
      "step": 8100
    },
    {
      "epoch": 1.2372855624715349,
      "grad_norm": 0.09305309504270554,
      "learning_rate": 2.257628662517079e-05,
      "loss": 0.0646,
      "step": 8150
    },
    {
      "epoch": 1.244876271443753,
      "grad_norm": 0.044270291924476624,
      "learning_rate": 2.2530742371337485e-05,
      "loss": 0.0807,
      "step": 8200
    },
    {
      "epoch": 1.252466980415971,
      "grad_norm": 0.036894310265779495,
      "learning_rate": 2.2485198117504175e-05,
      "loss": 0.1203,
      "step": 8250
    },
    {
      "epoch": 1.260057689388189,
      "grad_norm": 9.033699989318848,
      "learning_rate": 2.243965386367087e-05,
      "loss": 0.0876,
      "step": 8300
    },
    {
      "epoch": 1.2676483983604068,
      "grad_norm": 3.7835209369659424,
      "learning_rate": 2.239410960983756e-05,
      "loss": 0.1112,
      "step": 8350
    },
    {
      "epoch": 1.2752391073326248,
      "grad_norm": 10.011475563049316,
      "learning_rate": 2.2348565356004254e-05,
      "loss": 0.1494,
      "step": 8400
    },
    {
      "epoch": 1.2828298163048428,
      "grad_norm": 0.01807199791073799,
      "learning_rate": 2.2303021102170944e-05,
      "loss": 0.077,
      "step": 8450
    },
    {
      "epoch": 1.2904205252770609,
      "grad_norm": 12.205936431884766,
      "learning_rate": 2.2257476848337638e-05,
      "loss": 0.0923,
      "step": 8500
    },
    {
      "epoch": 1.298011234249279,
      "grad_norm": 5.5583930015563965,
      "learning_rate": 2.221193259450433e-05,
      "loss": 0.1019,
      "step": 8550
    },
    {
      "epoch": 1.305601943221497,
      "grad_norm": 0.2173692286014557,
      "learning_rate": 2.216638834067102e-05,
      "loss": 0.0721,
      "step": 8600
    },
    {
      "epoch": 1.313192652193715,
      "grad_norm": 2.0627920627593994,
      "learning_rate": 2.2120844086837713e-05,
      "loss": 0.0991,
      "step": 8650
    },
    {
      "epoch": 1.320783361165933,
      "grad_norm": 0.05124980956315994,
      "learning_rate": 2.2075299833004404e-05,
      "loss": 0.0947,
      "step": 8700
    },
    {
      "epoch": 1.328374070138151,
      "grad_norm": 0.01869847998023033,
      "learning_rate": 2.2029755579171094e-05,
      "loss": 0.1331,
      "step": 8750
    },
    {
      "epoch": 1.3359647791103688,
      "grad_norm": 0.03299663960933685,
      "learning_rate": 2.1984211325337785e-05,
      "loss": 0.1029,
      "step": 8800
    },
    {
      "epoch": 1.3435554880825868,
      "grad_norm": 0.006164370104670525,
      "learning_rate": 2.193866707150448e-05,
      "loss": 0.0592,
      "step": 8850
    },
    {
      "epoch": 1.3511461970548049,
      "grad_norm": 2.0010249614715576,
      "learning_rate": 2.189312281767117e-05,
      "loss": 0.0816,
      "step": 8900
    },
    {
      "epoch": 1.358736906027023,
      "grad_norm": 0.05386369675397873,
      "learning_rate": 2.1847578563837863e-05,
      "loss": 0.1179,
      "step": 8950
    },
    {
      "epoch": 1.366327614999241,
      "grad_norm": 0.1446322202682495,
      "learning_rate": 2.1802034310004554e-05,
      "loss": 0.1074,
      "step": 9000
    },
    {
      "epoch": 1.373918323971459,
      "grad_norm": 4.581583499908447,
      "learning_rate": 2.1756490056171244e-05,
      "loss": 0.0958,
      "step": 9050
    },
    {
      "epoch": 1.381509032943677,
      "grad_norm": 0.09513495862483978,
      "learning_rate": 2.1710945802337938e-05,
      "loss": 0.075,
      "step": 9100
    },
    {
      "epoch": 1.389099741915895,
      "grad_norm": 0.2268090546131134,
      "learning_rate": 2.166540154850463e-05,
      "loss": 0.0891,
      "step": 9150
    },
    {
      "epoch": 1.396690450888113,
      "grad_norm": 0.07496143132448196,
      "learning_rate": 2.1619857294671323e-05,
      "loss": 0.0862,
      "step": 9200
    },
    {
      "epoch": 1.4042811598603309,
      "grad_norm": 0.7866777777671814,
      "learning_rate": 2.1574313040838013e-05,
      "loss": 0.0943,
      "step": 9250
    },
    {
      "epoch": 1.411871868832549,
      "grad_norm": 7.751572132110596,
      "learning_rate": 2.1528768787004707e-05,
      "loss": 0.1055,
      "step": 9300
    },
    {
      "epoch": 1.419462577804767,
      "grad_norm": 20.037389755249023,
      "learning_rate": 2.1483224533171397e-05,
      "loss": 0.101,
      "step": 9350
    },
    {
      "epoch": 1.427053286776985,
      "grad_norm": 0.1049342155456543,
      "learning_rate": 2.143768027933809e-05,
      "loss": 0.0814,
      "step": 9400
    },
    {
      "epoch": 1.434643995749203,
      "grad_norm": 2.3805925846099854,
      "learning_rate": 2.1392136025504782e-05,
      "loss": 0.1533,
      "step": 9450
    },
    {
      "epoch": 1.442234704721421,
      "grad_norm": 0.14459849894046783,
      "learning_rate": 2.1346591771671472e-05,
      "loss": 0.101,
      "step": 9500
    },
    {
      "epoch": 1.449825413693639,
      "grad_norm": 4.472272872924805,
      "learning_rate": 2.1301047517838166e-05,
      "loss": 0.0999,
      "step": 9550
    },
    {
      "epoch": 1.457416122665857,
      "grad_norm": 2.0551159381866455,
      "learning_rate": 2.1255503264004857e-05,
      "loss": 0.0794,
      "step": 9600
    },
    {
      "epoch": 1.465006831638075,
      "grad_norm": 15.399116516113281,
      "learning_rate": 2.120995901017155e-05,
      "loss": 0.0831,
      "step": 9650
    },
    {
      "epoch": 1.472597540610293,
      "grad_norm": 7.620377063751221,
      "learning_rate": 2.116441475633824e-05,
      "loss": 0.1139,
      "step": 9700
    },
    {
      "epoch": 1.480188249582511,
      "grad_norm": 0.02330877259373665,
      "learning_rate": 2.1118870502504935e-05,
      "loss": 0.0722,
      "step": 9750
    },
    {
      "epoch": 1.487778958554729,
      "grad_norm": 6.95189094543457,
      "learning_rate": 2.1073326248671626e-05,
      "loss": 0.0801,
      "step": 9800
    },
    {
      "epoch": 1.495369667526947,
      "grad_norm": 8.388599395751953,
      "learning_rate": 2.102778199483832e-05,
      "loss": 0.1263,
      "step": 9850
    },
    {
      "epoch": 1.502960376499165,
      "grad_norm": 4.646027565002441,
      "learning_rate": 2.098223774100501e-05,
      "loss": 0.0759,
      "step": 9900
    },
    {
      "epoch": 1.510551085471383,
      "grad_norm": 0.2993217706680298,
      "learning_rate": 2.09366934871717e-05,
      "loss": 0.1016,
      "step": 9950
    },
    {
      "epoch": 1.518141794443601,
      "grad_norm": 8.981534957885742,
      "learning_rate": 2.0891149233338395e-05,
      "loss": 0.113,
      "step": 10000
    },
    {
      "epoch": 1.525732503415819,
      "grad_norm": 0.014347665011882782,
      "learning_rate": 2.0845604979505085e-05,
      "loss": 0.0996,
      "step": 10050
    },
    {
      "epoch": 1.5333232123880371,
      "grad_norm": 0.045733626931905746,
      "learning_rate": 2.080006072567178e-05,
      "loss": 0.0932,
      "step": 10100
    },
    {
      "epoch": 1.540913921360255,
      "grad_norm": 0.03722027316689491,
      "learning_rate": 2.075451647183847e-05,
      "loss": 0.0869,
      "step": 10150
    },
    {
      "epoch": 1.5485046303324732,
      "grad_norm": 0.03521658852696419,
      "learning_rate": 2.0708972218005164e-05,
      "loss": 0.1188,
      "step": 10200
    },
    {
      "epoch": 1.556095339304691,
      "grad_norm": 0.01612371951341629,
      "learning_rate": 2.0663427964171854e-05,
      "loss": 0.1439,
      "step": 10250
    },
    {
      "epoch": 1.563686048276909,
      "grad_norm": 0.9872256517410278,
      "learning_rate": 2.0617883710338548e-05,
      "loss": 0.0943,
      "step": 10300
    },
    {
      "epoch": 1.571276757249127,
      "grad_norm": 0.30184221267700195,
      "learning_rate": 2.057233945650524e-05,
      "loss": 0.1255,
      "step": 10350
    },
    {
      "epoch": 1.578867466221345,
      "grad_norm": 18.42599868774414,
      "learning_rate": 2.052679520267193e-05,
      "loss": 0.1169,
      "step": 10400
    },
    {
      "epoch": 1.5864581751935631,
      "grad_norm": 11.464556694030762,
      "learning_rate": 2.0481250948838623e-05,
      "loss": 0.0897,
      "step": 10450
    },
    {
      "epoch": 1.594048884165781,
      "grad_norm": 0.09058916568756104,
      "learning_rate": 2.0435706695005314e-05,
      "loss": 0.09,
      "step": 10500
    },
    {
      "epoch": 1.6016395931379992,
      "grad_norm": 0.007839668542146683,
      "learning_rate": 2.0390162441172007e-05,
      "loss": 0.1055,
      "step": 10550
    },
    {
      "epoch": 1.609230302110217,
      "grad_norm": 12.488269805908203,
      "learning_rate": 2.0344618187338698e-05,
      "loss": 0.1013,
      "step": 10600
    },
    {
      "epoch": 1.6168210110824353,
      "grad_norm": 0.22150495648384094,
      "learning_rate": 2.0299073933505392e-05,
      "loss": 0.1095,
      "step": 10650
    },
    {
      "epoch": 1.624411720054653,
      "grad_norm": 0.23668943345546722,
      "learning_rate": 2.0253529679672082e-05,
      "loss": 0.1181,
      "step": 10700
    },
    {
      "epoch": 1.632002429026871,
      "grad_norm": 0.014803498983383179,
      "learning_rate": 2.0207985425838776e-05,
      "loss": 0.0946,
      "step": 10750
    },
    {
      "epoch": 1.6395931379990891,
      "grad_norm": 3.6515438556671143,
      "learning_rate": 2.0162441172005467e-05,
      "loss": 0.0851,
      "step": 10800
    },
    {
      "epoch": 1.6471838469713072,
      "grad_norm": 0.47882336378097534,
      "learning_rate": 2.0116896918172157e-05,
      "loss": 0.1389,
      "step": 10850
    },
    {
      "epoch": 1.6547745559435252,
      "grad_norm": 1.1482408046722412,
      "learning_rate": 2.007135266433885e-05,
      "loss": 0.119,
      "step": 10900
    },
    {
      "epoch": 1.662365264915743,
      "grad_norm": 0.01974923349916935,
      "learning_rate": 2.0025808410505542e-05,
      "loss": 0.1304,
      "step": 10950
    },
    {
      "epoch": 1.6699559738879612,
      "grad_norm": 1.352579951286316,
      "learning_rate": 1.9980264156672236e-05,
      "loss": 0.0656,
      "step": 11000
    },
    {
      "epoch": 1.677546682860179,
      "grad_norm": 0.29193469882011414,
      "learning_rate": 1.9934719902838926e-05,
      "loss": 0.0601,
      "step": 11050
    },
    {
      "epoch": 1.6851373918323973,
      "grad_norm": 8.176802635192871,
      "learning_rate": 1.988917564900562e-05,
      "loss": 0.1557,
      "step": 11100
    },
    {
      "epoch": 1.692728100804615,
      "grad_norm": 0.09518291056156158,
      "learning_rate": 1.984363139517231e-05,
      "loss": 0.1114,
      "step": 11150
    },
    {
      "epoch": 1.7003188097768331,
      "grad_norm": 2.5128250122070312,
      "learning_rate": 1.9798087141339005e-05,
      "loss": 0.0509,
      "step": 11200
    },
    {
      "epoch": 1.7079095187490512,
      "grad_norm": 7.3730950355529785,
      "learning_rate": 1.9752542887505692e-05,
      "loss": 0.1001,
      "step": 11250
    },
    {
      "epoch": 1.7155002277212692,
      "grad_norm": 0.1322927474975586,
      "learning_rate": 1.9706998633672382e-05,
      "loss": 0.0899,
      "step": 11300
    },
    {
      "epoch": 1.7230909366934872,
      "grad_norm": 8.861368179321289,
      "learning_rate": 1.9661454379839076e-05,
      "loss": 0.1294,
      "step": 11350
    },
    {
      "epoch": 1.730681645665705,
      "grad_norm": 16.513168334960938,
      "learning_rate": 1.9615910126005767e-05,
      "loss": 0.0836,
      "step": 11400
    },
    {
      "epoch": 1.7382723546379233,
      "grad_norm": 5.810540676116943,
      "learning_rate": 1.957036587217246e-05,
      "loss": 0.0896,
      "step": 11450
    },
    {
      "epoch": 1.745863063610141,
      "grad_norm": 25.54034423828125,
      "learning_rate": 1.952482161833915e-05,
      "loss": 0.1001,
      "step": 11500
    },
    {
      "epoch": 1.7534537725823593,
      "grad_norm": 4.723233222961426,
      "learning_rate": 1.9479277364505845e-05,
      "loss": 0.1457,
      "step": 11550
    },
    {
      "epoch": 1.7610444815545772,
      "grad_norm": 0.007088135462254286,
      "learning_rate": 1.9433733110672536e-05,
      "loss": 0.127,
      "step": 11600
    },
    {
      "epoch": 1.7686351905267952,
      "grad_norm": 8.116147994995117,
      "learning_rate": 1.938818885683923e-05,
      "loss": 0.0995,
      "step": 11650
    },
    {
      "epoch": 1.7762258994990132,
      "grad_norm": 0.6514536738395691,
      "learning_rate": 1.934264460300592e-05,
      "loss": 0.1038,
      "step": 11700
    },
    {
      "epoch": 1.7838166084712312,
      "grad_norm": 11.930383682250977,
      "learning_rate": 1.929710034917261e-05,
      "loss": 0.068,
      "step": 11750
    },
    {
      "epoch": 1.7914073174434493,
      "grad_norm": 8.1942777633667,
      "learning_rate": 1.9251556095339305e-05,
      "loss": 0.0682,
      "step": 11800
    },
    {
      "epoch": 1.798998026415667,
      "grad_norm": 0.07120682299137115,
      "learning_rate": 1.9206011841505995e-05,
      "loss": 0.1043,
      "step": 11850
    },
    {
      "epoch": 1.8065887353878853,
      "grad_norm": 0.02671733871102333,
      "learning_rate": 1.916046758767269e-05,
      "loss": 0.1132,
      "step": 11900
    },
    {
      "epoch": 1.8141794443601031,
      "grad_norm": 0.18410895764827728,
      "learning_rate": 1.911492333383938e-05,
      "loss": 0.132,
      "step": 11950
    },
    {
      "epoch": 1.8217701533323214,
      "grad_norm": 23.116098403930664,
      "learning_rate": 1.9069379080006073e-05,
      "loss": 0.1125,
      "step": 12000
    },
    {
      "epoch": 1.8293608623045392,
      "grad_norm": 5.898257732391357,
      "learning_rate": 1.9023834826172764e-05,
      "loss": 0.1023,
      "step": 12050
    },
    {
      "epoch": 1.8369515712767572,
      "grad_norm": 9.635226249694824,
      "learning_rate": 1.8978290572339458e-05,
      "loss": 0.0717,
      "step": 12100
    },
    {
      "epoch": 1.8445422802489753,
      "grad_norm": 0.03923911601305008,
      "learning_rate": 1.893274631850615e-05,
      "loss": 0.0895,
      "step": 12150
    },
    {
      "epoch": 1.8521329892211933,
      "grad_norm": 0.0053503564558923244,
      "learning_rate": 1.888720206467284e-05,
      "loss": 0.0961,
      "step": 12200
    },
    {
      "epoch": 1.8597236981934113,
      "grad_norm": 0.24922706186771393,
      "learning_rate": 1.8841657810839533e-05,
      "loss": 0.1394,
      "step": 12250
    },
    {
      "epoch": 1.8673144071656291,
      "grad_norm": 8.145780563354492,
      "learning_rate": 1.8796113557006223e-05,
      "loss": 0.1097,
      "step": 12300
    },
    {
      "epoch": 1.8749051161378474,
      "grad_norm": 0.024109479039907455,
      "learning_rate": 1.8750569303172917e-05,
      "loss": 0.0637,
      "step": 12350
    },
    {
      "epoch": 1.8824958251100652,
      "grad_norm": 1.3381842374801636,
      "learning_rate": 1.8705025049339608e-05,
      "loss": 0.1095,
      "step": 12400
    },
    {
      "epoch": 1.8900865340822834,
      "grad_norm": 5.975992679595947,
      "learning_rate": 1.8659480795506302e-05,
      "loss": 0.0631,
      "step": 12450
    },
    {
      "epoch": 1.8976772430545013,
      "grad_norm": 0.015345520339906216,
      "learning_rate": 1.8613936541672992e-05,
      "loss": 0.1142,
      "step": 12500
    },
    {
      "epoch": 1.9052679520267193,
      "grad_norm": 1.91029691696167,
      "learning_rate": 1.8568392287839686e-05,
      "loss": 0.1027,
      "step": 12550
    },
    {
      "epoch": 1.9128586609989373,
      "grad_norm": 0.011335204355418682,
      "learning_rate": 1.8522848034006377e-05,
      "loss": 0.0845,
      "step": 12600
    },
    {
      "epoch": 1.9204493699711553,
      "grad_norm": 22.576936721801758,
      "learning_rate": 1.8477303780173067e-05,
      "loss": 0.0887,
      "step": 12650
    },
    {
      "epoch": 1.9280400789433734,
      "grad_norm": 0.05464579164981842,
      "learning_rate": 1.843175952633976e-05,
      "loss": 0.0739,
      "step": 12700
    },
    {
      "epoch": 1.9356307879155912,
      "grad_norm": 0.022499142214655876,
      "learning_rate": 1.8386215272506452e-05,
      "loss": 0.0531,
      "step": 12750
    },
    {
      "epoch": 1.9432214968878094,
      "grad_norm": 0.026879874989390373,
      "learning_rate": 1.8340671018673146e-05,
      "loss": 0.0829,
      "step": 12800
    },
    {
      "epoch": 1.9508122058600272,
      "grad_norm": 0.10080689191818237,
      "learning_rate": 1.8295126764839836e-05,
      "loss": 0.0882,
      "step": 12850
    },
    {
      "epoch": 1.9584029148322455,
      "grad_norm": 8.253646850585938,
      "learning_rate": 1.824958251100653e-05,
      "loss": 0.1047,
      "step": 12900
    },
    {
      "epoch": 1.9659936238044633,
      "grad_norm": 1.6679154634475708,
      "learning_rate": 1.820403825717322e-05,
      "loss": 0.1306,
      "step": 12950
    },
    {
      "epoch": 1.9735843327766813,
      "grad_norm": 3.2338335514068604,
      "learning_rate": 1.8158494003339915e-05,
      "loss": 0.0618,
      "step": 13000
    },
    {
      "epoch": 1.9811750417488994,
      "grad_norm": 11.550454139709473,
      "learning_rate": 1.8112949749506605e-05,
      "loss": 0.0919,
      "step": 13050
    },
    {
      "epoch": 1.9887657507211174,
      "grad_norm": 13.99939250946045,
      "learning_rate": 1.8067405495673296e-05,
      "loss": 0.1439,
      "step": 13100
    },
    {
      "epoch": 1.9963564596933354,
      "grad_norm": 0.010370914824306965,
      "learning_rate": 1.802186124183999e-05,
      "loss": 0.0862,
      "step": 13150
    },
    {
      "epoch": 2.0,
      "eval_runtime": 38.0556,
      "eval_samples_per_second": 702.892,
      "eval_steps_per_second": 43.936,
      "step": 13174
    },
    {
      "epoch": 2.0039471686655532,
      "grad_norm": 0.22136624157428741,
      "learning_rate": 1.797631698800668e-05,
      "loss": 0.06,
      "step": 13200
    },
    {
      "epoch": 2.0115378776377715,
      "grad_norm": 7.611391067504883,
      "learning_rate": 1.7930772734173374e-05,
      "loss": 0.0234,
      "step": 13250
    },
    {
      "epoch": 2.0191285866099893,
      "grad_norm": 2.723944664001465,
      "learning_rate": 1.7885228480340065e-05,
      "loss": 0.0476,
      "step": 13300
    },
    {
      "epoch": 2.0267192955822075,
      "grad_norm": 0.002538116183131933,
      "learning_rate": 1.783968422650676e-05,
      "loss": 0.0436,
      "step": 13350
    },
    {
      "epoch": 2.0343100045544253,
      "grad_norm": 0.007489852141588926,
      "learning_rate": 1.779413997267345e-05,
      "loss": 0.0105,
      "step": 13400
    },
    {
      "epoch": 2.0419007135266436,
      "grad_norm": 0.012889621779322624,
      "learning_rate": 1.7748595718840143e-05,
      "loss": 0.0556,
      "step": 13450
    },
    {
      "epoch": 2.0494914224988614,
      "grad_norm": 0.0024003467988222837,
      "learning_rate": 1.7703051465006833e-05,
      "loss": 0.0551,
      "step": 13500
    },
    {
      "epoch": 2.057082131471079,
      "grad_norm": 12.532286643981934,
      "learning_rate": 1.7657507211173524e-05,
      "loss": 0.0608,
      "step": 13550
    },
    {
      "epoch": 2.0646728404432975,
      "grad_norm": 0.1301240772008896,
      "learning_rate": 1.7611962957340218e-05,
      "loss": 0.0603,
      "step": 13600
    },
    {
      "epoch": 2.0722635494155153,
      "grad_norm": 7.506495952606201,
      "learning_rate": 1.756641870350691e-05,
      "loss": 0.0686,
      "step": 13650
    },
    {
      "epoch": 2.0798542583877335,
      "grad_norm": 0.005076700821518898,
      "learning_rate": 1.7520874449673602e-05,
      "loss": 0.0615,
      "step": 13700
    },
    {
      "epoch": 2.0874449673599513,
      "grad_norm": 2.2629692554473877,
      "learning_rate": 1.747533019584029e-05,
      "loss": 0.078,
      "step": 13750
    },
    {
      "epoch": 2.0950356763321696,
      "grad_norm": 0.5276634693145752,
      "learning_rate": 1.7429785942006983e-05,
      "loss": 0.0259,
      "step": 13800
    },
    {
      "epoch": 2.1026263853043874,
      "grad_norm": 25.792259216308594,
      "learning_rate": 1.7384241688173674e-05,
      "loss": 0.0815,
      "step": 13850
    },
    {
      "epoch": 2.1102170942766056,
      "grad_norm": 10.094088554382324,
      "learning_rate": 1.7338697434340368e-05,
      "loss": 0.0549,
      "step": 13900
    },
    {
      "epoch": 2.1178078032488235,
      "grad_norm": 0.03171536698937416,
      "learning_rate": 1.729315318050706e-05,
      "loss": 0.0688,
      "step": 13950
    },
    {
      "epoch": 2.1253985122210413,
      "grad_norm": 0.004046436864882708,
      "learning_rate": 1.724760892667375e-05,
      "loss": 0.0478,
      "step": 14000
    },
    {
      "epoch": 2.1329892211932595,
      "grad_norm": 0.04553778097033501,
      "learning_rate": 1.7202064672840443e-05,
      "loss": 0.0329,
      "step": 14050
    },
    {
      "epoch": 2.1405799301654773,
      "grad_norm": 1.0247364044189453,
      "learning_rate": 1.7156520419007133e-05,
      "loss": 0.0623,
      "step": 14100
    },
    {
      "epoch": 2.1481706391376956,
      "grad_norm": 11.405193328857422,
      "learning_rate": 1.7110976165173827e-05,
      "loss": 0.081,
      "step": 14150
    },
    {
      "epoch": 2.1557613481099134,
      "grad_norm": 0.011828501708805561,
      "learning_rate": 1.7065431911340518e-05,
      "loss": 0.0758,
      "step": 14200
    },
    {
      "epoch": 2.1633520570821316,
      "grad_norm": 0.015151115134358406,
      "learning_rate": 1.701988765750721e-05,
      "loss": 0.0628,
      "step": 14250
    },
    {
      "epoch": 2.1709427660543494,
      "grad_norm": 11.2518310546875,
      "learning_rate": 1.6974343403673902e-05,
      "loss": 0.0456,
      "step": 14300
    },
    {
      "epoch": 2.1785334750265677,
      "grad_norm": 0.2631201148033142,
      "learning_rate": 1.6928799149840596e-05,
      "loss": 0.0429,
      "step": 14350
    },
    {
      "epoch": 2.1861241839987855,
      "grad_norm": 0.3433937430381775,
      "learning_rate": 1.6883254896007287e-05,
      "loss": 0.0188,
      "step": 14400
    },
    {
      "epoch": 2.1937148929710033,
      "grad_norm": 0.002763807773590088,
      "learning_rate": 1.6837710642173977e-05,
      "loss": 0.0913,
      "step": 14450
    },
    {
      "epoch": 2.2013056019432216,
      "grad_norm": 5.78828763961792,
      "learning_rate": 1.679216638834067e-05,
      "loss": 0.0396,
      "step": 14500
    },
    {
      "epoch": 2.2088963109154394,
      "grad_norm": 0.0023880533408373594,
      "learning_rate": 1.674662213450736e-05,
      "loss": 0.0606,
      "step": 14550
    },
    {
      "epoch": 2.2164870198876576,
      "grad_norm": 0.04126410558819771,
      "learning_rate": 1.6701077880674056e-05,
      "loss": 0.0726,
      "step": 14600
    },
    {
      "epoch": 2.2240777288598754,
      "grad_norm": 0.003566751955077052,
      "learning_rate": 1.6655533626840746e-05,
      "loss": 0.0599,
      "step": 14650
    },
    {
      "epoch": 2.2316684378320937,
      "grad_norm": 1.4182175397872925,
      "learning_rate": 1.660998937300744e-05,
      "loss": 0.0359,
      "step": 14700
    },
    {
      "epoch": 2.2392591468043115,
      "grad_norm": 0.08601231873035431,
      "learning_rate": 1.656444511917413e-05,
      "loss": 0.0644,
      "step": 14750
    },
    {
      "epoch": 2.2468498557765297,
      "grad_norm": 0.04346853494644165,
      "learning_rate": 1.6518900865340824e-05,
      "loss": 0.0956,
      "step": 14800
    },
    {
      "epoch": 2.2544405647487475,
      "grad_norm": 0.23540553450584412,
      "learning_rate": 1.6473356611507515e-05,
      "loss": 0.0568,
      "step": 14850
    },
    {
      "epoch": 2.2620312737209654,
      "grad_norm": 0.03795263171195984,
      "learning_rate": 1.6427812357674206e-05,
      "loss": 0.0859,
      "step": 14900
    },
    {
      "epoch": 2.2696219826931836,
      "grad_norm": 0.002829305361956358,
      "learning_rate": 1.63822681038409e-05,
      "loss": 0.0488,
      "step": 14950
    },
    {
      "epoch": 2.2772126916654014,
      "grad_norm": 8.382412910461426,
      "learning_rate": 1.633672385000759e-05,
      "loss": 0.0822,
      "step": 15000
    },
    {
      "epoch": 2.2848034006376197,
      "grad_norm": 0.007595268543809652,
      "learning_rate": 1.6291179596174284e-05,
      "loss": 0.0572,
      "step": 15050
    },
    {
      "epoch": 2.2923941096098375,
      "grad_norm": 3.4331209659576416,
      "learning_rate": 1.6245635342340974e-05,
      "loss": 0.0666,
      "step": 15100
    },
    {
      "epoch": 2.2999848185820557,
      "grad_norm": 9.854687690734863,
      "learning_rate": 1.620009108850767e-05,
      "loss": 0.0725,
      "step": 15150
    },
    {
      "epoch": 2.3075755275542735,
      "grad_norm": 0.0019474343862384558,
      "learning_rate": 1.615454683467436e-05,
      "loss": 0.0539,
      "step": 15200
    },
    {
      "epoch": 2.3151662365264913,
      "grad_norm": 8.097280502319336,
      "learning_rate": 1.6109002580841053e-05,
      "loss": 0.0452,
      "step": 15250
    },
    {
      "epoch": 2.3227569454987096,
      "grad_norm": 0.10348743200302124,
      "learning_rate": 1.6063458327007743e-05,
      "loss": 0.0774,
      "step": 15300
    },
    {
      "epoch": 2.3303476544709274,
      "grad_norm": 0.0023538055829703808,
      "learning_rate": 1.6017914073174434e-05,
      "loss": 0.0228,
      "step": 15350
    },
    {
      "epoch": 2.3379383634431457,
      "grad_norm": 0.0025943682994693518,
      "learning_rate": 1.5972369819341128e-05,
      "loss": 0.0443,
      "step": 15400
    },
    {
      "epoch": 2.3455290724153635,
      "grad_norm": 0.03153310716152191,
      "learning_rate": 1.5926825565507818e-05,
      "loss": 0.059,
      "step": 15450
    },
    {
      "epoch": 2.3531197813875817,
      "grad_norm": 0.006459516007453203,
      "learning_rate": 1.5881281311674512e-05,
      "loss": 0.0349,
      "step": 15500
    },
    {
      "epoch": 2.3607104903597995,
      "grad_norm": 0.043393779546022415,
      "learning_rate": 1.5835737057841203e-05,
      "loss": 0.0499,
      "step": 15550
    },
    {
      "epoch": 2.3683011993320178,
      "grad_norm": 0.03301906958222389,
      "learning_rate": 1.5790192804007897e-05,
      "loss": 0.0571,
      "step": 15600
    },
    {
      "epoch": 2.3758919083042356,
      "grad_norm": 9.447141647338867,
      "learning_rate": 1.5744648550174587e-05,
      "loss": 0.0449,
      "step": 15650
    },
    {
      "epoch": 2.383482617276454,
      "grad_norm": 0.0021868920885026455,
      "learning_rate": 1.569910429634128e-05,
      "loss": 0.0278,
      "step": 15700
    },
    {
      "epoch": 2.3910733262486716,
      "grad_norm": 5.172336101531982,
      "learning_rate": 1.565356004250797e-05,
      "loss": 0.0753,
      "step": 15750
    },
    {
      "epoch": 2.3986640352208894,
      "grad_norm": 0.002149307867512107,
      "learning_rate": 1.5608015788674662e-05,
      "loss": 0.0515,
      "step": 15800
    },
    {
      "epoch": 2.4062547441931077,
      "grad_norm": 0.002291748533025384,
      "learning_rate": 1.5562471534841356e-05,
      "loss": 0.0728,
      "step": 15850
    },
    {
      "epoch": 2.4138454531653255,
      "grad_norm": 15.331686973571777,
      "learning_rate": 1.5516927281008047e-05,
      "loss": 0.0498,
      "step": 15900
    },
    {
      "epoch": 2.4214361621375438,
      "grad_norm": 0.019344108179211617,
      "learning_rate": 1.547138302717474e-05,
      "loss": 0.0318,
      "step": 15950
    },
    {
      "epoch": 2.4290268711097616,
      "grad_norm": 0.08280986547470093,
      "learning_rate": 1.542583877334143e-05,
      "loss": 0.0637,
      "step": 16000
    },
    {
      "epoch": 2.43661758008198,
      "grad_norm": 1.5631897449493408,
      "learning_rate": 1.5380294519508125e-05,
      "loss": 0.0584,
      "step": 16050
    },
    {
      "epoch": 2.4442082890541976,
      "grad_norm": 5.03278923034668,
      "learning_rate": 1.5334750265674815e-05,
      "loss": 0.0458,
      "step": 16100
    },
    {
      "epoch": 2.4517989980264154,
      "grad_norm": 5.870784282684326,
      "learning_rate": 1.528920601184151e-05,
      "loss": 0.0514,
      "step": 16150
    },
    {
      "epoch": 2.4593897069986337,
      "grad_norm": 0.30841654539108276,
      "learning_rate": 1.5243661758008198e-05,
      "loss": 0.047,
      "step": 16200
    },
    {
      "epoch": 2.4669804159708515,
      "grad_norm": 0.0023640678264200687,
      "learning_rate": 1.5198117504174889e-05,
      "loss": 0.0394,
      "step": 16250
    },
    {
      "epoch": 2.4745711249430697,
      "grad_norm": 0.0010505664395168424,
      "learning_rate": 1.5152573250341583e-05,
      "loss": 0.0339,
      "step": 16300
    },
    {
      "epoch": 2.4821618339152876,
      "grad_norm": 6.001008033752441,
      "learning_rate": 1.5107028996508273e-05,
      "loss": 0.0541,
      "step": 16350
    },
    {
      "epoch": 2.489752542887506,
      "grad_norm": 0.006623897701501846,
      "learning_rate": 1.5061484742674967e-05,
      "loss": 0.033,
      "step": 16400
    },
    {
      "epoch": 2.4973432518597236,
      "grad_norm": 0.5213090181350708,
      "learning_rate": 1.5015940488841658e-05,
      "loss": 0.0176,
      "step": 16450
    },
    {
      "epoch": 2.504933960831942,
      "grad_norm": 0.003951654303818941,
      "learning_rate": 1.497039623500835e-05,
      "loss": 0.0824,
      "step": 16500
    },
    {
      "epoch": 2.5125246698041597,
      "grad_norm": 34.01966094970703,
      "learning_rate": 1.4924851981175042e-05,
      "loss": 0.0323,
      "step": 16550
    },
    {
      "epoch": 2.520115378776378,
      "grad_norm": 1.985426664352417,
      "learning_rate": 1.4879307727341734e-05,
      "loss": 0.0501,
      "step": 16600
    },
    {
      "epoch": 2.5277060877485957,
      "grad_norm": 0.001303818542510271,
      "learning_rate": 1.4833763473508427e-05,
      "loss": 0.0335,
      "step": 16650
    },
    {
      "epoch": 2.5352967967208135,
      "grad_norm": 0.0007164627895690501,
      "learning_rate": 1.4788219219675119e-05,
      "loss": 0.0602,
      "step": 16700
    },
    {
      "epoch": 2.542887505693032,
      "grad_norm": 0.014302661642432213,
      "learning_rate": 1.4742674965841811e-05,
      "loss": 0.0498,
      "step": 16750
    },
    {
      "epoch": 2.5504782146652496,
      "grad_norm": 15.725141525268555,
      "learning_rate": 1.4697130712008503e-05,
      "loss": 0.054,
      "step": 16800
    },
    {
      "epoch": 2.558068923637468,
      "grad_norm": 0.0012735917698591948,
      "learning_rate": 1.4651586458175194e-05,
      "loss": 0.054,
      "step": 16850
    },
    {
      "epoch": 2.5656596326096857,
      "grad_norm": 9.077531814575195,
      "learning_rate": 1.4606042204341884e-05,
      "loss": 0.0504,
      "step": 16900
    },
    {
      "epoch": 2.573250341581904,
      "grad_norm": 3.213452100753784,
      "learning_rate": 1.4560497950508577e-05,
      "loss": 0.0424,
      "step": 16950
    },
    {
      "epoch": 2.5808410505541217,
      "grad_norm": 7.069216728210449,
      "learning_rate": 1.4514953696675269e-05,
      "loss": 0.0504,
      "step": 17000
    },
    {
      "epoch": 2.5884317595263395,
      "grad_norm": 0.0029178117401897907,
      "learning_rate": 1.4469409442841961e-05,
      "loss": 0.0462,
      "step": 17050
    },
    {
      "epoch": 2.596022468498558,
      "grad_norm": 0.0035724546760320663,
      "learning_rate": 1.4423865189008653e-05,
      "loss": 0.0506,
      "step": 17100
    },
    {
      "epoch": 2.603613177470776,
      "grad_norm": 0.024722376838326454,
      "learning_rate": 1.4378320935175345e-05,
      "loss": 0.0425,
      "step": 17150
    },
    {
      "epoch": 2.611203886442994,
      "grad_norm": 0.05785733461380005,
      "learning_rate": 1.4332776681342038e-05,
      "loss": 0.0699,
      "step": 17200
    },
    {
      "epoch": 2.6187945954152116,
      "grad_norm": 0.0016919473418965936,
      "learning_rate": 1.428723242750873e-05,
      "loss": 0.0581,
      "step": 17250
    },
    {
      "epoch": 2.62638530438743,
      "grad_norm": 11.171769142150879,
      "learning_rate": 1.4241688173675422e-05,
      "loss": 0.0675,
      "step": 17300
    },
    {
      "epoch": 2.6339760133596477,
      "grad_norm": 8.506949424743652,
      "learning_rate": 1.4196143919842113e-05,
      "loss": 0.0517,
      "step": 17350
    },
    {
      "epoch": 2.641566722331866,
      "grad_norm": 0.5792705416679382,
      "learning_rate": 1.4150599666008805e-05,
      "loss": 0.0523,
      "step": 17400
    },
    {
      "epoch": 2.6491574313040838,
      "grad_norm": 0.003076018299907446,
      "learning_rate": 1.4105055412175497e-05,
      "loss": 0.0547,
      "step": 17450
    },
    {
      "epoch": 2.656748140276302,
      "grad_norm": 0.0931839570403099,
      "learning_rate": 1.405951115834219e-05,
      "loss": 0.0239,
      "step": 17500
    },
    {
      "epoch": 2.66433884924852,
      "grad_norm": 0.016464432701468468,
      "learning_rate": 1.4013966904508882e-05,
      "loss": 0.0509,
      "step": 17550
    },
    {
      "epoch": 2.6719295582207376,
      "grad_norm": 0.0054184249602258205,
      "learning_rate": 1.3968422650675574e-05,
      "loss": 0.0436,
      "step": 17600
    },
    {
      "epoch": 2.679520267192956,
      "grad_norm": 0.0581061989068985,
      "learning_rate": 1.3922878396842266e-05,
      "loss": 0.0624,
      "step": 17650
    },
    {
      "epoch": 2.6871109761651737,
      "grad_norm": 0.008538560010492802,
      "learning_rate": 1.3877334143008958e-05,
      "loss": 0.0386,
      "step": 17700
    },
    {
      "epoch": 2.694701685137392,
      "grad_norm": 0.0283465888351202,
      "learning_rate": 1.383178988917565e-05,
      "loss": 0.0376,
      "step": 17750
    },
    {
      "epoch": 2.7022923941096098,
      "grad_norm": 0.003482275875285268,
      "learning_rate": 1.3786245635342341e-05,
      "loss": 0.0183,
      "step": 17800
    },
    {
      "epoch": 2.709883103081828,
      "grad_norm": 0.6926165819168091,
      "learning_rate": 1.3740701381509033e-05,
      "loss": 0.0588,
      "step": 17850
    },
    {
      "epoch": 2.717473812054046,
      "grad_norm": 0.001778322272002697,
      "learning_rate": 1.3695157127675725e-05,
      "loss": 0.0191,
      "step": 17900
    },
    {
      "epoch": 2.7250645210262636,
      "grad_norm": 2.4795382022857666,
      "learning_rate": 1.3649612873842418e-05,
      "loss": 0.076,
      "step": 17950
    },
    {
      "epoch": 2.732655229998482,
      "grad_norm": 0.0122293159365654,
      "learning_rate": 1.360406862000911e-05,
      "loss": 0.0612,
      "step": 18000
    },
    {
      "epoch": 2.7402459389707,
      "grad_norm": 4.662500858306885,
      "learning_rate": 1.3558524366175802e-05,
      "loss": 0.0744,
      "step": 18050
    },
    {
      "epoch": 2.747836647942918,
      "grad_norm": 5.158463954925537,
      "learning_rate": 1.3512980112342493e-05,
      "loss": 0.0943,
      "step": 18100
    },
    {
      "epoch": 2.7554273569151357,
      "grad_norm": 0.10635584592819214,
      "learning_rate": 1.3467435858509185e-05,
      "loss": 0.0481,
      "step": 18150
    },
    {
      "epoch": 2.763018065887354,
      "grad_norm": 0.005931586027145386,
      "learning_rate": 1.3421891604675877e-05,
      "loss": 0.0258,
      "step": 18200
    },
    {
      "epoch": 2.770608774859572,
      "grad_norm": 0.028244623914361,
      "learning_rate": 1.3376347350842568e-05,
      "loss": 0.0526,
      "step": 18250
    },
    {
      "epoch": 2.77819948383179,
      "grad_norm": 0.007768137846142054,
      "learning_rate": 1.333080309700926e-05,
      "loss": 0.0541,
      "step": 18300
    },
    {
      "epoch": 2.785790192804008,
      "grad_norm": 4.414464473724365,
      "learning_rate": 1.3285258843175952e-05,
      "loss": 0.051,
      "step": 18350
    },
    {
      "epoch": 2.793380901776226,
      "grad_norm": 0.053025901317596436,
      "learning_rate": 1.3239714589342644e-05,
      "loss": 0.0557,
      "step": 18400
    },
    {
      "epoch": 2.800971610748444,
      "grad_norm": 0.002575686201453209,
      "learning_rate": 1.3194170335509336e-05,
      "loss": 0.0585,
      "step": 18450
    },
    {
      "epoch": 2.8085623197206617,
      "grad_norm": 0.19863806664943695,
      "learning_rate": 1.3148626081676029e-05,
      "loss": 0.0488,
      "step": 18500
    },
    {
      "epoch": 2.81615302869288,
      "grad_norm": 0.002164657926186919,
      "learning_rate": 1.3103081827842721e-05,
      "loss": 0.0472,
      "step": 18550
    },
    {
      "epoch": 2.823743737665098,
      "grad_norm": 0.00466370303183794,
      "learning_rate": 1.3057537574009413e-05,
      "loss": 0.0577,
      "step": 18600
    },
    {
      "epoch": 2.831334446637316,
      "grad_norm": 5.162217617034912,
      "learning_rate": 1.3011993320176105e-05,
      "loss": 0.0677,
      "step": 18650
    },
    {
      "epoch": 2.838925155609534,
      "grad_norm": 0.03736773878335953,
      "learning_rate": 1.2966449066342796e-05,
      "loss": 0.051,
      "step": 18700
    },
    {
      "epoch": 2.846515864581752,
      "grad_norm": 0.0012966461945325136,
      "learning_rate": 1.2920904812509488e-05,
      "loss": 0.0392,
      "step": 18750
    },
    {
      "epoch": 2.85410657355397,
      "grad_norm": 0.049197953194379807,
      "learning_rate": 1.287536055867618e-05,
      "loss": 0.065,
      "step": 18800
    },
    {
      "epoch": 2.8616972825261877,
      "grad_norm": 0.006112316623330116,
      "learning_rate": 1.2829816304842873e-05,
      "loss": 0.0669,
      "step": 18850
    },
    {
      "epoch": 2.869287991498406,
      "grad_norm": 0.0012127603404223919,
      "learning_rate": 1.2784272051009565e-05,
      "loss": 0.0372,
      "step": 18900
    },
    {
      "epoch": 2.876878700470624,
      "grad_norm": 0.0069475965574383736,
      "learning_rate": 1.2738727797176257e-05,
      "loss": 0.0306,
      "step": 18950
    },
    {
      "epoch": 2.884469409442842,
      "grad_norm": 1.1212936639785767,
      "learning_rate": 1.269318354334295e-05,
      "loss": 0.08,
      "step": 19000
    },
    {
      "epoch": 2.89206011841506,
      "grad_norm": 0.056755583733320236,
      "learning_rate": 1.2647639289509641e-05,
      "loss": 0.0434,
      "step": 19050
    },
    {
      "epoch": 2.899650827387278,
      "grad_norm": 0.01743948459625244,
      "learning_rate": 1.2602095035676334e-05,
      "loss": 0.0491,
      "step": 19100
    },
    {
      "epoch": 2.907241536359496,
      "grad_norm": 0.6185580492019653,
      "learning_rate": 1.2556550781843024e-05,
      "loss": 0.0422,
      "step": 19150
    },
    {
      "epoch": 2.914832245331714,
      "grad_norm": 16.94100570678711,
      "learning_rate": 1.2511006528009716e-05,
      "loss": 0.0206,
      "step": 19200
    },
    {
      "epoch": 2.922422954303932,
      "grad_norm": 0.002531195990741253,
      "learning_rate": 1.2465462274176409e-05,
      "loss": 0.06,
      "step": 19250
    },
    {
      "epoch": 2.93001366327615,
      "grad_norm": 0.0035239688586443663,
      "learning_rate": 1.2419918020343101e-05,
      "loss": 0.0588,
      "step": 19300
    },
    {
      "epoch": 2.937604372248368,
      "grad_norm": 16.79828453063965,
      "learning_rate": 1.2374373766509791e-05,
      "loss": 0.057,
      "step": 19350
    },
    {
      "epoch": 2.945195081220586,
      "grad_norm": 0.012489140965044498,
      "learning_rate": 1.2328829512676484e-05,
      "loss": 0.058,
      "step": 19400
    },
    {
      "epoch": 2.952785790192804,
      "grad_norm": 0.03304906189441681,
      "learning_rate": 1.2283285258843176e-05,
      "loss": 0.0513,
      "step": 19450
    },
    {
      "epoch": 2.960376499165022,
      "grad_norm": 0.018316049128770828,
      "learning_rate": 1.2237741005009868e-05,
      "loss": 0.0345,
      "step": 19500
    },
    {
      "epoch": 2.96796720813724,
      "grad_norm": 0.003123064525425434,
      "learning_rate": 1.219219675117656e-05,
      "loss": 0.0678,
      "step": 19550
    },
    {
      "epoch": 2.975557917109458,
      "grad_norm": 2.292268753051758,
      "learning_rate": 1.214665249734325e-05,
      "loss": 0.0577,
      "step": 19600
    },
    {
      "epoch": 2.983148626081676,
      "grad_norm": 0.27921998500823975,
      "learning_rate": 1.2101108243509943e-05,
      "loss": 0.0584,
      "step": 19650
    },
    {
      "epoch": 2.990739335053894,
      "grad_norm": 0.005671361926943064,
      "learning_rate": 1.2055563989676635e-05,
      "loss": 0.0588,
      "step": 19700
    },
    {
      "epoch": 2.998330044026112,
      "grad_norm": 0.13956183195114136,
      "learning_rate": 1.2010019735843328e-05,
      "loss": 0.0367,
      "step": 19750
    },
    {
      "epoch": 3.0,
      "eval_runtime": 38.1102,
      "eval_samples_per_second": 701.886,
      "eval_steps_per_second": 43.873,
      "step": 19761
    },
    {
      "epoch": 3.00592075299833,
      "grad_norm": 0.03290143981575966,
      "learning_rate": 1.196447548201002e-05,
      "loss": 0.0469,
      "step": 19800
    },
    {
      "epoch": 3.013511461970548,
      "grad_norm": 0.006316551938652992,
      "learning_rate": 1.1918931228176712e-05,
      "loss": 0.0338,
      "step": 19850
    },
    {
      "epoch": 3.021102170942766,
      "grad_norm": 22.914684295654297,
      "learning_rate": 1.1873386974343404e-05,
      "loss": 0.0232,
      "step": 19900
    },
    {
      "epoch": 3.028692879914984,
      "grad_norm": 0.0006203115917742252,
      "learning_rate": 1.1827842720510096e-05,
      "loss": 0.0312,
      "step": 19950
    },
    {
      "epoch": 3.036283588887202,
      "grad_norm": 0.4070211946964264,
      "learning_rate": 1.1782298466676789e-05,
      "loss": 0.0393,
      "step": 20000
    },
    {
      "epoch": 3.04387429785942,
      "grad_norm": 0.9828908443450928,
      "learning_rate": 1.173675421284348e-05,
      "loss": 0.0063,
      "step": 20050
    },
    {
      "epoch": 3.0514650068316382,
      "grad_norm": 25.835464477539062,
      "learning_rate": 1.1691209959010171e-05,
      "loss": 0.0153,
      "step": 20100
    },
    {
      "epoch": 3.059055715803856,
      "grad_norm": 0.7378546595573425,
      "learning_rate": 1.1645665705176864e-05,
      "loss": 0.0503,
      "step": 20150
    },
    {
      "epoch": 3.0666464247760743,
      "grad_norm": 5.050486087799072,
      "learning_rate": 1.1600121451343556e-05,
      "loss": 0.0465,
      "step": 20200
    },
    {
      "epoch": 3.074237133748292,
      "grad_norm": 1.0316230058670044,
      "learning_rate": 1.1554577197510248e-05,
      "loss": 0.0115,
      "step": 20250
    },
    {
      "epoch": 3.08182784272051,
      "grad_norm": 0.0204776581376791,
      "learning_rate": 1.150903294367694e-05,
      "loss": 0.0353,
      "step": 20300
    },
    {
      "epoch": 3.089418551692728,
      "grad_norm": 0.011231234297156334,
      "learning_rate": 1.1463488689843632e-05,
      "loss": 0.0101,
      "step": 20350
    },
    {
      "epoch": 3.097009260664946,
      "grad_norm": 0.00043961749179288745,
      "learning_rate": 1.1417944436010325e-05,
      "loss": 0.019,
      "step": 20400
    },
    {
      "epoch": 3.1045999696371642,
      "grad_norm": 0.0028695114888250828,
      "learning_rate": 1.1372400182177017e-05,
      "loss": 0.0343,
      "step": 20450
    },
    {
      "epoch": 3.112190678609382,
      "grad_norm": 0.019884921610355377,
      "learning_rate": 1.1326855928343707e-05,
      "loss": 0.0462,
      "step": 20500
    },
    {
      "epoch": 3.1197813875816003,
      "grad_norm": 0.5355314016342163,
      "learning_rate": 1.12813116745104e-05,
      "loss": 0.0146,
      "step": 20550
    },
    {
      "epoch": 3.127372096553818,
      "grad_norm": 0.0025734230875968933,
      "learning_rate": 1.123576742067709e-05,
      "loss": 0.0252,
      "step": 20600
    },
    {
      "epoch": 3.134962805526036,
      "grad_norm": 0.0008210990927182138,
      "learning_rate": 1.1190223166843782e-05,
      "loss": 0.0083,
      "step": 20650
    },
    {
      "epoch": 3.142553514498254,
      "grad_norm": 13.774084091186523,
      "learning_rate": 1.1144678913010475e-05,
      "loss": 0.0087,
      "step": 20700
    },
    {
      "epoch": 3.150144223470472,
      "grad_norm": 0.012875553220510483,
      "learning_rate": 1.1099134659177167e-05,
      "loss": 0.0048,
      "step": 20750
    },
    {
      "epoch": 3.15773493244269,
      "grad_norm": 0.004367040935903788,
      "learning_rate": 1.1053590405343859e-05,
      "loss": 0.0273,
      "step": 20800
    },
    {
      "epoch": 3.165325641414908,
      "grad_norm": 0.0007676514214836061,
      "learning_rate": 1.1008046151510551e-05,
      "loss": 0.0452,
      "step": 20850
    },
    {
      "epoch": 3.1729163503871263,
      "grad_norm": 0.6675720810890198,
      "learning_rate": 1.0962501897677244e-05,
      "loss": 0.0307,
      "step": 20900
    },
    {
      "epoch": 3.180507059359344,
      "grad_norm": 0.01286233589053154,
      "learning_rate": 1.0916957643843936e-05,
      "loss": 0.0216,
      "step": 20950
    },
    {
      "epoch": 3.1880977683315623,
      "grad_norm": 0.002314005047082901,
      "learning_rate": 1.0871413390010626e-05,
      "loss": 0.0374,
      "step": 21000
    },
    {
      "epoch": 3.19568847730378,
      "grad_norm": 10.567161560058594,
      "learning_rate": 1.0825869136177319e-05,
      "loss": 0.0236,
      "step": 21050
    },
    {
      "epoch": 3.2032791862759984,
      "grad_norm": 0.047151681035757065,
      "learning_rate": 1.078032488234401e-05,
      "loss": 0.0181,
      "step": 21100
    },
    {
      "epoch": 3.210869895248216,
      "grad_norm": 0.01723567023873329,
      "learning_rate": 1.0734780628510703e-05,
      "loss": 0.009,
      "step": 21150
    },
    {
      "epoch": 3.218460604220434,
      "grad_norm": 0.022132854908704758,
      "learning_rate": 1.0689236374677395e-05,
      "loss": 0.0195,
      "step": 21200
    },
    {
      "epoch": 3.2260513131926523,
      "grad_norm": 0.03611793369054794,
      "learning_rate": 1.0643692120844087e-05,
      "loss": 0.0317,
      "step": 21250
    },
    {
      "epoch": 3.23364202216487,
      "grad_norm": 10.170194625854492,
      "learning_rate": 1.059814786701078e-05,
      "loss": 0.019,
      "step": 21300
    },
    {
      "epoch": 3.2412327311370883,
      "grad_norm": 6.761831760406494,
      "learning_rate": 1.0552603613177472e-05,
      "loss": 0.0188,
      "step": 21350
    },
    {
      "epoch": 3.248823440109306,
      "grad_norm": 10.946813583374023,
      "learning_rate": 1.0507059359344164e-05,
      "loss": 0.0372,
      "step": 21400
    },
    {
      "epoch": 3.2564141490815244,
      "grad_norm": 0.004475911147892475,
      "learning_rate": 1.0461515105510855e-05,
      "loss": 0.0352,
      "step": 21450
    },
    {
      "epoch": 3.264004858053742,
      "grad_norm": 0.001052375417202711,
      "learning_rate": 1.0415970851677547e-05,
      "loss": 0.0298,
      "step": 21500
    },
    {
      "epoch": 3.27159556702596,
      "grad_norm": 0.0013751364313066006,
      "learning_rate": 1.0370426597844239e-05,
      "loss": 0.0267,
      "step": 21550
    },
    {
      "epoch": 3.2791862759981782,
      "grad_norm": 0.007215270306915045,
      "learning_rate": 1.0324882344010931e-05,
      "loss": 0.0355,
      "step": 21600
    },
    {
      "epoch": 3.286776984970396,
      "grad_norm": 0.003778905374929309,
      "learning_rate": 1.0279338090177624e-05,
      "loss": 0.0312,
      "step": 21650
    },
    {
      "epoch": 3.2943676939426143,
      "grad_norm": 0.0019131283042952418,
      "learning_rate": 1.0233793836344316e-05,
      "loss": 0.0121,
      "step": 21700
    },
    {
      "epoch": 3.301958402914832,
      "grad_norm": 0.01612771302461624,
      "learning_rate": 1.0188249582511008e-05,
      "loss": 0.043,
      "step": 21750
    },
    {
      "epoch": 3.3095491118870504,
      "grad_norm": 0.003564926330000162,
      "learning_rate": 1.01427053286777e-05,
      "loss": 0.0525,
      "step": 21800
    },
    {
      "epoch": 3.317139820859268,
      "grad_norm": 0.0020466060377657413,
      "learning_rate": 1.009716107484439e-05,
      "loss": 0.0384,
      "step": 21850
    },
    {
      "epoch": 3.3247305298314864,
      "grad_norm": 0.005148842930793762,
      "learning_rate": 1.0051616821011081e-05,
      "loss": 0.0218,
      "step": 21900
    },
    {
      "epoch": 3.3323212388037042,
      "grad_norm": 0.2573518753051758,
      "learning_rate": 1.0006072567177773e-05,
      "loss": 0.022,
      "step": 21950
    },
    {
      "epoch": 3.3399119477759225,
      "grad_norm": 0.0009086421341635287,
      "learning_rate": 9.960528313344466e-06,
      "loss": 0.0403,
      "step": 22000
    },
    {
      "epoch": 3.3475026567481403,
      "grad_norm": 0.0006943160551600158,
      "learning_rate": 9.914984059511158e-06,
      "loss": 0.0121,
      "step": 22050
    },
    {
      "epoch": 3.355093365720358,
      "grad_norm": 0.020574258640408516,
      "learning_rate": 9.86943980567785e-06,
      "loss": 0.0263,
      "step": 22100
    },
    {
      "epoch": 3.3626840746925764,
      "grad_norm": 0.0025651617906987667,
      "learning_rate": 9.823895551844542e-06,
      "loss": 0.0228,
      "step": 22150
    },
    {
      "epoch": 3.370274783664794,
      "grad_norm": 11.20188045501709,
      "learning_rate": 9.778351298011235e-06,
      "loss": 0.048,
      "step": 22200
    },
    {
      "epoch": 3.3778654926370124,
      "grad_norm": 0.000905168242752552,
      "learning_rate": 9.732807044177927e-06,
      "loss": 0.018,
      "step": 22250
    },
    {
      "epoch": 3.38545620160923,
      "grad_norm": 0.5774343013763428,
      "learning_rate": 9.687262790344619e-06,
      "loss": 0.0691,
      "step": 22300
    },
    {
      "epoch": 3.3930469105814485,
      "grad_norm": 17.20022964477539,
      "learning_rate": 9.64171853651131e-06,
      "loss": 0.0194,
      "step": 22350
    },
    {
      "epoch": 3.4006376195536663,
      "grad_norm": 0.003966817166656256,
      "learning_rate": 9.596174282678002e-06,
      "loss": 0.0318,
      "step": 22400
    },
    {
      "epoch": 3.408228328525884,
      "grad_norm": 0.0018488321220502257,
      "learning_rate": 9.550630028844694e-06,
      "loss": 0.0187,
      "step": 22450
    },
    {
      "epoch": 3.4158190374981023,
      "grad_norm": 0.001639472902752459,
      "learning_rate": 9.505085775011386e-06,
      "loss": 0.0196,
      "step": 22500
    },
    {
      "epoch": 3.42340974647032,
      "grad_norm": 0.0030477449763566256,
      "learning_rate": 9.459541521178078e-06,
      "loss": 0.0364,
      "step": 22550
    },
    {
      "epoch": 3.4310004554425384,
      "grad_norm": 0.05795911327004433,
      "learning_rate": 9.41399726734477e-06,
      "loss": 0.0192,
      "step": 22600
    },
    {
      "epoch": 3.438591164414756,
      "grad_norm": 0.06518726795911789,
      "learning_rate": 9.368453013511463e-06,
      "loss": 0.0226,
      "step": 22650
    },
    {
      "epoch": 3.4461818733869745,
      "grad_norm": 0.0008213764522224665,
      "learning_rate": 9.322908759678155e-06,
      "loss": 0.0366,
      "step": 22700
    },
    {
      "epoch": 3.4537725823591923,
      "grad_norm": 1.1345819234848022,
      "learning_rate": 9.277364505844847e-06,
      "loss": 0.0386,
      "step": 22750
    },
    {
      "epoch": 3.4613632913314105,
      "grad_norm": 2.919769287109375,
      "learning_rate": 9.231820252011538e-06,
      "loss": 0.0233,
      "step": 22800
    },
    {
      "epoch": 3.4689540003036283,
      "grad_norm": 0.0054010627791285515,
      "learning_rate": 9.18627599817823e-06,
      "loss": 0.0297,
      "step": 22850
    },
    {
      "epoch": 3.4765447092758466,
      "grad_norm": 0.021374795585870743,
      "learning_rate": 9.140731744344922e-06,
      "loss": 0.0213,
      "step": 22900
    },
    {
      "epoch": 3.4841354182480644,
      "grad_norm": 10.321237564086914,
      "learning_rate": 9.095187490511615e-06,
      "loss": 0.0335,
      "step": 22950
    },
    {
      "epoch": 3.491726127220282,
      "grad_norm": 0.030880559235811234,
      "learning_rate": 9.049643236678307e-06,
      "loss": 0.037,
      "step": 23000
    },
    {
      "epoch": 3.4993168361925004,
      "grad_norm": 0.0005338179180398583,
      "learning_rate": 9.004098982844999e-06,
      "loss": 0.0121,
      "step": 23050
    },
    {
      "epoch": 3.5069075451647183,
      "grad_norm": 21.916841506958008,
      "learning_rate": 8.95855472901169e-06,
      "loss": 0.0391,
      "step": 23100
    },
    {
      "epoch": 3.5144982541369365,
      "grad_norm": 0.0005952644860371947,
      "learning_rate": 8.913010475178382e-06,
      "loss": 0.0396,
      "step": 23150
    },
    {
      "epoch": 3.5220889631091543,
      "grad_norm": 0.004227530211210251,
      "learning_rate": 8.867466221345074e-06,
      "loss": 0.049,
      "step": 23200
    },
    {
      "epoch": 3.5296796720813726,
      "grad_norm": 12.425705909729004,
      "learning_rate": 8.821921967511765e-06,
      "loss": 0.0399,
      "step": 23250
    },
    {
      "epoch": 3.5372703810535904,
      "grad_norm": 0.028760308399796486,
      "learning_rate": 8.776377713678457e-06,
      "loss": 0.027,
      "step": 23300
    },
    {
      "epoch": 3.544861090025808,
      "grad_norm": 5.940562725067139,
      "learning_rate": 8.730833459845149e-06,
      "loss": 0.0135,
      "step": 23350
    },
    {
      "epoch": 3.5524517989980264,
      "grad_norm": 3.9054269790649414,
      "learning_rate": 8.685289206011841e-06,
      "loss": 0.0261,
      "step": 23400
    },
    {
      "epoch": 3.5600425079702447,
      "grad_norm": 0.06918121129274368,
      "learning_rate": 8.639744952178533e-06,
      "loss": 0.0114,
      "step": 23450
    },
    {
      "epoch": 3.5676332169424625,
      "grad_norm": 3.309570074081421,
      "learning_rate": 8.594200698345226e-06,
      "loss": 0.0208,
      "step": 23500
    },
    {
      "epoch": 3.5752239259146803,
      "grad_norm": 0.02411326766014099,
      "learning_rate": 8.548656444511918e-06,
      "loss": 0.019,
      "step": 23550
    },
    {
      "epoch": 3.5828146348868986,
      "grad_norm": 0.6198381185531616,
      "learning_rate": 8.50311219067861e-06,
      "loss": 0.0346,
      "step": 23600
    },
    {
      "epoch": 3.5904053438591164,
      "grad_norm": 13.908424377441406,
      "learning_rate": 8.457567936845302e-06,
      "loss": 0.065,
      "step": 23650
    },
    {
      "epoch": 3.5979960528313346,
      "grad_norm": 0.0022189272567629814,
      "learning_rate": 8.412023683011993e-06,
      "loss": 0.0433,
      "step": 23700
    },
    {
      "epoch": 3.6055867618035524,
      "grad_norm": 0.0008211254025809467,
      "learning_rate": 8.366479429178685e-06,
      "loss": 0.0162,
      "step": 23750
    },
    {
      "epoch": 3.6131774707757707,
      "grad_norm": 13.963356971740723,
      "learning_rate": 8.320935175345377e-06,
      "loss": 0.032,
      "step": 23800
    },
    {
      "epoch": 3.6207681797479885,
      "grad_norm": 0.15797050297260284,
      "learning_rate": 8.27539092151207e-06,
      "loss": 0.0249,
      "step": 23850
    },
    {
      "epoch": 3.6283588887202063,
      "grad_norm": 0.0023322650231420994,
      "learning_rate": 8.229846667678762e-06,
      "loss": 0.0063,
      "step": 23900
    },
    {
      "epoch": 3.6359495976924245,
      "grad_norm": 17.699174880981445,
      "learning_rate": 8.184302413845454e-06,
      "loss": 0.0504,
      "step": 23950
    },
    {
      "epoch": 3.6435403066646423,
      "grad_norm": 0.00046802285942249,
      "learning_rate": 8.138758160012146e-06,
      "loss": 0.0245,
      "step": 24000
    },
    {
      "epoch": 3.6511310156368606,
      "grad_norm": 9.790094375610352,
      "learning_rate": 8.093213906178838e-06,
      "loss": 0.0156,
      "step": 24050
    },
    {
      "epoch": 3.6587217246090784,
      "grad_norm": 0.0008645845227874815,
      "learning_rate": 8.04766965234553e-06,
      "loss": 0.011,
      "step": 24100
    },
    {
      "epoch": 3.6663124335812967,
      "grad_norm": 10.480079650878906,
      "learning_rate": 8.002125398512221e-06,
      "loss": 0.0115,
      "step": 24150
    },
    {
      "epoch": 3.6739031425535145,
      "grad_norm": 0.007814845070242882,
      "learning_rate": 7.956581144678913e-06,
      "loss": 0.036,
      "step": 24200
    },
    {
      "epoch": 3.6814938515257323,
      "grad_norm": 1.9135187864303589,
      "learning_rate": 7.911036890845606e-06,
      "loss": 0.0127,
      "step": 24250
    },
    {
      "epoch": 3.6890845604979505,
      "grad_norm": 0.0003968064265791327,
      "learning_rate": 7.865492637012298e-06,
      "loss": 0.0213,
      "step": 24300
    },
    {
      "epoch": 3.696675269470169,
      "grad_norm": 0.08024092018604279,
      "learning_rate": 7.819948383178988e-06,
      "loss": 0.0304,
      "step": 24350
    },
    {
      "epoch": 3.7042659784423866,
      "grad_norm": 37.44281768798828,
      "learning_rate": 7.77440412934568e-06,
      "loss": 0.038,
      "step": 24400
    },
    {
      "epoch": 3.7118566874146044,
      "grad_norm": 0.00028779907734133303,
      "learning_rate": 7.728859875512373e-06,
      "loss": 0.0091,
      "step": 24450
    },
    {
      "epoch": 3.7194473963868226,
      "grad_norm": 0.054760340601205826,
      "learning_rate": 7.683315621679065e-06,
      "loss": 0.0728,
      "step": 24500
    },
    {
      "epoch": 3.7270381053590405,
      "grad_norm": 0.005203745793551207,
      "learning_rate": 7.637771367845757e-06,
      "loss": 0.047,
      "step": 24550
    },
    {
      "epoch": 3.7346288143312587,
      "grad_norm": 0.01508235651999712,
      "learning_rate": 7.592227114012449e-06,
      "loss": 0.0313,
      "step": 24600
    },
    {
      "epoch": 3.7422195233034765,
      "grad_norm": 0.014647228643298149,
      "learning_rate": 7.54668286017914e-06,
      "loss": 0.0189,
      "step": 24650
    },
    {
      "epoch": 3.7498102322756948,
      "grad_norm": 0.0014302196213975549,
      "learning_rate": 7.501138606345832e-06,
      "loss": 0.0594,
      "step": 24700
    },
    {
      "epoch": 3.7574009412479126,
      "grad_norm": 0.0010849084937945008,
      "learning_rate": 7.4555943525125245e-06,
      "loss": 0.0309,
      "step": 24750
    },
    {
      "epoch": 3.7649916502201304,
      "grad_norm": 0.01598423533141613,
      "learning_rate": 7.410050098679217e-06,
      "loss": 0.028,
      "step": 24800
    },
    {
      "epoch": 3.7725823591923486,
      "grad_norm": 0.005286468658596277,
      "learning_rate": 7.364505844845909e-06,
      "loss": 0.0184,
      "step": 24850
    },
    {
      "epoch": 3.7801730681645664,
      "grad_norm": 0.09565062075853348,
      "learning_rate": 7.3189615910126e-06,
      "loss": 0.038,
      "step": 24900
    },
    {
      "epoch": 3.7877637771367847,
      "grad_norm": 0.03416730463504791,
      "learning_rate": 7.2734173371792925e-06,
      "loss": 0.0306,
      "step": 24950
    },
    {
      "epoch": 3.7953544861090025,
      "grad_norm": 0.7171468734741211,
      "learning_rate": 7.227873083345985e-06,
      "loss": 0.003,
      "step": 25000
    },
    {
      "epoch": 3.8029451950812208,
      "grad_norm": 11.165336608886719,
      "learning_rate": 7.182328829512677e-06,
      "loss": 0.0291,
      "step": 25050
    },
    {
      "epoch": 3.8105359040534386,
      "grad_norm": 2.1755688190460205,
      "learning_rate": 7.136784575679369e-06,
      "loss": 0.0384,
      "step": 25100
    },
    {
      "epoch": 3.8181266130256564,
      "grad_norm": 0.0015131726395338774,
      "learning_rate": 7.0912403218460606e-06,
      "loss": 0.0368,
      "step": 25150
    },
    {
      "epoch": 3.8257173219978746,
      "grad_norm": 0.047697268426418304,
      "learning_rate": 7.045696068012753e-06,
      "loss": 0.0097,
      "step": 25200
    },
    {
      "epoch": 3.833308030970093,
      "grad_norm": 0.0007093006861396134,
      "learning_rate": 7.000151814179445e-06,
      "loss": 0.0183,
      "step": 25250
    },
    {
      "epoch": 3.8408987399423107,
      "grad_norm": 0.0032084134873002768,
      "learning_rate": 6.954607560346136e-06,
      "loss": 0.013,
      "step": 25300
    },
    {
      "epoch": 3.8484894489145285,
      "grad_norm": 0.027891812846064568,
      "learning_rate": 6.909063306512828e-06,
      "loss": 0.0276,
      "step": 25350
    },
    {
      "epoch": 3.8560801578867467,
      "grad_norm": 0.0034773279912769794,
      "learning_rate": 6.86351905267952e-06,
      "loss": 0.0297,
      "step": 25400
    },
    {
      "epoch": 3.8636708668589645,
      "grad_norm": 0.003833820577710867,
      "learning_rate": 6.817974798846212e-06,
      "loss": 0.0237,
      "step": 25450
    },
    {
      "epoch": 3.8712615758311824,
      "grad_norm": 0.001593896420672536,
      "learning_rate": 6.7724305450129044e-06,
      "loss": 0.0392,
      "step": 25500
    },
    {
      "epoch": 3.8788522848034006,
      "grad_norm": 0.0011019427329301834,
      "learning_rate": 6.726886291179597e-06,
      "loss": 0.0182,
      "step": 25550
    },
    {
      "epoch": 3.886442993775619,
      "grad_norm": 1.0230566263198853,
      "learning_rate": 6.681342037346288e-06,
      "loss": 0.0164,
      "step": 25600
    },
    {
      "epoch": 3.8940337027478367,
      "grad_norm": 13.670833587646484,
      "learning_rate": 6.63579778351298e-06,
      "loss": 0.0469,
      "step": 25650
    },
    {
      "epoch": 3.9016244117200545,
      "grad_norm": 0.015290489420294762,
      "learning_rate": 6.5902535296796725e-06,
      "loss": 0.0125,
      "step": 25700
    },
    {
      "epoch": 3.9092151206922727,
      "grad_norm": 0.00131570256780833,
      "learning_rate": 6.544709275846365e-06,
      "loss": 0.0552,
      "step": 25750
    },
    {
      "epoch": 3.9168058296644905,
      "grad_norm": 0.012414632365107536,
      "learning_rate": 6.499165022013056e-06,
      "loss": 0.0362,
      "step": 25800
    },
    {
      "epoch": 3.924396538636709,
      "grad_norm": 0.0024597267620265484,
      "learning_rate": 6.453620768179748e-06,
      "loss": 0.0054,
      "step": 25850
    },
    {
      "epoch": 3.9319872476089266,
      "grad_norm": 0.01289402972906828,
      "learning_rate": 6.40807651434644e-06,
      "loss": 0.0186,
      "step": 25900
    },
    {
      "epoch": 3.939577956581145,
      "grad_norm": 0.010544383898377419,
      "learning_rate": 6.362532260513132e-06,
      "loss": 0.0286,
      "step": 25950
    },
    {
      "epoch": 3.9471686655533627,
      "grad_norm": 0.0018165346700698137,
      "learning_rate": 6.316988006679824e-06,
      "loss": 0.0076,
      "step": 26000
    },
    {
      "epoch": 3.9547593745255805,
      "grad_norm": 0.08395407348871231,
      "learning_rate": 6.2714437528465155e-06,
      "loss": 0.0238,
      "step": 26050
    },
    {
      "epoch": 3.9623500834977987,
      "grad_norm": 0.06743206828832626,
      "learning_rate": 6.225899499013208e-06,
      "loss": 0.0137,
      "step": 26100
    },
    {
      "epoch": 3.969940792470017,
      "grad_norm": 20.00494384765625,
      "learning_rate": 6.1803552451799e-06,
      "loss": 0.0474,
      "step": 26150
    },
    {
      "epoch": 3.9775315014422348,
      "grad_norm": 4.46220588684082,
      "learning_rate": 6.134810991346592e-06,
      "loss": 0.0411,
      "step": 26200
    },
    {
      "epoch": 3.9851222104144526,
      "grad_norm": 0.002006327034905553,
      "learning_rate": 6.0892667375132836e-06,
      "loss": 0.0104,
      "step": 26250
    },
    {
      "epoch": 3.992712919386671,
      "grad_norm": 0.0017122408607974648,
      "learning_rate": 6.043722483679976e-06,
      "loss": 0.0485,
      "step": 26300
    },
    {
      "epoch": 4.0,
      "eval_runtime": 38.2332,
      "eval_samples_per_second": 699.628,
      "eval_steps_per_second": 43.732,
      "step": 26348
    },
    {
      "epoch": 4.000303628358889,
      "grad_norm": 0.08718279004096985,
      "learning_rate": 5.998178229846668e-06,
      "loss": 0.0213,
      "step": 26350
    },
    {
      "epoch": 4.0078943373311064,
      "grad_norm": 0.08997821062803268,
      "learning_rate": 5.95263397601336e-06,
      "loss": 0.0063,
      "step": 26400
    },
    {
      "epoch": 4.015485046303325,
      "grad_norm": 0.009132896549999714,
      "learning_rate": 5.9070897221800525e-06,
      "loss": 0.0112,
      "step": 26450
    },
    {
      "epoch": 4.023075755275543,
      "grad_norm": 0.0073194801807403564,
      "learning_rate": 5.861545468346744e-06,
      "loss": 0.0016,
      "step": 26500
    },
    {
      "epoch": 4.03066646424776,
      "grad_norm": 0.004764197859913111,
      "learning_rate": 5.816001214513435e-06,
      "loss": 0.0028,
      "step": 26550
    },
    {
      "epoch": 4.038257173219979,
      "grad_norm": 0.0027497538831084967,
      "learning_rate": 5.7704569606801274e-06,
      "loss": 0.0097,
      "step": 26600
    },
    {
      "epoch": 4.045847882192197,
      "grad_norm": 0.06062214449048042,
      "learning_rate": 5.72491270684682e-06,
      "loss": 0.0207,
      "step": 26650
    },
    {
      "epoch": 4.053438591164415,
      "grad_norm": 0.00023615892860107124,
      "learning_rate": 5.679368453013511e-06,
      "loss": 0.0092,
      "step": 26700
    },
    {
      "epoch": 4.061029300136632,
      "grad_norm": 0.020158477127552032,
      "learning_rate": 5.633824199180203e-06,
      "loss": 0.01,
      "step": 26750
    },
    {
      "epoch": 4.068620009108851,
      "grad_norm": 0.0018774383934214711,
      "learning_rate": 5.5882799453468955e-06,
      "loss": 0.0083,
      "step": 26800
    },
    {
      "epoch": 4.076210718081069,
      "grad_norm": 0.0005723437643609941,
      "learning_rate": 5.542735691513588e-06,
      "loss": 0.0283,
      "step": 26850
    },
    {
      "epoch": 4.083801427053287,
      "grad_norm": 0.00997805967926979,
      "learning_rate": 5.49719143768028e-06,
      "loss": 0.0238,
      "step": 26900
    },
    {
      "epoch": 4.0913921360255046,
      "grad_norm": 0.0007614325731992722,
      "learning_rate": 5.451647183846971e-06,
      "loss": 0.0137,
      "step": 26950
    },
    {
      "epoch": 4.098982844997723,
      "grad_norm": 0.01579858921468258,
      "learning_rate": 5.4061029300136635e-06,
      "loss": 0.0131,
      "step": 27000
    },
    {
      "epoch": 4.106573553969941,
      "grad_norm": 0.01090248767286539,
      "learning_rate": 5.360558676180356e-06,
      "loss": 0.0116,
      "step": 27050
    },
    {
      "epoch": 4.114164262942158,
      "grad_norm": 0.6503143310546875,
      "learning_rate": 5.315014422347048e-06,
      "loss": 0.0312,
      "step": 27100
    },
    {
      "epoch": 4.121754971914377,
      "grad_norm": 0.13535819947719574,
      "learning_rate": 5.2694701685137385e-06,
      "loss": 0.0144,
      "step": 27150
    },
    {
      "epoch": 4.129345680886595,
      "grad_norm": 0.0010040337219834328,
      "learning_rate": 5.223925914680431e-06,
      "loss": 0.0162,
      "step": 27200
    },
    {
      "epoch": 4.136936389858813,
      "grad_norm": 0.02511061728000641,
      "learning_rate": 5.178381660847123e-06,
      "loss": 0.0205,
      "step": 27250
    },
    {
      "epoch": 4.1445270988310305,
      "grad_norm": 0.00048819673247635365,
      "learning_rate": 5.132837407013815e-06,
      "loss": 0.0177,
      "step": 27300
    },
    {
      "epoch": 4.152117807803249,
      "grad_norm": 0.0004040453350171447,
      "learning_rate": 5.087293153180507e-06,
      "loss": 0.009,
      "step": 27350
    },
    {
      "epoch": 4.159708516775467,
      "grad_norm": 0.007581164129078388,
      "learning_rate": 5.041748899347199e-06,
      "loss": 0.0039,
      "step": 27400
    },
    {
      "epoch": 4.167299225747684,
      "grad_norm": 0.006680045276880264,
      "learning_rate": 4.996204645513891e-06,
      "loss": 0.0033,
      "step": 27450
    },
    {
      "epoch": 4.174889934719903,
      "grad_norm": 0.007190401665866375,
      "learning_rate": 4.950660391680583e-06,
      "loss": 0.0099,
      "step": 27500
    },
    {
      "epoch": 4.182480643692121,
      "grad_norm": 0.00036279798950999975,
      "learning_rate": 4.9051161378472755e-06,
      "loss": 0.0088,
      "step": 27550
    },
    {
      "epoch": 4.190071352664339,
      "grad_norm": 0.13057266175746918,
      "learning_rate": 4.859571884013967e-06,
      "loss": 0.0045,
      "step": 27600
    },
    {
      "epoch": 4.1976620616365565,
      "grad_norm": 12.948219299316406,
      "learning_rate": 4.814027630180659e-06,
      "loss": 0.0153,
      "step": 27650
    },
    {
      "epoch": 4.205252770608775,
      "grad_norm": 13.083646774291992,
      "learning_rate": 4.768483376347351e-06,
      "loss": 0.0207,
      "step": 27700
    },
    {
      "epoch": 4.212843479580993,
      "grad_norm": 0.016308415681123734,
      "learning_rate": 4.7229391225140435e-06,
      "loss": 0.0309,
      "step": 27750
    },
    {
      "epoch": 4.220434188553211,
      "grad_norm": 0.0016612947219982743,
      "learning_rate": 4.677394868680735e-06,
      "loss": 0.0004,
      "step": 27800
    },
    {
      "epoch": 4.228024897525429,
      "grad_norm": 0.001334612024948001,
      "learning_rate": 4.631850614847426e-06,
      "loss": 0.0009,
      "step": 27850
    },
    {
      "epoch": 4.235615606497647,
      "grad_norm": 0.00041218273690901697,
      "learning_rate": 4.5863063610141185e-06,
      "loss": 0.0051,
      "step": 27900
    },
    {
      "epoch": 4.243206315469865,
      "grad_norm": 0.0025207954458892345,
      "learning_rate": 4.540762107180811e-06,
      "loss": 0.0205,
      "step": 27950
    },
    {
      "epoch": 4.2507970244420825,
      "grad_norm": 0.005354140419512987,
      "learning_rate": 4.495217853347503e-06,
      "loss": 0.0007,
      "step": 28000
    },
    {
      "epoch": 4.258387733414301,
      "grad_norm": 0.576374888420105,
      "learning_rate": 4.449673599514194e-06,
      "loss": 0.0053,
      "step": 28050
    },
    {
      "epoch": 4.265978442386519,
      "grad_norm": 0.004138402175158262,
      "learning_rate": 4.4041293456808865e-06,
      "loss": 0.014,
      "step": 28100
    },
    {
      "epoch": 4.273569151358737,
      "grad_norm": 0.00028985412791371346,
      "learning_rate": 4.358585091847579e-06,
      "loss": 0.028,
      "step": 28150
    },
    {
      "epoch": 4.281159860330955,
      "grad_norm": 0.0002709677501115948,
      "learning_rate": 4.313040838014271e-06,
      "loss": 0.0114,
      "step": 28200
    },
    {
      "epoch": 4.288750569303173,
      "grad_norm": 0.00043938541784882545,
      "learning_rate": 4.267496584180963e-06,
      "loss": 0.0119,
      "step": 28250
    },
    {
      "epoch": 4.296341278275391,
      "grad_norm": 0.0038771852850914,
      "learning_rate": 4.2219523303476546e-06,
      "loss": 0.0403,
      "step": 28300
    },
    {
      "epoch": 4.3039319872476085,
      "grad_norm": 0.001122533343732357,
      "learning_rate": 4.176408076514347e-06,
      "loss": 0.0257,
      "step": 28350
    },
    {
      "epoch": 4.311522696219827,
      "grad_norm": 0.10982765257358551,
      "learning_rate": 4.130863822681038e-06,
      "loss": 0.009,
      "step": 28400
    },
    {
      "epoch": 4.319113405192045,
      "grad_norm": 9.913846969604492,
      "learning_rate": 4.08531956884773e-06,
      "loss": 0.0071,
      "step": 28450
    },
    {
      "epoch": 4.326704114164263,
      "grad_norm": 0.0004866818489972502,
      "learning_rate": 4.039775315014422e-06,
      "loss": 0.0232,
      "step": 28500
    },
    {
      "epoch": 4.334294823136481,
      "grad_norm": 0.010646448470652103,
      "learning_rate": 3.994231061181114e-06,
      "loss": 0.0165,
      "step": 28550
    },
    {
      "epoch": 4.341885532108699,
      "grad_norm": 0.0007722537266090512,
      "learning_rate": 3.948686807347806e-06,
      "loss": 0.0068,
      "step": 28600
    },
    {
      "epoch": 4.349476241080917,
      "grad_norm": 0.0003706314892042428,
      "learning_rate": 3.9031425535144984e-06,
      "loss": 0.0174,
      "step": 28650
    },
    {
      "epoch": 4.357066950053135,
      "grad_norm": 0.00026914532645605505,
      "learning_rate": 3.857598299681191e-06,
      "loss": 0.0061,
      "step": 28700
    },
    {
      "epoch": 4.364657659025353,
      "grad_norm": 0.008042202331125736,
      "learning_rate": 3.812054045847882e-06,
      "loss": 0.0104,
      "step": 28750
    },
    {
      "epoch": 4.372248367997571,
      "grad_norm": 0.0018188052345067263,
      "learning_rate": 3.7665097920145743e-06,
      "loss": 0.008,
      "step": 28800
    },
    {
      "epoch": 4.379839076969789,
      "grad_norm": 0.0014950046315789223,
      "learning_rate": 3.720965538181266e-06,
      "loss": 0.0187,
      "step": 28850
    },
    {
      "epoch": 4.387429785942007,
      "grad_norm": 0.007232665084302425,
      "learning_rate": 3.675421284347958e-06,
      "loss": 0.0129,
      "step": 28900
    },
    {
      "epoch": 4.395020494914225,
      "grad_norm": 0.0024143236223608255,
      "learning_rate": 3.62987703051465e-06,
      "loss": 0.0054,
      "step": 28950
    },
    {
      "epoch": 4.402611203886443,
      "grad_norm": 0.00016295794921461493,
      "learning_rate": 3.5843327766813423e-06,
      "loss": 0.0056,
      "step": 29000
    },
    {
      "epoch": 4.410201912858661,
      "grad_norm": 0.01587418094277382,
      "learning_rate": 3.538788522848034e-06,
      "loss": 0.022,
      "step": 29050
    },
    {
      "epoch": 4.417792621830879,
      "grad_norm": 0.0002800330694299191,
      "learning_rate": 3.4932442690147263e-06,
      "loss": 0.021,
      "step": 29100
    },
    {
      "epoch": 4.425383330803097,
      "grad_norm": 0.6727336645126343,
      "learning_rate": 3.447700015181418e-06,
      "loss": 0.0087,
      "step": 29150
    },
    {
      "epoch": 4.432974039775315,
      "grad_norm": 9.934810638427734,
      "learning_rate": 3.40215576134811e-06,
      "loss": 0.027,
      "step": 29200
    },
    {
      "epoch": 4.4405647487475335,
      "grad_norm": 0.04227929189801216,
      "learning_rate": 3.3566115075148017e-06,
      "loss": 0.0024,
      "step": 29250
    },
    {
      "epoch": 4.448155457719751,
      "grad_norm": 0.17332172393798828,
      "learning_rate": 3.311067253681494e-06,
      "loss": 0.0146,
      "step": 29300
    },
    {
      "epoch": 4.455746166691969,
      "grad_norm": 0.0019612510222941637,
      "learning_rate": 3.2655229998481858e-06,
      "loss": 0.0054,
      "step": 29350
    },
    {
      "epoch": 4.463336875664187,
      "grad_norm": 0.00033640602487139404,
      "learning_rate": 3.219978746014878e-06,
      "loss": 0.0374,
      "step": 29400
    },
    {
      "epoch": 4.470927584636405,
      "grad_norm": 0.00042230449616909027,
      "learning_rate": 3.1744344921815702e-06,
      "loss": 0.0034,
      "step": 29450
    },
    {
      "epoch": 4.478518293608623,
      "grad_norm": 0.00495507474988699,
      "learning_rate": 3.1288902383482616e-06,
      "loss": 0.006,
      "step": 29500
    },
    {
      "epoch": 4.486109002580841,
      "grad_norm": 0.004195731598883867,
      "learning_rate": 3.083345984514954e-06,
      "loss": 0.0216,
      "step": 29550
    },
    {
      "epoch": 4.4936997115530595,
      "grad_norm": 0.015685725957155228,
      "learning_rate": 3.0378017306816456e-06,
      "loss": 0.0166,
      "step": 29600
    },
    {
      "epoch": 4.501290420525277,
      "grad_norm": 0.0018872052896767855,
      "learning_rate": 2.992257476848338e-06,
      "loss": 0.0108,
      "step": 29650
    },
    {
      "epoch": 4.508881129497495,
      "grad_norm": 0.0004234859661664814,
      "learning_rate": 2.9467132230150296e-06,
      "loss": 0.0105,
      "step": 29700
    },
    {
      "epoch": 4.516471838469713,
      "grad_norm": 0.006609992124140263,
      "learning_rate": 2.901168969181722e-06,
      "loss": 0.01,
      "step": 29750
    },
    {
      "epoch": 4.524062547441931,
      "grad_norm": 0.0020154311787337065,
      "learning_rate": 2.8556247153484132e-06,
      "loss": 0.0132,
      "step": 29800
    },
    {
      "epoch": 4.531653256414149,
      "grad_norm": 0.012759149074554443,
      "learning_rate": 2.8100804615151055e-06,
      "loss": 0.0077,
      "step": 29850
    },
    {
      "epoch": 4.539243965386367,
      "grad_norm": 0.004057296086102724,
      "learning_rate": 2.7645362076817977e-06,
      "loss": 0.0025,
      "step": 29900
    },
    {
      "epoch": 4.5468346743585855,
      "grad_norm": 0.0036063615698367357,
      "learning_rate": 2.7189919538484895e-06,
      "loss": 0.0262,
      "step": 29950
    },
    {
      "epoch": 4.554425383330803,
      "grad_norm": 0.0007461455534212291,
      "learning_rate": 2.6734477000151817e-06,
      "loss": 0.0189,
      "step": 30000
    },
    {
      "epoch": 4.562016092303021,
      "grad_norm": 0.00030093028908595443,
      "learning_rate": 2.6279034461818735e-06,
      "loss": 0.0118,
      "step": 30050
    },
    {
      "epoch": 4.569606801275239,
      "grad_norm": 0.0007241146522574127,
      "learning_rate": 2.5823591923485653e-06,
      "loss": 0.0092,
      "step": 30100
    },
    {
      "epoch": 4.577197510247457,
      "grad_norm": 0.0004720140132121742,
      "learning_rate": 2.536814938515257e-06,
      "loss": 0.0334,
      "step": 30150
    },
    {
      "epoch": 4.584788219219675,
      "grad_norm": 0.0016892628045752645,
      "learning_rate": 2.4912706846819493e-06,
      "loss": 0.0028,
      "step": 30200
    },
    {
      "epoch": 4.592378928191893,
      "grad_norm": 0.001205549342557788,
      "learning_rate": 2.445726430848641e-06,
      "loss": 0.0085,
      "step": 30250
    },
    {
      "epoch": 4.5999696371641114,
      "grad_norm": 0.0009108875528909266,
      "learning_rate": 2.4001821770153334e-06,
      "loss": 0.0134,
      "step": 30300
    },
    {
      "epoch": 4.607560346136329,
      "grad_norm": 0.018680332228541374,
      "learning_rate": 2.3546379231820256e-06,
      "loss": 0.0125,
      "step": 30350
    },
    {
      "epoch": 4.615151055108547,
      "grad_norm": 0.0003905060875695199,
      "learning_rate": 2.3090936693487174e-06,
      "loss": 0.0166,
      "step": 30400
    },
    {
      "epoch": 4.622741764080765,
      "grad_norm": 0.0008439382072538137,
      "learning_rate": 2.263549415515409e-06,
      "loss": 0.0105,
      "step": 30450
    },
    {
      "epoch": 4.630332473052983,
      "grad_norm": 0.00016385650087613612,
      "learning_rate": 2.218005161682101e-06,
      "loss": 0.0165,
      "step": 30500
    },
    {
      "epoch": 4.637923182025201,
      "grad_norm": 0.0011425119591876864,
      "learning_rate": 2.172460907848793e-06,
      "loss": 0.0114,
      "step": 30550
    },
    {
      "epoch": 4.645513890997419,
      "grad_norm": 0.00020584542653523386,
      "learning_rate": 2.126916654015485e-06,
      "loss": 0.0087,
      "step": 30600
    },
    {
      "epoch": 4.653104599969637,
      "grad_norm": 0.0008526861201971769,
      "learning_rate": 2.0813724001821772e-06,
      "loss": 0.0034,
      "step": 30650
    },
    {
      "epoch": 4.660695308941855,
      "grad_norm": 0.0010175785282626748,
      "learning_rate": 2.035828146348869e-06,
      "loss": 0.0148,
      "step": 30700
    },
    {
      "epoch": 4.668286017914073,
      "grad_norm": 0.00017923212726600468,
      "learning_rate": 1.990283892515561e-06,
      "loss": 0.0096,
      "step": 30750
    },
    {
      "epoch": 4.675876726886291,
      "grad_norm": 37.7287483215332,
      "learning_rate": 1.944739638682253e-06,
      "loss": 0.0336,
      "step": 30800
    },
    {
      "epoch": 4.6834674358585096,
      "grad_norm": 0.007138911169022322,
      "learning_rate": 1.8991953848489449e-06,
      "loss": 0.016,
      "step": 30850
    },
    {
      "epoch": 4.691058144830727,
      "grad_norm": 0.000893893011379987,
      "learning_rate": 1.8536511310156369e-06,
      "loss": 0.0198,
      "step": 30900
    },
    {
      "epoch": 4.698648853802945,
      "grad_norm": 0.018649639561772346,
      "learning_rate": 1.8081068771823289e-06,
      "loss": 0.0095,
      "step": 30950
    },
    {
      "epoch": 4.706239562775163,
      "grad_norm": 0.0025327755138278008,
      "learning_rate": 1.7625626233490209e-06,
      "loss": 0.015,
      "step": 31000
    },
    {
      "epoch": 4.713830271747382,
      "grad_norm": 0.022508399561047554,
      "learning_rate": 1.717018369515713e-06,
      "loss": 0.0138,
      "step": 31050
    },
    {
      "epoch": 4.721420980719599,
      "grad_norm": 0.01833524741232395,
      "learning_rate": 1.671474115682405e-06,
      "loss": 0.0001,
      "step": 31100
    },
    {
      "epoch": 4.729011689691817,
      "grad_norm": 0.0009271276649087667,
      "learning_rate": 1.6259298618490967e-06,
      "loss": 0.0117,
      "step": 31150
    },
    {
      "epoch": 4.7366023986640355,
      "grad_norm": 0.003025457728654146,
      "learning_rate": 1.5803856080157887e-06,
      "loss": 0.0222,
      "step": 31200
    },
    {
      "epoch": 4.744193107636253,
      "grad_norm": 0.0018426136812195182,
      "learning_rate": 1.5348413541824807e-06,
      "loss": 0.0211,
      "step": 31250
    },
    {
      "epoch": 4.751783816608471,
      "grad_norm": 0.0006020346190780401,
      "learning_rate": 1.4892971003491725e-06,
      "loss": 0.0079,
      "step": 31300
    },
    {
      "epoch": 4.759374525580689,
      "grad_norm": 0.008377039805054665,
      "learning_rate": 1.4437528465158646e-06,
      "loss": 0.0243,
      "step": 31350
    },
    {
      "epoch": 4.766965234552908,
      "grad_norm": 0.0016610425664111972,
      "learning_rate": 1.3982085926825566e-06,
      "loss": 0.0126,
      "step": 31400
    },
    {
      "epoch": 4.774555943525125,
      "grad_norm": 0.0019020226318389177,
      "learning_rate": 1.3526643388492486e-06,
      "loss": 0.0106,
      "step": 31450
    },
    {
      "epoch": 4.782146652497343,
      "grad_norm": 0.00033494923263788223,
      "learning_rate": 1.3071200850159406e-06,
      "loss": 0.0174,
      "step": 31500
    },
    {
      "epoch": 4.7897373614695615,
      "grad_norm": 7.433276176452637,
      "learning_rate": 1.2615758311826326e-06,
      "loss": 0.0228,
      "step": 31550
    },
    {
      "epoch": 4.797328070441779,
      "grad_norm": 0.00219224626198411,
      "learning_rate": 1.2160315773493244e-06,
      "loss": 0.0048,
      "step": 31600
    },
    {
      "epoch": 4.804918779413997,
      "grad_norm": 0.0009474735124967992,
      "learning_rate": 1.1704873235160164e-06,
      "loss": 0.0052,
      "step": 31650
    },
    {
      "epoch": 4.812509488386215,
      "grad_norm": 0.0003083623305428773,
      "learning_rate": 1.1249430696827084e-06,
      "loss": 0.0242,
      "step": 31700
    },
    {
      "epoch": 4.820100197358434,
      "grad_norm": 0.0011533264769241214,
      "learning_rate": 1.0793988158494002e-06,
      "loss": 0.0232,
      "step": 31750
    },
    {
      "epoch": 4.827690906330651,
      "grad_norm": 0.006006491836160421,
      "learning_rate": 1.0338545620160922e-06,
      "loss": 0.0172,
      "step": 31800
    },
    {
      "epoch": 4.835281615302869,
      "grad_norm": 0.0011045620776712894,
      "learning_rate": 9.883103081827842e-07,
      "loss": 0.0209,
      "step": 31850
    },
    {
      "epoch": 4.8428723242750875,
      "grad_norm": 0.7837690114974976,
      "learning_rate": 9.427660543494764e-07,
      "loss": 0.0206,
      "step": 31900
    },
    {
      "epoch": 4.850463033247305,
      "grad_norm": 0.0006482937023974955,
      "learning_rate": 8.972218005161682e-07,
      "loss": 0.004,
      "step": 31950
    },
    {
      "epoch": 4.858053742219523,
      "grad_norm": 0.0034765310119837523,
      "learning_rate": 8.516775466828603e-07,
      "loss": 0.0005,
      "step": 32000
    },
    {
      "epoch": 4.865644451191741,
      "grad_norm": 0.0007959179347380996,
      "learning_rate": 8.061332928495522e-07,
      "loss": 0.0118,
      "step": 32050
    },
    {
      "epoch": 4.87323516016396,
      "grad_norm": 0.0004817575099878013,
      "learning_rate": 7.605890390162441e-07,
      "loss": 0.0071,
      "step": 32100
    },
    {
      "epoch": 4.880825869136177,
      "grad_norm": 0.002089662477374077,
      "learning_rate": 7.150447851829361e-07,
      "loss": 0.002,
      "step": 32150
    },
    {
      "epoch": 4.888416578108395,
      "grad_norm": 0.6496542096138,
      "learning_rate": 6.695005313496281e-07,
      "loss": 0.0239,
      "step": 32200
    },
    {
      "epoch": 4.8960072870806135,
      "grad_norm": 0.0007307029445655644,
      "learning_rate": 6.2395627751632e-07,
      "loss": 0.0075,
      "step": 32250
    },
    {
      "epoch": 4.903597996052831,
      "grad_norm": 0.0003593937144614756,
      "learning_rate": 5.78412023683012e-07,
      "loss": 0.0079,
      "step": 32300
    },
    {
      "epoch": 4.911188705025049,
      "grad_norm": 12.04385757446289,
      "learning_rate": 5.328677698497039e-07,
      "loss": 0.0232,
      "step": 32350
    },
    {
      "epoch": 4.918779413997267,
      "grad_norm": 0.04236328974366188,
      "learning_rate": 4.873235160163959e-07,
      "loss": 0.0165,
      "step": 32400
    },
    {
      "epoch": 4.926370122969486,
      "grad_norm": 0.003508802969008684,
      "learning_rate": 4.417792621830879e-07,
      "loss": 0.0112,
      "step": 32450
    },
    {
      "epoch": 4.933960831941703,
      "grad_norm": 0.01512664183974266,
      "learning_rate": 3.962350083497799e-07,
      "loss": 0.0093,
      "step": 32500
    }
  ],
  "logging_steps": 50,
  "max_steps": 32935,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.793715515392e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
