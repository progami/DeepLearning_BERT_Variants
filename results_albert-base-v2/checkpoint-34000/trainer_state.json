{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.9853372434017595,
  "eval_steps": 500,
  "global_step": 34000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007331378299120235,
      "grad_norm": 4.977410793304443,
      "learning_rate": 2.995601173020528e-05,
      "loss": 0.6026,
      "step": 50
    },
    {
      "epoch": 0.01466275659824047,
      "grad_norm": 0.9302943348884583,
      "learning_rate": 2.991202346041056e-05,
      "loss": 0.2617,
      "step": 100
    },
    {
      "epoch": 0.021994134897360705,
      "grad_norm": 8.332456588745117,
      "learning_rate": 2.9868035190615835e-05,
      "loss": 0.2131,
      "step": 150
    },
    {
      "epoch": 0.02932551319648094,
      "grad_norm": 5.111752986907959,
      "learning_rate": 2.9824046920821115e-05,
      "loss": 0.2924,
      "step": 200
    },
    {
      "epoch": 0.036656891495601175,
      "grad_norm": 0.1007736474275589,
      "learning_rate": 2.9780058651026394e-05,
      "loss": 0.2811,
      "step": 250
    },
    {
      "epoch": 0.04398826979472141,
      "grad_norm": 0.0982954278588295,
      "learning_rate": 2.9736070381231673e-05,
      "loss": 0.2671,
      "step": 300
    },
    {
      "epoch": 0.051319648093841645,
      "grad_norm": 4.806332111358643,
      "learning_rate": 2.9692082111436953e-05,
      "loss": 0.3349,
      "step": 350
    },
    {
      "epoch": 0.05865102639296188,
      "grad_norm": 0.1346154808998108,
      "learning_rate": 2.964809384164223e-05,
      "loss": 0.2757,
      "step": 400
    },
    {
      "epoch": 0.06598240469208211,
      "grad_norm": 0.10242219269275665,
      "learning_rate": 2.9604105571847508e-05,
      "loss": 0.3085,
      "step": 450
    },
    {
      "epoch": 0.07331378299120235,
      "grad_norm": 0.15697161853313446,
      "learning_rate": 2.9560117302052787e-05,
      "loss": 0.2926,
      "step": 500
    },
    {
      "epoch": 0.08064516129032258,
      "grad_norm": 0.18236662447452545,
      "learning_rate": 2.9516129032258067e-05,
      "loss": 0.2629,
      "step": 550
    },
    {
      "epoch": 0.08797653958944282,
      "grad_norm": 0.2898983657360077,
      "learning_rate": 2.9472140762463343e-05,
      "loss": 0.2389,
      "step": 600
    },
    {
      "epoch": 0.09530791788856305,
      "grad_norm": 0.04412061348557472,
      "learning_rate": 2.9428152492668622e-05,
      "loss": 0.175,
      "step": 650
    },
    {
      "epoch": 0.10263929618768329,
      "grad_norm": 0.40223565697669983,
      "learning_rate": 2.93841642228739e-05,
      "loss": 0.2258,
      "step": 700
    },
    {
      "epoch": 0.10997067448680352,
      "grad_norm": 0.4648890793323517,
      "learning_rate": 2.934017595307918e-05,
      "loss": 0.2053,
      "step": 750
    },
    {
      "epoch": 0.11730205278592376,
      "grad_norm": 0.04416055604815483,
      "learning_rate": 2.929618768328446e-05,
      "loss": 0.2434,
      "step": 800
    },
    {
      "epoch": 0.12463343108504399,
      "grad_norm": 6.282876968383789,
      "learning_rate": 2.9252199413489736e-05,
      "loss": 0.189,
      "step": 850
    },
    {
      "epoch": 0.13196480938416422,
      "grad_norm": 10.280176162719727,
      "learning_rate": 2.9208211143695016e-05,
      "loss": 0.15,
      "step": 900
    },
    {
      "epoch": 0.13929618768328444,
      "grad_norm": 0.11310596764087677,
      "learning_rate": 2.9164222873900295e-05,
      "loss": 0.2306,
      "step": 950
    },
    {
      "epoch": 0.1466275659824047,
      "grad_norm": 0.07531458139419556,
      "learning_rate": 2.9120234604105574e-05,
      "loss": 0.2235,
      "step": 1000
    },
    {
      "epoch": 0.15395894428152493,
      "grad_norm": 0.3268461525440216,
      "learning_rate": 2.9076246334310854e-05,
      "loss": 0.2006,
      "step": 1050
    },
    {
      "epoch": 0.16129032258064516,
      "grad_norm": 2.250030040740967,
      "learning_rate": 2.903225806451613e-05,
      "loss": 0.2254,
      "step": 1100
    },
    {
      "epoch": 0.16862170087976538,
      "grad_norm": 0.046319980174303055,
      "learning_rate": 2.898826979472141e-05,
      "loss": 0.1739,
      "step": 1150
    },
    {
      "epoch": 0.17595307917888564,
      "grad_norm": 0.9803967475891113,
      "learning_rate": 2.8944281524926688e-05,
      "loss": 0.176,
      "step": 1200
    },
    {
      "epoch": 0.18328445747800587,
      "grad_norm": 0.060880690813064575,
      "learning_rate": 2.8900293255131968e-05,
      "loss": 0.1671,
      "step": 1250
    },
    {
      "epoch": 0.1906158357771261,
      "grad_norm": 0.24424581229686737,
      "learning_rate": 2.8856304985337244e-05,
      "loss": 0.1593,
      "step": 1300
    },
    {
      "epoch": 0.19794721407624633,
      "grad_norm": 17.640689849853516,
      "learning_rate": 2.8812316715542523e-05,
      "loss": 0.1799,
      "step": 1350
    },
    {
      "epoch": 0.20527859237536658,
      "grad_norm": 0.25050684809684753,
      "learning_rate": 2.8768328445747802e-05,
      "loss": 0.1972,
      "step": 1400
    },
    {
      "epoch": 0.2126099706744868,
      "grad_norm": 0.06855261325836182,
      "learning_rate": 2.872434017595308e-05,
      "loss": 0.247,
      "step": 1450
    },
    {
      "epoch": 0.21994134897360704,
      "grad_norm": 10.421142578125,
      "learning_rate": 2.868035190615836e-05,
      "loss": 0.1468,
      "step": 1500
    },
    {
      "epoch": 0.22727272727272727,
      "grad_norm": 8.402139663696289,
      "learning_rate": 2.8636363636363637e-05,
      "loss": 0.1897,
      "step": 1550
    },
    {
      "epoch": 0.23460410557184752,
      "grad_norm": 0.009386277757585049,
      "learning_rate": 2.8592375366568916e-05,
      "loss": 0.1858,
      "step": 1600
    },
    {
      "epoch": 0.24193548387096775,
      "grad_norm": 13.420344352722168,
      "learning_rate": 2.8548387096774196e-05,
      "loss": 0.1982,
      "step": 1650
    },
    {
      "epoch": 0.24926686217008798,
      "grad_norm": 16.88909912109375,
      "learning_rate": 2.8504398826979475e-05,
      "loss": 0.1168,
      "step": 1700
    },
    {
      "epoch": 0.2565982404692082,
      "grad_norm": 4.561285018920898,
      "learning_rate": 2.8460410557184754e-05,
      "loss": 0.2247,
      "step": 1750
    },
    {
      "epoch": 0.26392961876832843,
      "grad_norm": 9.171642303466797,
      "learning_rate": 2.841642228739003e-05,
      "loss": 0.2539,
      "step": 1800
    },
    {
      "epoch": 0.27126099706744866,
      "grad_norm": 0.16617630422115326,
      "learning_rate": 2.837243401759531e-05,
      "loss": 0.2046,
      "step": 1850
    },
    {
      "epoch": 0.2785923753665689,
      "grad_norm": 0.006564566865563393,
      "learning_rate": 2.832844574780059e-05,
      "loss": 0.0957,
      "step": 1900
    },
    {
      "epoch": 0.2859237536656892,
      "grad_norm": 0.04901980236172676,
      "learning_rate": 2.828445747800587e-05,
      "loss": 0.1475,
      "step": 1950
    },
    {
      "epoch": 0.2932551319648094,
      "grad_norm": 15.505196571350098,
      "learning_rate": 2.8240469208211144e-05,
      "loss": 0.2077,
      "step": 2000
    },
    {
      "epoch": 0.30058651026392963,
      "grad_norm": 19.83377456665039,
      "learning_rate": 2.8196480938416424e-05,
      "loss": 0.2494,
      "step": 2050
    },
    {
      "epoch": 0.30791788856304986,
      "grad_norm": 0.07860161364078522,
      "learning_rate": 2.8152492668621703e-05,
      "loss": 0.1787,
      "step": 2100
    },
    {
      "epoch": 0.3152492668621701,
      "grad_norm": 0.04206875339150429,
      "learning_rate": 2.810850439882698e-05,
      "loss": 0.2084,
      "step": 2150
    },
    {
      "epoch": 0.3225806451612903,
      "grad_norm": 26.80065155029297,
      "learning_rate": 2.806451612903226e-05,
      "loss": 0.2082,
      "step": 2200
    },
    {
      "epoch": 0.32991202346041054,
      "grad_norm": 0.03526110202074051,
      "learning_rate": 2.8020527859237534e-05,
      "loss": 0.2038,
      "step": 2250
    },
    {
      "epoch": 0.33724340175953077,
      "grad_norm": 0.03445836156606674,
      "learning_rate": 2.7976539589442814e-05,
      "loss": 0.1815,
      "step": 2300
    },
    {
      "epoch": 0.34457478005865105,
      "grad_norm": 19.30154037475586,
      "learning_rate": 2.7932551319648093e-05,
      "loss": 0.1809,
      "step": 2350
    },
    {
      "epoch": 0.3519061583577713,
      "grad_norm": 22.149608612060547,
      "learning_rate": 2.7888563049853372e-05,
      "loss": 0.1833,
      "step": 2400
    },
    {
      "epoch": 0.3592375366568915,
      "grad_norm": 10.697514533996582,
      "learning_rate": 2.7844574780058652e-05,
      "loss": 0.177,
      "step": 2450
    },
    {
      "epoch": 0.36656891495601174,
      "grad_norm": 14.397747993469238,
      "learning_rate": 2.7800586510263928e-05,
      "loss": 0.1572,
      "step": 2500
    },
    {
      "epoch": 0.37390029325513197,
      "grad_norm": 0.021980734542012215,
      "learning_rate": 2.7756598240469207e-05,
      "loss": 0.1392,
      "step": 2550
    },
    {
      "epoch": 0.3812316715542522,
      "grad_norm": 0.017233628779649734,
      "learning_rate": 2.7712609970674486e-05,
      "loss": 0.1698,
      "step": 2600
    },
    {
      "epoch": 0.3885630498533724,
      "grad_norm": 14.8013916015625,
      "learning_rate": 2.7668621700879766e-05,
      "loss": 0.1651,
      "step": 2650
    },
    {
      "epoch": 0.39589442815249265,
      "grad_norm": 22.39274024963379,
      "learning_rate": 2.7624633431085045e-05,
      "loss": 0.2224,
      "step": 2700
    },
    {
      "epoch": 0.4032258064516129,
      "grad_norm": 0.06739116460084915,
      "learning_rate": 2.758064516129032e-05,
      "loss": 0.1437,
      "step": 2750
    },
    {
      "epoch": 0.41055718475073316,
      "grad_norm": 19.922056198120117,
      "learning_rate": 2.75366568914956e-05,
      "loss": 0.1673,
      "step": 2800
    },
    {
      "epoch": 0.4178885630498534,
      "grad_norm": 0.09933334589004517,
      "learning_rate": 2.749266862170088e-05,
      "loss": 0.2297,
      "step": 2850
    },
    {
      "epoch": 0.4252199413489736,
      "grad_norm": 26.023521423339844,
      "learning_rate": 2.744868035190616e-05,
      "loss": 0.1881,
      "step": 2900
    },
    {
      "epoch": 0.43255131964809385,
      "grad_norm": 0.7038065195083618,
      "learning_rate": 2.7404692082111435e-05,
      "loss": 0.1009,
      "step": 2950
    },
    {
      "epoch": 0.4398826979472141,
      "grad_norm": 0.22644181549549103,
      "learning_rate": 2.7360703812316714e-05,
      "loss": 0.2354,
      "step": 3000
    },
    {
      "epoch": 0.4472140762463343,
      "grad_norm": 0.041593942791223526,
      "learning_rate": 2.7316715542521994e-05,
      "loss": 0.1365,
      "step": 3050
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 0.1170821487903595,
      "learning_rate": 2.7272727272727273e-05,
      "loss": 0.2045,
      "step": 3100
    },
    {
      "epoch": 0.46187683284457476,
      "grad_norm": 5.346038818359375,
      "learning_rate": 2.7228739002932552e-05,
      "loss": 0.1856,
      "step": 3150
    },
    {
      "epoch": 0.46920821114369504,
      "grad_norm": 0.2129475176334381,
      "learning_rate": 2.718475073313783e-05,
      "loss": 0.2146,
      "step": 3200
    },
    {
      "epoch": 0.47653958944281527,
      "grad_norm": 21.780609130859375,
      "learning_rate": 2.7140762463343108e-05,
      "loss": 0.2045,
      "step": 3250
    },
    {
      "epoch": 0.4838709677419355,
      "grad_norm": 11.176115989685059,
      "learning_rate": 2.7096774193548387e-05,
      "loss": 0.1338,
      "step": 3300
    },
    {
      "epoch": 0.4912023460410557,
      "grad_norm": 0.3817802369594574,
      "learning_rate": 2.7052785923753666e-05,
      "loss": 0.2283,
      "step": 3350
    },
    {
      "epoch": 0.49853372434017595,
      "grad_norm": 13.705652236938477,
      "learning_rate": 2.7008797653958946e-05,
      "loss": 0.1975,
      "step": 3400
    },
    {
      "epoch": 0.5058651026392962,
      "grad_norm": 8.926742553710938,
      "learning_rate": 2.6964809384164222e-05,
      "loss": 0.1178,
      "step": 3450
    },
    {
      "epoch": 0.5131964809384164,
      "grad_norm": 0.025323176756501198,
      "learning_rate": 2.69208211143695e-05,
      "loss": 0.1726,
      "step": 3500
    },
    {
      "epoch": 0.5205278592375366,
      "grad_norm": 15.885405540466309,
      "learning_rate": 2.687683284457478e-05,
      "loss": 0.1671,
      "step": 3550
    },
    {
      "epoch": 0.5278592375366569,
      "grad_norm": 0.07547356933355331,
      "learning_rate": 2.683284457478006e-05,
      "loss": 0.1735,
      "step": 3600
    },
    {
      "epoch": 0.5351906158357771,
      "grad_norm": 13.981966972351074,
      "learning_rate": 2.6788856304985336e-05,
      "loss": 0.2119,
      "step": 3650
    },
    {
      "epoch": 0.5425219941348973,
      "grad_norm": 4.722143173217773,
      "learning_rate": 2.6744868035190615e-05,
      "loss": 0.1741,
      "step": 3700
    },
    {
      "epoch": 0.5498533724340176,
      "grad_norm": 28.807817459106445,
      "learning_rate": 2.6700879765395895e-05,
      "loss": 0.2154,
      "step": 3750
    },
    {
      "epoch": 0.5571847507331378,
      "grad_norm": 23.10902976989746,
      "learning_rate": 2.6656891495601174e-05,
      "loss": 0.2039,
      "step": 3800
    },
    {
      "epoch": 0.5645161290322581,
      "grad_norm": 0.1528182029724121,
      "learning_rate": 2.6612903225806453e-05,
      "loss": 0.1765,
      "step": 3850
    },
    {
      "epoch": 0.5718475073313783,
      "grad_norm": 0.08855774253606796,
      "learning_rate": 2.656891495601173e-05,
      "loss": 0.1947,
      "step": 3900
    },
    {
      "epoch": 0.5791788856304986,
      "grad_norm": 0.022111332044005394,
      "learning_rate": 2.652492668621701e-05,
      "loss": 0.1487,
      "step": 3950
    },
    {
      "epoch": 0.5865102639296188,
      "grad_norm": 0.1246219277381897,
      "learning_rate": 2.6480938416422288e-05,
      "loss": 0.145,
      "step": 4000
    },
    {
      "epoch": 0.593841642228739,
      "grad_norm": 0.6055783629417419,
      "learning_rate": 2.6436950146627567e-05,
      "loss": 0.1394,
      "step": 4050
    },
    {
      "epoch": 0.6011730205278593,
      "grad_norm": 0.280404269695282,
      "learning_rate": 2.6392961876832847e-05,
      "loss": 0.1758,
      "step": 4100
    },
    {
      "epoch": 0.6085043988269795,
      "grad_norm": 21.21718406677246,
      "learning_rate": 2.6348973607038123e-05,
      "loss": 0.1497,
      "step": 4150
    },
    {
      "epoch": 0.6158357771260997,
      "grad_norm": 11.284147262573242,
      "learning_rate": 2.6304985337243402e-05,
      "loss": 0.1443,
      "step": 4200
    },
    {
      "epoch": 0.6231671554252199,
      "grad_norm": 14.921070098876953,
      "learning_rate": 2.626099706744868e-05,
      "loss": 0.1796,
      "step": 4250
    },
    {
      "epoch": 0.6304985337243402,
      "grad_norm": 0.18058666586875916,
      "learning_rate": 2.621700879765396e-05,
      "loss": 0.201,
      "step": 4300
    },
    {
      "epoch": 0.6378299120234604,
      "grad_norm": 0.060482386499643326,
      "learning_rate": 2.617302052785924e-05,
      "loss": 0.1625,
      "step": 4350
    },
    {
      "epoch": 0.6451612903225806,
      "grad_norm": 18.87338638305664,
      "learning_rate": 2.6129032258064516e-05,
      "loss": 0.1388,
      "step": 4400
    },
    {
      "epoch": 0.6524926686217009,
      "grad_norm": 0.39924389123916626,
      "learning_rate": 2.6085043988269795e-05,
      "loss": 0.1769,
      "step": 4450
    },
    {
      "epoch": 0.6598240469208211,
      "grad_norm": 2.0280237197875977,
      "learning_rate": 2.6041055718475075e-05,
      "loss": 0.1458,
      "step": 4500
    },
    {
      "epoch": 0.6671554252199413,
      "grad_norm": 0.014004470780491829,
      "learning_rate": 2.5997067448680354e-05,
      "loss": 0.1047,
      "step": 4550
    },
    {
      "epoch": 0.6744868035190615,
      "grad_norm": 5.285965442657471,
      "learning_rate": 2.595307917888563e-05,
      "loss": 0.1008,
      "step": 4600
    },
    {
      "epoch": 0.6818181818181818,
      "grad_norm": 9.907370567321777,
      "learning_rate": 2.590909090909091e-05,
      "loss": 0.1733,
      "step": 4650
    },
    {
      "epoch": 0.6891495601173021,
      "grad_norm": 7.8637590408325195,
      "learning_rate": 2.586510263929619e-05,
      "loss": 0.1236,
      "step": 4700
    },
    {
      "epoch": 0.6964809384164223,
      "grad_norm": 0.13478580117225647,
      "learning_rate": 2.5821114369501468e-05,
      "loss": 0.1612,
      "step": 4750
    },
    {
      "epoch": 0.7038123167155426,
      "grad_norm": 7.577088832855225,
      "learning_rate": 2.5777126099706747e-05,
      "loss": 0.1467,
      "step": 4800
    },
    {
      "epoch": 0.7111436950146628,
      "grad_norm": 0.06431147456169128,
      "learning_rate": 2.5733137829912023e-05,
      "loss": 0.1718,
      "step": 4850
    },
    {
      "epoch": 0.718475073313783,
      "grad_norm": 0.0837397500872612,
      "learning_rate": 2.5689149560117303e-05,
      "loss": 0.157,
      "step": 4900
    },
    {
      "epoch": 0.7258064516129032,
      "grad_norm": 12.89743709564209,
      "learning_rate": 2.5645161290322582e-05,
      "loss": 0.1586,
      "step": 4950
    },
    {
      "epoch": 0.7331378299120235,
      "grad_norm": 33.25824737548828,
      "learning_rate": 2.560117302052786e-05,
      "loss": 0.1533,
      "step": 5000
    },
    {
      "epoch": 0.7404692082111437,
      "grad_norm": 0.025394544005393982,
      "learning_rate": 2.555718475073314e-05,
      "loss": 0.1489,
      "step": 5050
    },
    {
      "epoch": 0.7478005865102639,
      "grad_norm": 16.00102424621582,
      "learning_rate": 2.5513196480938417e-05,
      "loss": 0.1706,
      "step": 5100
    },
    {
      "epoch": 0.7551319648093842,
      "grad_norm": 0.17665816843509674,
      "learning_rate": 2.5469208211143696e-05,
      "loss": 0.2184,
      "step": 5150
    },
    {
      "epoch": 0.7624633431085044,
      "grad_norm": 21.176307678222656,
      "learning_rate": 2.5425219941348975e-05,
      "loss": 0.1162,
      "step": 5200
    },
    {
      "epoch": 0.7697947214076246,
      "grad_norm": 4.664439678192139,
      "learning_rate": 2.5381231671554255e-05,
      "loss": 0.1426,
      "step": 5250
    },
    {
      "epoch": 0.7771260997067448,
      "grad_norm": 7.4770002365112305,
      "learning_rate": 2.533724340175953e-05,
      "loss": 0.1733,
      "step": 5300
    },
    {
      "epoch": 0.7844574780058651,
      "grad_norm": 0.0711633488535881,
      "learning_rate": 2.529325513196481e-05,
      "loss": 0.1546,
      "step": 5350
    },
    {
      "epoch": 0.7917888563049853,
      "grad_norm": 19.09608268737793,
      "learning_rate": 2.524926686217009e-05,
      "loss": 0.1586,
      "step": 5400
    },
    {
      "epoch": 0.7991202346041055,
      "grad_norm": 8.420244216918945,
      "learning_rate": 2.520527859237537e-05,
      "loss": 0.1925,
      "step": 5450
    },
    {
      "epoch": 0.8064516129032258,
      "grad_norm": 0.016016924753785133,
      "learning_rate": 2.5161290322580648e-05,
      "loss": 0.1582,
      "step": 5500
    },
    {
      "epoch": 0.8137829912023461,
      "grad_norm": 0.021489739418029785,
      "learning_rate": 2.5117302052785924e-05,
      "loss": 0.1197,
      "step": 5550
    },
    {
      "epoch": 0.8211143695014663,
      "grad_norm": 5.522714138031006,
      "learning_rate": 2.5073313782991203e-05,
      "loss": 0.2,
      "step": 5600
    },
    {
      "epoch": 0.8284457478005866,
      "grad_norm": 0.1735440045595169,
      "learning_rate": 2.5029325513196483e-05,
      "loss": 0.1598,
      "step": 5650
    },
    {
      "epoch": 0.8357771260997068,
      "grad_norm": 1.0703471899032593,
      "learning_rate": 2.4985337243401762e-05,
      "loss": 0.2313,
      "step": 5700
    },
    {
      "epoch": 0.843108504398827,
      "grad_norm": 19.72575569152832,
      "learning_rate": 2.494134897360704e-05,
      "loss": 0.1119,
      "step": 5750
    },
    {
      "epoch": 0.8504398826979472,
      "grad_norm": 0.45341575145721436,
      "learning_rate": 2.4897360703812317e-05,
      "loss": 0.1043,
      "step": 5800
    },
    {
      "epoch": 0.8577712609970675,
      "grad_norm": 6.462268829345703,
      "learning_rate": 2.4853372434017597e-05,
      "loss": 0.1447,
      "step": 5850
    },
    {
      "epoch": 0.8651026392961877,
      "grad_norm": 8.611952781677246,
      "learning_rate": 2.4809384164222876e-05,
      "loss": 0.1444,
      "step": 5900
    },
    {
      "epoch": 0.8724340175953079,
      "grad_norm": 0.5582795739173889,
      "learning_rate": 2.4765395894428155e-05,
      "loss": 0.1905,
      "step": 5950
    },
    {
      "epoch": 0.8797653958944281,
      "grad_norm": 9.801620483398438,
      "learning_rate": 2.472140762463343e-05,
      "loss": 0.1556,
      "step": 6000
    },
    {
      "epoch": 0.8870967741935484,
      "grad_norm": 15.03403377532959,
      "learning_rate": 2.467741935483871e-05,
      "loss": 0.1163,
      "step": 6050
    },
    {
      "epoch": 0.8944281524926686,
      "grad_norm": 0.00597190298140049,
      "learning_rate": 2.463343108504399e-05,
      "loss": 0.1403,
      "step": 6100
    },
    {
      "epoch": 0.9017595307917888,
      "grad_norm": 1.7748465538024902,
      "learning_rate": 2.458944281524927e-05,
      "loss": 0.2178,
      "step": 6150
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 0.16126278042793274,
      "learning_rate": 2.454545454545455e-05,
      "loss": 0.1721,
      "step": 6200
    },
    {
      "epoch": 0.9164222873900293,
      "grad_norm": 22.191251754760742,
      "learning_rate": 2.4501466275659825e-05,
      "loss": 0.1571,
      "step": 6250
    },
    {
      "epoch": 0.9237536656891495,
      "grad_norm": 0.046970464289188385,
      "learning_rate": 2.4457478005865104e-05,
      "loss": 0.1545,
      "step": 6300
    },
    {
      "epoch": 0.9310850439882697,
      "grad_norm": 0.027524365112185478,
      "learning_rate": 2.4413489736070384e-05,
      "loss": 0.1071,
      "step": 6350
    },
    {
      "epoch": 0.9384164222873901,
      "grad_norm": 1.3556854724884033,
      "learning_rate": 2.436950146627566e-05,
      "loss": 0.2113,
      "step": 6400
    },
    {
      "epoch": 0.9457478005865103,
      "grad_norm": 0.0438324436545372,
      "learning_rate": 2.432551319648094e-05,
      "loss": 0.0944,
      "step": 6450
    },
    {
      "epoch": 0.9530791788856305,
      "grad_norm": 0.24682438373565674,
      "learning_rate": 2.4281524926686215e-05,
      "loss": 0.1612,
      "step": 6500
    },
    {
      "epoch": 0.9604105571847508,
      "grad_norm": 0.011408000253140926,
      "learning_rate": 2.4237536656891494e-05,
      "loss": 0.0762,
      "step": 6550
    },
    {
      "epoch": 0.967741935483871,
      "grad_norm": 0.08236280828714371,
      "learning_rate": 2.4193548387096773e-05,
      "loss": 0.1416,
      "step": 6600
    },
    {
      "epoch": 0.9750733137829912,
      "grad_norm": 0.16168522834777832,
      "learning_rate": 2.4149560117302053e-05,
      "loss": 0.1185,
      "step": 6650
    },
    {
      "epoch": 0.9824046920821115,
      "grad_norm": 0.9949011206626892,
      "learning_rate": 2.4105571847507332e-05,
      "loss": 0.1471,
      "step": 6700
    },
    {
      "epoch": 0.9897360703812317,
      "grad_norm": 0.7017932534217834,
      "learning_rate": 2.4061583577712608e-05,
      "loss": 0.2212,
      "step": 6750
    },
    {
      "epoch": 0.9970674486803519,
      "grad_norm": 8.890881538391113,
      "learning_rate": 2.4017595307917888e-05,
      "loss": 0.1305,
      "step": 6800
    },
    {
      "epoch": 1.0,
      "eval_runtime": 47.6765,
      "eval_samples_per_second": 581.104,
      "eval_steps_per_second": 36.328,
      "step": 6820
    },
    {
      "epoch": 1.0043988269794721,
      "grad_norm": 8.309443473815918,
      "learning_rate": 2.3973607038123167e-05,
      "loss": 0.08,
      "step": 6850
    },
    {
      "epoch": 1.0117302052785924,
      "grad_norm": 13.987114906311035,
      "learning_rate": 2.3929618768328446e-05,
      "loss": 0.0967,
      "step": 6900
    },
    {
      "epoch": 1.0190615835777126,
      "grad_norm": 0.10244393348693848,
      "learning_rate": 2.3885630498533722e-05,
      "loss": 0.1155,
      "step": 6950
    },
    {
      "epoch": 1.0263929618768328,
      "grad_norm": 11.176668167114258,
      "learning_rate": 2.3841642228739e-05,
      "loss": 0.1109,
      "step": 7000
    },
    {
      "epoch": 1.033724340175953,
      "grad_norm": 0.14307801425457,
      "learning_rate": 2.379765395894428e-05,
      "loss": 0.1533,
      "step": 7050
    },
    {
      "epoch": 1.0410557184750733,
      "grad_norm": 2.9410088062286377,
      "learning_rate": 2.375366568914956e-05,
      "loss": 0.1531,
      "step": 7100
    },
    {
      "epoch": 1.0483870967741935,
      "grad_norm": 10.913891792297363,
      "learning_rate": 2.370967741935484e-05,
      "loss": 0.0981,
      "step": 7150
    },
    {
      "epoch": 1.0557184750733137,
      "grad_norm": 0.005951251834630966,
      "learning_rate": 2.3665689149560116e-05,
      "loss": 0.1196,
      "step": 7200
    },
    {
      "epoch": 1.063049853372434,
      "grad_norm": 41.929561614990234,
      "learning_rate": 2.3621700879765395e-05,
      "loss": 0.0871,
      "step": 7250
    },
    {
      "epoch": 1.0703812316715542,
      "grad_norm": 9.318648338317871,
      "learning_rate": 2.3577712609970674e-05,
      "loss": 0.1038,
      "step": 7300
    },
    {
      "epoch": 1.0777126099706744,
      "grad_norm": 6.903491973876953,
      "learning_rate": 2.3533724340175954e-05,
      "loss": 0.0767,
      "step": 7350
    },
    {
      "epoch": 1.0850439882697946,
      "grad_norm": 0.006530991289764643,
      "learning_rate": 2.3489736070381233e-05,
      "loss": 0.0938,
      "step": 7400
    },
    {
      "epoch": 1.0923753665689149,
      "grad_norm": 5.4708943367004395,
      "learning_rate": 2.344574780058651e-05,
      "loss": 0.1326,
      "step": 7450
    },
    {
      "epoch": 1.099706744868035,
      "grad_norm": 0.0034849648363888264,
      "learning_rate": 2.3401759530791788e-05,
      "loss": 0.0932,
      "step": 7500
    },
    {
      "epoch": 1.1070381231671553,
      "grad_norm": 5.749424934387207,
      "learning_rate": 2.3357771260997068e-05,
      "loss": 0.087,
      "step": 7550
    },
    {
      "epoch": 1.1143695014662756,
      "grad_norm": 4.466526508331299,
      "learning_rate": 2.3313782991202347e-05,
      "loss": 0.1087,
      "step": 7600
    },
    {
      "epoch": 1.1217008797653958,
      "grad_norm": 0.29942598938941956,
      "learning_rate": 2.3269794721407623e-05,
      "loss": 0.1405,
      "step": 7650
    },
    {
      "epoch": 1.129032258064516,
      "grad_norm": 3.2170281410217285,
      "learning_rate": 2.3225806451612902e-05,
      "loss": 0.135,
      "step": 7700
    },
    {
      "epoch": 1.1363636363636362,
      "grad_norm": 41.4887809753418,
      "learning_rate": 2.318181818181818e-05,
      "loss": 0.1021,
      "step": 7750
    },
    {
      "epoch": 1.1436950146627567,
      "grad_norm": 23.051132202148438,
      "learning_rate": 2.313782991202346e-05,
      "loss": 0.1411,
      "step": 7800
    },
    {
      "epoch": 1.151026392961877,
      "grad_norm": 0.015324418433010578,
      "learning_rate": 2.309384164222874e-05,
      "loss": 0.0709,
      "step": 7850
    },
    {
      "epoch": 1.1583577712609971,
      "grad_norm": 0.016770118847489357,
      "learning_rate": 2.3049853372434016e-05,
      "loss": 0.1067,
      "step": 7900
    },
    {
      "epoch": 1.1656891495601174,
      "grad_norm": 12.29745101928711,
      "learning_rate": 2.3005865102639296e-05,
      "loss": 0.1183,
      "step": 7950
    },
    {
      "epoch": 1.1730205278592376,
      "grad_norm": 0.04662388563156128,
      "learning_rate": 2.2961876832844575e-05,
      "loss": 0.1163,
      "step": 8000
    },
    {
      "epoch": 1.1803519061583578,
      "grad_norm": 0.006793919950723648,
      "learning_rate": 2.2917888563049854e-05,
      "loss": 0.1055,
      "step": 8050
    },
    {
      "epoch": 1.187683284457478,
      "grad_norm": 4.187164306640625,
      "learning_rate": 2.2873900293255134e-05,
      "loss": 0.1373,
      "step": 8100
    },
    {
      "epoch": 1.1950146627565983,
      "grad_norm": 0.04558314010500908,
      "learning_rate": 2.282991202346041e-05,
      "loss": 0.1627,
      "step": 8150
    },
    {
      "epoch": 1.2023460410557185,
      "grad_norm": 2.013622283935547,
      "learning_rate": 2.278592375366569e-05,
      "loss": 0.1263,
      "step": 8200
    },
    {
      "epoch": 1.2096774193548387,
      "grad_norm": 27.054567337036133,
      "learning_rate": 2.274193548387097e-05,
      "loss": 0.1455,
      "step": 8250
    },
    {
      "epoch": 1.217008797653959,
      "grad_norm": 0.00670067872852087,
      "learning_rate": 2.2697947214076248e-05,
      "loss": 0.1391,
      "step": 8300
    },
    {
      "epoch": 1.2243401759530792,
      "grad_norm": 0.4256654679775238,
      "learning_rate": 2.2653958944281524e-05,
      "loss": 0.1321,
      "step": 8350
    },
    {
      "epoch": 1.2316715542521994,
      "grad_norm": 0.18773895502090454,
      "learning_rate": 2.2609970674486803e-05,
      "loss": 0.1256,
      "step": 8400
    },
    {
      "epoch": 1.2390029325513197,
      "grad_norm": 0.04699772968888283,
      "learning_rate": 2.2565982404692082e-05,
      "loss": 0.1364,
      "step": 8450
    },
    {
      "epoch": 1.2463343108504399,
      "grad_norm": 10.850472450256348,
      "learning_rate": 2.2521994134897362e-05,
      "loss": 0.1105,
      "step": 8500
    },
    {
      "epoch": 1.2536656891495601,
      "grad_norm": 0.047292884439229965,
      "learning_rate": 2.247800586510264e-05,
      "loss": 0.1423,
      "step": 8550
    },
    {
      "epoch": 1.2609970674486803,
      "grad_norm": 0.0351252518594265,
      "learning_rate": 2.2434017595307917e-05,
      "loss": 0.0926,
      "step": 8600
    },
    {
      "epoch": 1.2683284457478006,
      "grad_norm": 0.16261735558509827,
      "learning_rate": 2.2390029325513196e-05,
      "loss": 0.1206,
      "step": 8650
    },
    {
      "epoch": 1.2756598240469208,
      "grad_norm": 0.06325104087591171,
      "learning_rate": 2.2346041055718476e-05,
      "loss": 0.1364,
      "step": 8700
    },
    {
      "epoch": 1.282991202346041,
      "grad_norm": 13.189055442810059,
      "learning_rate": 2.2302052785923755e-05,
      "loss": 0.1221,
      "step": 8750
    },
    {
      "epoch": 1.2903225806451613,
      "grad_norm": 1.4769091606140137,
      "learning_rate": 2.2258064516129034e-05,
      "loss": 0.0969,
      "step": 8800
    },
    {
      "epoch": 1.2976539589442815,
      "grad_norm": 0.36006540060043335,
      "learning_rate": 2.221407624633431e-05,
      "loss": 0.0866,
      "step": 8850
    },
    {
      "epoch": 1.3049853372434017,
      "grad_norm": 0.0543166846036911,
      "learning_rate": 2.217008797653959e-05,
      "loss": 0.0772,
      "step": 8900
    },
    {
      "epoch": 1.312316715542522,
      "grad_norm": 24.82634162902832,
      "learning_rate": 2.212609970674487e-05,
      "loss": 0.1034,
      "step": 8950
    },
    {
      "epoch": 1.3196480938416422,
      "grad_norm": 0.20559079945087433,
      "learning_rate": 2.208211143695015e-05,
      "loss": 0.1458,
      "step": 9000
    },
    {
      "epoch": 1.3269794721407624,
      "grad_norm": 0.005281560122966766,
      "learning_rate": 2.2038123167155428e-05,
      "loss": 0.0904,
      "step": 9050
    },
    {
      "epoch": 1.3343108504398826,
      "grad_norm": 0.022849824279546738,
      "learning_rate": 2.1994134897360704e-05,
      "loss": 0.1105,
      "step": 9100
    },
    {
      "epoch": 1.3416422287390029,
      "grad_norm": 0.00721524516120553,
      "learning_rate": 2.1950146627565983e-05,
      "loss": 0.0845,
      "step": 9150
    },
    {
      "epoch": 1.3489736070381233,
      "grad_norm": 8.255581855773926,
      "learning_rate": 2.1906158357771262e-05,
      "loss": 0.1275,
      "step": 9200
    },
    {
      "epoch": 1.3563049853372435,
      "grad_norm": 0.050239019095897675,
      "learning_rate": 2.1862170087976542e-05,
      "loss": 0.0915,
      "step": 9250
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 1.4293181896209717,
      "learning_rate": 2.1818181818181818e-05,
      "loss": 0.0979,
      "step": 9300
    },
    {
      "epoch": 1.370967741935484,
      "grad_norm": 25.02187728881836,
      "learning_rate": 2.1774193548387097e-05,
      "loss": 0.1132,
      "step": 9350
    },
    {
      "epoch": 1.3782991202346042,
      "grad_norm": 0.0034894575364887714,
      "learning_rate": 2.1730205278592377e-05,
      "loss": 0.1011,
      "step": 9400
    },
    {
      "epoch": 1.3856304985337244,
      "grad_norm": 1.5656459331512451,
      "learning_rate": 2.1686217008797656e-05,
      "loss": 0.1433,
      "step": 9450
    },
    {
      "epoch": 1.3929618768328447,
      "grad_norm": 0.5261728763580322,
      "learning_rate": 2.1642228739002935e-05,
      "loss": 0.0933,
      "step": 9500
    },
    {
      "epoch": 1.400293255131965,
      "grad_norm": 14.08041000366211,
      "learning_rate": 2.159824046920821e-05,
      "loss": 0.151,
      "step": 9550
    },
    {
      "epoch": 1.4076246334310851,
      "grad_norm": 20.563112258911133,
      "learning_rate": 2.155425219941349e-05,
      "loss": 0.112,
      "step": 9600
    },
    {
      "epoch": 1.4149560117302054,
      "grad_norm": 0.011094361543655396,
      "learning_rate": 2.151026392961877e-05,
      "loss": 0.0818,
      "step": 9650
    },
    {
      "epoch": 1.4222873900293256,
      "grad_norm": 0.07618272304534912,
      "learning_rate": 2.146627565982405e-05,
      "loss": 0.0893,
      "step": 9700
    },
    {
      "epoch": 1.4296187683284458,
      "grad_norm": 16.651411056518555,
      "learning_rate": 2.142228739002933e-05,
      "loss": 0.1186,
      "step": 9750
    },
    {
      "epoch": 1.436950146627566,
      "grad_norm": 7.942343711853027,
      "learning_rate": 2.1378299120234605e-05,
      "loss": 0.1129,
      "step": 9800
    },
    {
      "epoch": 1.4442815249266863,
      "grad_norm": 23.345165252685547,
      "learning_rate": 2.1334310850439884e-05,
      "loss": 0.0793,
      "step": 9850
    },
    {
      "epoch": 1.4516129032258065,
      "grad_norm": 10.210565567016602,
      "learning_rate": 2.1290322580645163e-05,
      "loss": 0.1267,
      "step": 9900
    },
    {
      "epoch": 1.4589442815249267,
      "grad_norm": 0.02087545394897461,
      "learning_rate": 2.1246334310850443e-05,
      "loss": 0.0783,
      "step": 9950
    },
    {
      "epoch": 1.466275659824047,
      "grad_norm": 2.1766507625579834,
      "learning_rate": 2.120234604105572e-05,
      "loss": 0.1129,
      "step": 10000
    },
    {
      "epoch": 1.4736070381231672,
      "grad_norm": 14.092883110046387,
      "learning_rate": 2.1158357771260998e-05,
      "loss": 0.053,
      "step": 10050
    },
    {
      "epoch": 1.4809384164222874,
      "grad_norm": 30.84293556213379,
      "learning_rate": 2.1114369501466277e-05,
      "loss": 0.173,
      "step": 10100
    },
    {
      "epoch": 1.4882697947214076,
      "grad_norm": 0.1710246205329895,
      "learning_rate": 2.1070381231671557e-05,
      "loss": 0.0879,
      "step": 10150
    },
    {
      "epoch": 1.4956011730205279,
      "grad_norm": 1.4655483961105347,
      "learning_rate": 2.1026392961876836e-05,
      "loss": 0.1397,
      "step": 10200
    },
    {
      "epoch": 1.502932551319648,
      "grad_norm": 0.01752862147986889,
      "learning_rate": 2.0982404692082112e-05,
      "loss": 0.1283,
      "step": 10250
    },
    {
      "epoch": 1.5102639296187683,
      "grad_norm": 0.03907625004649162,
      "learning_rate": 2.093841642228739e-05,
      "loss": 0.1661,
      "step": 10300
    },
    {
      "epoch": 1.5175953079178885,
      "grad_norm": 11.571709632873535,
      "learning_rate": 2.089442815249267e-05,
      "loss": 0.1535,
      "step": 10350
    },
    {
      "epoch": 1.5249266862170088,
      "grad_norm": 0.006580608896911144,
      "learning_rate": 2.085043988269795e-05,
      "loss": 0.055,
      "step": 10400
    },
    {
      "epoch": 1.532258064516129,
      "grad_norm": 0.02790054865181446,
      "learning_rate": 2.080645161290323e-05,
      "loss": 0.1408,
      "step": 10450
    },
    {
      "epoch": 1.5395894428152492,
      "grad_norm": 0.02725743129849434,
      "learning_rate": 2.0762463343108505e-05,
      "loss": 0.1039,
      "step": 10500
    },
    {
      "epoch": 1.5469208211143695,
      "grad_norm": 0.014163626357913017,
      "learning_rate": 2.0718475073313785e-05,
      "loss": 0.0963,
      "step": 10550
    },
    {
      "epoch": 1.5542521994134897,
      "grad_norm": 9.390986442565918,
      "learning_rate": 2.0674486803519064e-05,
      "loss": 0.1206,
      "step": 10600
    },
    {
      "epoch": 1.56158357771261,
      "grad_norm": 10.675066947937012,
      "learning_rate": 2.0630498533724343e-05,
      "loss": 0.124,
      "step": 10650
    },
    {
      "epoch": 1.5689149560117301,
      "grad_norm": 6.7687859535217285,
      "learning_rate": 2.058651026392962e-05,
      "loss": 0.138,
      "step": 10700
    },
    {
      "epoch": 1.5762463343108504,
      "grad_norm": 16.64919090270996,
      "learning_rate": 2.0542521994134895e-05,
      "loss": 0.1002,
      "step": 10750
    },
    {
      "epoch": 1.5835777126099706,
      "grad_norm": 10.278915405273438,
      "learning_rate": 2.0498533724340175e-05,
      "loss": 0.1232,
      "step": 10800
    },
    {
      "epoch": 1.5909090909090908,
      "grad_norm": 9.278386116027832,
      "learning_rate": 2.0454545454545454e-05,
      "loss": 0.1223,
      "step": 10850
    },
    {
      "epoch": 1.598240469208211,
      "grad_norm": 0.014997952617704868,
      "learning_rate": 2.0410557184750733e-05,
      "loss": 0.1478,
      "step": 10900
    },
    {
      "epoch": 1.6055718475073313,
      "grad_norm": 0.044325586408376694,
      "learning_rate": 2.036656891495601e-05,
      "loss": 0.1126,
      "step": 10950
    },
    {
      "epoch": 1.6129032258064515,
      "grad_norm": 35.99739074707031,
      "learning_rate": 2.032258064516129e-05,
      "loss": 0.1263,
      "step": 11000
    },
    {
      "epoch": 1.6202346041055717,
      "grad_norm": 0.0125845642760396,
      "learning_rate": 2.0278592375366568e-05,
      "loss": 0.0508,
      "step": 11050
    },
    {
      "epoch": 1.627565982404692,
      "grad_norm": 3.207034111022949,
      "learning_rate": 2.0234604105571847e-05,
      "loss": 0.1044,
      "step": 11100
    },
    {
      "epoch": 1.6348973607038122,
      "grad_norm": 0.0341702364385128,
      "learning_rate": 2.0190615835777127e-05,
      "loss": 0.0561,
      "step": 11150
    },
    {
      "epoch": 1.6422287390029324,
      "grad_norm": 11.242813110351562,
      "learning_rate": 2.0146627565982403e-05,
      "loss": 0.0814,
      "step": 11200
    },
    {
      "epoch": 1.6495601173020527,
      "grad_norm": 17.36420440673828,
      "learning_rate": 2.0102639296187682e-05,
      "loss": 0.1022,
      "step": 11250
    },
    {
      "epoch": 1.6568914956011729,
      "grad_norm": 1.0301949977874756,
      "learning_rate": 2.005865102639296e-05,
      "loss": 0.105,
      "step": 11300
    },
    {
      "epoch": 1.664222873900293,
      "grad_norm": 35.837646484375,
      "learning_rate": 2.001466275659824e-05,
      "loss": 0.1183,
      "step": 11350
    },
    {
      "epoch": 1.6715542521994133,
      "grad_norm": 0.014812069945037365,
      "learning_rate": 1.997067448680352e-05,
      "loss": 0.0674,
      "step": 11400
    },
    {
      "epoch": 1.6788856304985336,
      "grad_norm": 0.020199285820126534,
      "learning_rate": 1.9926686217008796e-05,
      "loss": 0.1183,
      "step": 11450
    },
    {
      "epoch": 1.6862170087976538,
      "grad_norm": 0.00647735595703125,
      "learning_rate": 1.9882697947214075e-05,
      "loss": 0.1003,
      "step": 11500
    },
    {
      "epoch": 1.6935483870967742,
      "grad_norm": 0.12548446655273438,
      "learning_rate": 1.9838709677419355e-05,
      "loss": 0.1212,
      "step": 11550
    },
    {
      "epoch": 1.7008797653958945,
      "grad_norm": 0.02444332465529442,
      "learning_rate": 1.9794721407624634e-05,
      "loss": 0.105,
      "step": 11600
    },
    {
      "epoch": 1.7082111436950147,
      "grad_norm": 28.973800659179688,
      "learning_rate": 1.975073313782991e-05,
      "loss": 0.0958,
      "step": 11650
    },
    {
      "epoch": 1.715542521994135,
      "grad_norm": 0.5790404677391052,
      "learning_rate": 1.970674486803519e-05,
      "loss": 0.1379,
      "step": 11700
    },
    {
      "epoch": 1.7228739002932552,
      "grad_norm": 0.17359280586242676,
      "learning_rate": 1.966275659824047e-05,
      "loss": 0.1309,
      "step": 11750
    },
    {
      "epoch": 1.7302052785923754,
      "grad_norm": 3.124181032180786,
      "learning_rate": 1.9618768328445748e-05,
      "loss": 0.1298,
      "step": 11800
    },
    {
      "epoch": 1.7375366568914956,
      "grad_norm": 27.190174102783203,
      "learning_rate": 1.9574780058651027e-05,
      "loss": 0.0863,
      "step": 11850
    },
    {
      "epoch": 1.7448680351906158,
      "grad_norm": 0.01588437519967556,
      "learning_rate": 1.9530791788856303e-05,
      "loss": 0.1102,
      "step": 11900
    },
    {
      "epoch": 1.752199413489736,
      "grad_norm": 5.901956558227539,
      "learning_rate": 1.9486803519061583e-05,
      "loss": 0.1545,
      "step": 11950
    },
    {
      "epoch": 1.7595307917888563,
      "grad_norm": 19.301834106445312,
      "learning_rate": 1.9442815249266862e-05,
      "loss": 0.0647,
      "step": 12000
    },
    {
      "epoch": 1.7668621700879765,
      "grad_norm": 0.009426855482161045,
      "learning_rate": 1.939882697947214e-05,
      "loss": 0.0578,
      "step": 12050
    },
    {
      "epoch": 1.7741935483870968,
      "grad_norm": 20.151500701904297,
      "learning_rate": 1.935483870967742e-05,
      "loss": 0.1295,
      "step": 12100
    },
    {
      "epoch": 1.781524926686217,
      "grad_norm": 0.3087308406829834,
      "learning_rate": 1.9310850439882697e-05,
      "loss": 0.1044,
      "step": 12150
    },
    {
      "epoch": 1.7888563049853372,
      "grad_norm": 14.65578556060791,
      "learning_rate": 1.9266862170087976e-05,
      "loss": 0.0847,
      "step": 12200
    },
    {
      "epoch": 1.7961876832844574,
      "grad_norm": 6.7161970138549805,
      "learning_rate": 1.9222873900293255e-05,
      "loss": 0.097,
      "step": 12250
    },
    {
      "epoch": 1.8035190615835777,
      "grad_norm": 10.072172164916992,
      "learning_rate": 1.9178885630498535e-05,
      "loss": 0.0726,
      "step": 12300
    },
    {
      "epoch": 1.810850439882698,
      "grad_norm": 0.005509395617991686,
      "learning_rate": 1.913489736070381e-05,
      "loss": 0.0837,
      "step": 12350
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 24.578012466430664,
      "learning_rate": 1.909090909090909e-05,
      "loss": 0.1279,
      "step": 12400
    },
    {
      "epoch": 1.8255131964809386,
      "grad_norm": 0.09563612937927246,
      "learning_rate": 1.904692082111437e-05,
      "loss": 0.158,
      "step": 12450
    },
    {
      "epoch": 1.8328445747800588,
      "grad_norm": 0.07367972284555435,
      "learning_rate": 1.900293255131965e-05,
      "loss": 0.0603,
      "step": 12500
    },
    {
      "epoch": 1.840175953079179,
      "grad_norm": 7.631824493408203,
      "learning_rate": 1.8958944281524928e-05,
      "loss": 0.091,
      "step": 12550
    },
    {
      "epoch": 1.8475073313782993,
      "grad_norm": 0.01660243235528469,
      "learning_rate": 1.8914956011730204e-05,
      "loss": 0.0967,
      "step": 12600
    },
    {
      "epoch": 1.8548387096774195,
      "grad_norm": 0.04085523635149002,
      "learning_rate": 1.8870967741935484e-05,
      "loss": 0.081,
      "step": 12650
    },
    {
      "epoch": 1.8621700879765397,
      "grad_norm": 0.04081275314092636,
      "learning_rate": 1.8826979472140763e-05,
      "loss": 0.1408,
      "step": 12700
    },
    {
      "epoch": 1.86950146627566,
      "grad_norm": 0.7960093021392822,
      "learning_rate": 1.8782991202346042e-05,
      "loss": 0.0886,
      "step": 12750
    },
    {
      "epoch": 1.8768328445747802,
      "grad_norm": 0.21243612468242645,
      "learning_rate": 1.873900293255132e-05,
      "loss": 0.1424,
      "step": 12800
    },
    {
      "epoch": 1.8841642228739004,
      "grad_norm": 0.06564406305551529,
      "learning_rate": 1.8695014662756598e-05,
      "loss": 0.1263,
      "step": 12850
    },
    {
      "epoch": 1.8914956011730206,
      "grad_norm": 3.5624327659606934,
      "learning_rate": 1.8651026392961877e-05,
      "loss": 0.1117,
      "step": 12900
    },
    {
      "epoch": 1.8988269794721409,
      "grad_norm": 0.0651668980717659,
      "learning_rate": 1.8607038123167156e-05,
      "loss": 0.0774,
      "step": 12950
    },
    {
      "epoch": 1.906158357771261,
      "grad_norm": 17.560558319091797,
      "learning_rate": 1.8563049853372436e-05,
      "loss": 0.1213,
      "step": 13000
    },
    {
      "epoch": 1.9134897360703813,
      "grad_norm": 0.030688753351569176,
      "learning_rate": 1.8519061583577715e-05,
      "loss": 0.0721,
      "step": 13050
    },
    {
      "epoch": 1.9208211143695015,
      "grad_norm": 11.608702659606934,
      "learning_rate": 1.847507331378299e-05,
      "loss": 0.1203,
      "step": 13100
    },
    {
      "epoch": 1.9281524926686218,
      "grad_norm": 0.012722871266305447,
      "learning_rate": 1.843108504398827e-05,
      "loss": 0.1045,
      "step": 13150
    },
    {
      "epoch": 1.935483870967742,
      "grad_norm": 0.002522733062505722,
      "learning_rate": 1.838709677419355e-05,
      "loss": 0.0729,
      "step": 13200
    },
    {
      "epoch": 1.9428152492668622,
      "grad_norm": 0.025826310738921165,
      "learning_rate": 1.834310850439883e-05,
      "loss": 0.0607,
      "step": 13250
    },
    {
      "epoch": 1.9501466275659824,
      "grad_norm": 8.444342613220215,
      "learning_rate": 1.8299120234604105e-05,
      "loss": 0.1126,
      "step": 13300
    },
    {
      "epoch": 1.9574780058651027,
      "grad_norm": 16.438644409179688,
      "learning_rate": 1.8255131964809384e-05,
      "loss": 0.1401,
      "step": 13350
    },
    {
      "epoch": 1.964809384164223,
      "grad_norm": 18.677885055541992,
      "learning_rate": 1.8211143695014664e-05,
      "loss": 0.073,
      "step": 13400
    },
    {
      "epoch": 1.9721407624633431,
      "grad_norm": 14.030224800109863,
      "learning_rate": 1.8167155425219943e-05,
      "loss": 0.0882,
      "step": 13450
    },
    {
      "epoch": 1.9794721407624634,
      "grad_norm": 0.04740807041525841,
      "learning_rate": 1.8123167155425222e-05,
      "loss": 0.1003,
      "step": 13500
    },
    {
      "epoch": 1.9868035190615836,
      "grad_norm": 0.056565213948488235,
      "learning_rate": 1.8079178885630498e-05,
      "loss": 0.0839,
      "step": 13550
    },
    {
      "epoch": 1.9941348973607038,
      "grad_norm": 6.489485263824463,
      "learning_rate": 1.8035190615835778e-05,
      "loss": 0.138,
      "step": 13600
    },
    {
      "epoch": 2.0,
      "eval_runtime": 47.6504,
      "eval_samples_per_second": 581.422,
      "eval_steps_per_second": 36.348,
      "step": 13640
    },
    {
      "epoch": 2.001466275659824,
      "grad_norm": 0.9816913604736328,
      "learning_rate": 1.7991202346041057e-05,
      "loss": 0.0919,
      "step": 13650
    },
    {
      "epoch": 2.0087976539589443,
      "grad_norm": 0.04781622812151909,
      "learning_rate": 1.7947214076246336e-05,
      "loss": 0.0562,
      "step": 13700
    },
    {
      "epoch": 2.0161290322580645,
      "grad_norm": 0.00595352565869689,
      "learning_rate": 1.7903225806451616e-05,
      "loss": 0.0534,
      "step": 13750
    },
    {
      "epoch": 2.0234604105571847,
      "grad_norm": 34.739131927490234,
      "learning_rate": 1.785923753665689e-05,
      "loss": 0.0982,
      "step": 13800
    },
    {
      "epoch": 2.030791788856305,
      "grad_norm": 0.022951720282435417,
      "learning_rate": 1.781524926686217e-05,
      "loss": 0.0506,
      "step": 13850
    },
    {
      "epoch": 2.038123167155425,
      "grad_norm": 0.08547830581665039,
      "learning_rate": 1.777126099706745e-05,
      "loss": 0.0676,
      "step": 13900
    },
    {
      "epoch": 2.0454545454545454,
      "grad_norm": 3.030651569366455,
      "learning_rate": 1.772727272727273e-05,
      "loss": 0.0697,
      "step": 13950
    },
    {
      "epoch": 2.0527859237536656,
      "grad_norm": 9.978283882141113,
      "learning_rate": 1.7683284457478006e-05,
      "loss": 0.0506,
      "step": 14000
    },
    {
      "epoch": 2.060117302052786,
      "grad_norm": 20.97475242614746,
      "learning_rate": 1.7639296187683285e-05,
      "loss": 0.0527,
      "step": 14050
    },
    {
      "epoch": 2.067448680351906,
      "grad_norm": 0.002054742071777582,
      "learning_rate": 1.7595307917888564e-05,
      "loss": 0.0639,
      "step": 14100
    },
    {
      "epoch": 2.0747800586510263,
      "grad_norm": 20.949729919433594,
      "learning_rate": 1.7551319648093844e-05,
      "loss": 0.0724,
      "step": 14150
    },
    {
      "epoch": 2.0821114369501466,
      "grad_norm": 14.265746116638184,
      "learning_rate": 1.7507331378299123e-05,
      "loss": 0.0802,
      "step": 14200
    },
    {
      "epoch": 2.089442815249267,
      "grad_norm": 0.015605601482093334,
      "learning_rate": 1.74633431085044e-05,
      "loss": 0.0731,
      "step": 14250
    },
    {
      "epoch": 2.096774193548387,
      "grad_norm": 0.005692589096724987,
      "learning_rate": 1.741935483870968e-05,
      "loss": 0.0473,
      "step": 14300
    },
    {
      "epoch": 2.1041055718475072,
      "grad_norm": 0.009382189251482487,
      "learning_rate": 1.7375366568914958e-05,
      "loss": 0.0497,
      "step": 14350
    },
    {
      "epoch": 2.1114369501466275,
      "grad_norm": 14.604148864746094,
      "learning_rate": 1.7331378299120237e-05,
      "loss": 0.0474,
      "step": 14400
    },
    {
      "epoch": 2.1187683284457477,
      "grad_norm": 0.016217254102230072,
      "learning_rate": 1.7287390029325516e-05,
      "loss": 0.0779,
      "step": 14450
    },
    {
      "epoch": 2.126099706744868,
      "grad_norm": 0.02382712811231613,
      "learning_rate": 1.7243401759530792e-05,
      "loss": 0.058,
      "step": 14500
    },
    {
      "epoch": 2.133431085043988,
      "grad_norm": 0.24151715636253357,
      "learning_rate": 1.7199413489736072e-05,
      "loss": 0.0766,
      "step": 14550
    },
    {
      "epoch": 2.1407624633431084,
      "grad_norm": 0.002652440220117569,
      "learning_rate": 1.715542521994135e-05,
      "loss": 0.0203,
      "step": 14600
    },
    {
      "epoch": 2.1480938416422286,
      "grad_norm": 1.3907614946365356,
      "learning_rate": 1.711143695014663e-05,
      "loss": 0.0393,
      "step": 14650
    },
    {
      "epoch": 2.155425219941349,
      "grad_norm": 0.1020440012216568,
      "learning_rate": 1.7067448680351906e-05,
      "loss": 0.054,
      "step": 14700
    },
    {
      "epoch": 2.162756598240469,
      "grad_norm": 0.002573651261627674,
      "learning_rate": 1.7023460410557186e-05,
      "loss": 0.0514,
      "step": 14750
    },
    {
      "epoch": 2.1700879765395893,
      "grad_norm": 0.009179514832794666,
      "learning_rate": 1.6979472140762465e-05,
      "loss": 0.0738,
      "step": 14800
    },
    {
      "epoch": 2.1774193548387095,
      "grad_norm": 4.1407036781311035,
      "learning_rate": 1.6935483870967744e-05,
      "loss": 0.0967,
      "step": 14850
    },
    {
      "epoch": 2.1847507331378297,
      "grad_norm": 0.0020056979265064,
      "learning_rate": 1.6891495601173024e-05,
      "loss": 0.0423,
      "step": 14900
    },
    {
      "epoch": 2.19208211143695,
      "grad_norm": 30.35178565979004,
      "learning_rate": 1.6847507331378296e-05,
      "loss": 0.0709,
      "step": 14950
    },
    {
      "epoch": 2.19941348973607,
      "grad_norm": 0.000924854539334774,
      "learning_rate": 1.6803519061583576e-05,
      "loss": 0.0486,
      "step": 15000
    },
    {
      "epoch": 2.2067448680351904,
      "grad_norm": 0.1909889280796051,
      "learning_rate": 1.6759530791788855e-05,
      "loss": 0.0848,
      "step": 15050
    },
    {
      "epoch": 2.2140762463343107,
      "grad_norm": 36.12922668457031,
      "learning_rate": 1.6715542521994134e-05,
      "loss": 0.0577,
      "step": 15100
    },
    {
      "epoch": 2.221407624633431,
      "grad_norm": 0.2745577096939087,
      "learning_rate": 1.6671554252199414e-05,
      "loss": 0.0876,
      "step": 15150
    },
    {
      "epoch": 2.228739002932551,
      "grad_norm": 0.2645210027694702,
      "learning_rate": 1.662756598240469e-05,
      "loss": 0.0463,
      "step": 15200
    },
    {
      "epoch": 2.236070381231672,
      "grad_norm": 0.532734751701355,
      "learning_rate": 1.658357771260997e-05,
      "loss": 0.1019,
      "step": 15250
    },
    {
      "epoch": 2.2434017595307916,
      "grad_norm": 0.004603259731084108,
      "learning_rate": 1.653958944281525e-05,
      "loss": 0.0659,
      "step": 15300
    },
    {
      "epoch": 2.2507331378299122,
      "grad_norm": 0.007075940724462271,
      "learning_rate": 1.6495601173020528e-05,
      "loss": 0.072,
      "step": 15350
    },
    {
      "epoch": 2.258064516129032,
      "grad_norm": 0.0857788622379303,
      "learning_rate": 1.6451612903225807e-05,
      "loss": 0.0474,
      "step": 15400
    },
    {
      "epoch": 2.2653958944281527,
      "grad_norm": 0.005360568407922983,
      "learning_rate": 1.6407624633431083e-05,
      "loss": 0.0514,
      "step": 15450
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 29.785099029541016,
      "learning_rate": 1.6363636363636363e-05,
      "loss": 0.056,
      "step": 15500
    },
    {
      "epoch": 2.280058651026393,
      "grad_norm": 9.408302307128906,
      "learning_rate": 1.6319648093841642e-05,
      "loss": 0.0446,
      "step": 15550
    },
    {
      "epoch": 2.2873900293255134,
      "grad_norm": 0.15087182819843292,
      "learning_rate": 1.627565982404692e-05,
      "loss": 0.0503,
      "step": 15600
    },
    {
      "epoch": 2.2947214076246336,
      "grad_norm": 0.05465300753712654,
      "learning_rate": 1.6231671554252197e-05,
      "loss": 0.1001,
      "step": 15650
    },
    {
      "epoch": 2.302052785923754,
      "grad_norm": 0.004791829269379377,
      "learning_rate": 1.6187683284457477e-05,
      "loss": 0.0691,
      "step": 15700
    },
    {
      "epoch": 2.309384164222874,
      "grad_norm": 87.01903533935547,
      "learning_rate": 1.6143695014662756e-05,
      "loss": 0.0554,
      "step": 15750
    },
    {
      "epoch": 2.3167155425219943,
      "grad_norm": 0.04337208718061447,
      "learning_rate": 1.6099706744868035e-05,
      "loss": 0.0881,
      "step": 15800
    },
    {
      "epoch": 2.3240469208211145,
      "grad_norm": 7.193863391876221,
      "learning_rate": 1.6055718475073315e-05,
      "loss": 0.0719,
      "step": 15850
    },
    {
      "epoch": 2.3313782991202348,
      "grad_norm": 0.06826901435852051,
      "learning_rate": 1.601173020527859e-05,
      "loss": 0.0523,
      "step": 15900
    },
    {
      "epoch": 2.338709677419355,
      "grad_norm": 5.19249963760376,
      "learning_rate": 1.596774193548387e-05,
      "loss": 0.0593,
      "step": 15950
    },
    {
      "epoch": 2.346041055718475,
      "grad_norm": 13.416834831237793,
      "learning_rate": 1.592375366568915e-05,
      "loss": 0.0818,
      "step": 16000
    },
    {
      "epoch": 2.3533724340175954,
      "grad_norm": 4.512346267700195,
      "learning_rate": 1.587976539589443e-05,
      "loss": 0.0484,
      "step": 16050
    },
    {
      "epoch": 2.3607038123167157,
      "grad_norm": 0.0033589843660593033,
      "learning_rate": 1.5835777126099708e-05,
      "loss": 0.0587,
      "step": 16100
    },
    {
      "epoch": 2.368035190615836,
      "grad_norm": 0.07374323159456253,
      "learning_rate": 1.5791788856304984e-05,
      "loss": 0.0501,
      "step": 16150
    },
    {
      "epoch": 2.375366568914956,
      "grad_norm": 0.011876137927174568,
      "learning_rate": 1.5747800586510263e-05,
      "loss": 0.0665,
      "step": 16200
    },
    {
      "epoch": 2.3826979472140764,
      "grad_norm": 0.000700101547408849,
      "learning_rate": 1.5703812316715543e-05,
      "loss": 0.0445,
      "step": 16250
    },
    {
      "epoch": 2.3900293255131966,
      "grad_norm": 0.001371437101624906,
      "learning_rate": 1.5659824046920822e-05,
      "loss": 0.0459,
      "step": 16300
    },
    {
      "epoch": 2.397360703812317,
      "grad_norm": 17.683788299560547,
      "learning_rate": 1.5615835777126098e-05,
      "loss": 0.082,
      "step": 16350
    },
    {
      "epoch": 2.404692082111437,
      "grad_norm": 0.9969233870506287,
      "learning_rate": 1.5571847507331377e-05,
      "loss": 0.0959,
      "step": 16400
    },
    {
      "epoch": 2.4120234604105573,
      "grad_norm": 0.06698000431060791,
      "learning_rate": 1.5527859237536657e-05,
      "loss": 0.1094,
      "step": 16450
    },
    {
      "epoch": 2.4193548387096775,
      "grad_norm": 0.0045120567083358765,
      "learning_rate": 1.5483870967741936e-05,
      "loss": 0.0432,
      "step": 16500
    },
    {
      "epoch": 2.4266862170087977,
      "grad_norm": 19.901165008544922,
      "learning_rate": 1.5439882697947215e-05,
      "loss": 0.0857,
      "step": 16550
    },
    {
      "epoch": 2.434017595307918,
      "grad_norm": 0.3710833191871643,
      "learning_rate": 1.539589442815249e-05,
      "loss": 0.0794,
      "step": 16600
    },
    {
      "epoch": 2.441348973607038,
      "grad_norm": 0.0050346446223556995,
      "learning_rate": 1.535190615835777e-05,
      "loss": 0.0352,
      "step": 16650
    },
    {
      "epoch": 2.4486803519061584,
      "grad_norm": 0.025634244084358215,
      "learning_rate": 1.530791788856305e-05,
      "loss": 0.0942,
      "step": 16700
    },
    {
      "epoch": 2.4560117302052786,
      "grad_norm": 0.012423574924468994,
      "learning_rate": 1.526392961876833e-05,
      "loss": 0.051,
      "step": 16750
    },
    {
      "epoch": 2.463343108504399,
      "grad_norm": 0.02669071964919567,
      "learning_rate": 1.5219941348973607e-05,
      "loss": 0.068,
      "step": 16800
    },
    {
      "epoch": 2.470674486803519,
      "grad_norm": 76.20748901367188,
      "learning_rate": 1.5175953079178886e-05,
      "loss": 0.04,
      "step": 16850
    },
    {
      "epoch": 2.4780058651026393,
      "grad_norm": 0.03415686637163162,
      "learning_rate": 1.5131964809384164e-05,
      "loss": 0.0723,
      "step": 16900
    },
    {
      "epoch": 2.4853372434017595,
      "grad_norm": 0.014749331399798393,
      "learning_rate": 1.5087976539589443e-05,
      "loss": 0.0642,
      "step": 16950
    },
    {
      "epoch": 2.4926686217008798,
      "grad_norm": 5.390010833740234,
      "learning_rate": 1.5043988269794721e-05,
      "loss": 0.0385,
      "step": 17000
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.0009063410107046366,
      "learning_rate": 1.5e-05,
      "loss": 0.0463,
      "step": 17050
    },
    {
      "epoch": 2.5073313782991202,
      "grad_norm": 1.6007472276687622,
      "learning_rate": 1.495601173020528e-05,
      "loss": 0.0454,
      "step": 17100
    },
    {
      "epoch": 2.5146627565982405,
      "grad_norm": 0.005350090563297272,
      "learning_rate": 1.4912023460410557e-05,
      "loss": 0.0851,
      "step": 17150
    },
    {
      "epoch": 2.5219941348973607,
      "grad_norm": 6.879419803619385,
      "learning_rate": 1.4868035190615837e-05,
      "loss": 0.1124,
      "step": 17200
    },
    {
      "epoch": 2.529325513196481,
      "grad_norm": 18.50111198425293,
      "learning_rate": 1.4824046920821114e-05,
      "loss": 0.058,
      "step": 17250
    },
    {
      "epoch": 2.536656891495601,
      "grad_norm": 0.027335312217473984,
      "learning_rate": 1.4780058651026394e-05,
      "loss": 0.0511,
      "step": 17300
    },
    {
      "epoch": 2.5439882697947214,
      "grad_norm": 0.009072993882000446,
      "learning_rate": 1.4736070381231671e-05,
      "loss": 0.0484,
      "step": 17350
    },
    {
      "epoch": 2.5513196480938416,
      "grad_norm": 117.0725326538086,
      "learning_rate": 1.469208211143695e-05,
      "loss": 0.0904,
      "step": 17400
    },
    {
      "epoch": 2.558651026392962,
      "grad_norm": 26.895605087280273,
      "learning_rate": 1.464809384164223e-05,
      "loss": 0.0708,
      "step": 17450
    },
    {
      "epoch": 2.565982404692082,
      "grad_norm": 0.0045210737735033035,
      "learning_rate": 1.4604105571847508e-05,
      "loss": 0.0472,
      "step": 17500
    },
    {
      "epoch": 2.5733137829912023,
      "grad_norm": 0.015065949410200119,
      "learning_rate": 1.4560117302052787e-05,
      "loss": 0.1132,
      "step": 17550
    },
    {
      "epoch": 2.5806451612903225,
      "grad_norm": 0.020472582429647446,
      "learning_rate": 1.4516129032258065e-05,
      "loss": 0.0803,
      "step": 17600
    },
    {
      "epoch": 2.5879765395894427,
      "grad_norm": 0.09422368556261063,
      "learning_rate": 1.4472140762463344e-05,
      "loss": 0.0738,
      "step": 17650
    },
    {
      "epoch": 2.595307917888563,
      "grad_norm": 20.245201110839844,
      "learning_rate": 1.4428152492668622e-05,
      "loss": 0.0849,
      "step": 17700
    },
    {
      "epoch": 2.602639296187683,
      "grad_norm": 0.3055761456489563,
      "learning_rate": 1.4384164222873901e-05,
      "loss": 0.0475,
      "step": 17750
    },
    {
      "epoch": 2.6099706744868034,
      "grad_norm": 0.01212456077337265,
      "learning_rate": 1.434017595307918e-05,
      "loss": 0.0504,
      "step": 17800
    },
    {
      "epoch": 2.6173020527859236,
      "grad_norm": 0.003941460978239775,
      "learning_rate": 1.4296187683284458e-05,
      "loss": 0.0789,
      "step": 17850
    },
    {
      "epoch": 2.624633431085044,
      "grad_norm": 0.02619924768805504,
      "learning_rate": 1.4252199413489737e-05,
      "loss": 0.098,
      "step": 17900
    },
    {
      "epoch": 2.631964809384164,
      "grad_norm": 0.002015944104641676,
      "learning_rate": 1.4208211143695015e-05,
      "loss": 0.0881,
      "step": 17950
    },
    {
      "epoch": 2.6392961876832843,
      "grad_norm": 0.009807409718632698,
      "learning_rate": 1.4164222873900295e-05,
      "loss": 0.093,
      "step": 18000
    },
    {
      "epoch": 2.6466275659824046,
      "grad_norm": 0.00267576752230525,
      "learning_rate": 1.4120234604105572e-05,
      "loss": 0.089,
      "step": 18050
    },
    {
      "epoch": 2.653958944281525,
      "grad_norm": 2.359663963317871,
      "learning_rate": 1.4076246334310852e-05,
      "loss": 0.0621,
      "step": 18100
    },
    {
      "epoch": 2.661290322580645,
      "grad_norm": 0.008442497812211514,
      "learning_rate": 1.403225806451613e-05,
      "loss": 0.0903,
      "step": 18150
    },
    {
      "epoch": 2.6686217008797652,
      "grad_norm": 21.87571144104004,
      "learning_rate": 1.3988269794721407e-05,
      "loss": 0.0807,
      "step": 18200
    },
    {
      "epoch": 2.6759530791788855,
      "grad_norm": 0.1661665439605713,
      "learning_rate": 1.3944281524926686e-05,
      "loss": 0.0558,
      "step": 18250
    },
    {
      "epoch": 2.6832844574780057,
      "grad_norm": 0.03283488377928734,
      "learning_rate": 1.3900293255131964e-05,
      "loss": 0.0709,
      "step": 18300
    },
    {
      "epoch": 2.690615835777126,
      "grad_norm": 10.197590827941895,
      "learning_rate": 1.3856304985337243e-05,
      "loss": 0.0902,
      "step": 18350
    },
    {
      "epoch": 2.6979472140762466,
      "grad_norm": 0.010968346148729324,
      "learning_rate": 1.3812316715542523e-05,
      "loss": 0.0583,
      "step": 18400
    },
    {
      "epoch": 2.7052785923753664,
      "grad_norm": 32.73064422607422,
      "learning_rate": 1.37683284457478e-05,
      "loss": 0.094,
      "step": 18450
    },
    {
      "epoch": 2.712609970674487,
      "grad_norm": 0.016904231160879135,
      "learning_rate": 1.372434017595308e-05,
      "loss": 0.0551,
      "step": 18500
    },
    {
      "epoch": 2.719941348973607,
      "grad_norm": 9.757433891296387,
      "learning_rate": 1.3680351906158357e-05,
      "loss": 0.0698,
      "step": 18550
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 0.0638880729675293,
      "learning_rate": 1.3636363636363637e-05,
      "loss": 0.0577,
      "step": 18600
    },
    {
      "epoch": 2.7346041055718473,
      "grad_norm": 0.1217617318034172,
      "learning_rate": 1.3592375366568914e-05,
      "loss": 0.0934,
      "step": 18650
    },
    {
      "epoch": 2.741935483870968,
      "grad_norm": 0.04469495639204979,
      "learning_rate": 1.3548387096774194e-05,
      "loss": 0.0274,
      "step": 18700
    },
    {
      "epoch": 2.7492668621700878,
      "grad_norm": 19.32811737060547,
      "learning_rate": 1.3504398826979473e-05,
      "loss": 0.0826,
      "step": 18750
    },
    {
      "epoch": 2.7565982404692084,
      "grad_norm": 0.01960599422454834,
      "learning_rate": 1.346041055718475e-05,
      "loss": 0.0615,
      "step": 18800
    },
    {
      "epoch": 2.763929618768328,
      "grad_norm": 19.799264907836914,
      "learning_rate": 1.341642228739003e-05,
      "loss": 0.0657,
      "step": 18850
    },
    {
      "epoch": 2.771260997067449,
      "grad_norm": 0.09194809198379517,
      "learning_rate": 1.3372434017595308e-05,
      "loss": 0.0871,
      "step": 18900
    },
    {
      "epoch": 2.7785923753665687,
      "grad_norm": 0.004621854051947594,
      "learning_rate": 1.3328445747800587e-05,
      "loss": 0.0302,
      "step": 18950
    },
    {
      "epoch": 2.7859237536656893,
      "grad_norm": 0.003822469851002097,
      "learning_rate": 1.3284457478005865e-05,
      "loss": 0.0488,
      "step": 19000
    },
    {
      "epoch": 2.793255131964809,
      "grad_norm": 0.03207595273852348,
      "learning_rate": 1.3240469208211144e-05,
      "loss": 0.0911,
      "step": 19050
    },
    {
      "epoch": 2.80058651026393,
      "grad_norm": 0.013905669562518597,
      "learning_rate": 1.3196480938416423e-05,
      "loss": 0.0441,
      "step": 19100
    },
    {
      "epoch": 2.8079178885630496,
      "grad_norm": 0.010601135902106762,
      "learning_rate": 1.3152492668621701e-05,
      "loss": 0.0734,
      "step": 19150
    },
    {
      "epoch": 2.8152492668621703,
      "grad_norm": 43.45177459716797,
      "learning_rate": 1.310850439882698e-05,
      "loss": 0.0597,
      "step": 19200
    },
    {
      "epoch": 2.8225806451612905,
      "grad_norm": 0.00970225129276514,
      "learning_rate": 1.3064516129032258e-05,
      "loss": 0.0636,
      "step": 19250
    },
    {
      "epoch": 2.8299120234604107,
      "grad_norm": 0.043575435876846313,
      "learning_rate": 1.3020527859237537e-05,
      "loss": 0.0262,
      "step": 19300
    },
    {
      "epoch": 2.837243401759531,
      "grad_norm": 0.33920568227767944,
      "learning_rate": 1.2976539589442815e-05,
      "loss": 0.0885,
      "step": 19350
    },
    {
      "epoch": 2.844574780058651,
      "grad_norm": 12.01727294921875,
      "learning_rate": 1.2932551319648094e-05,
      "loss": 0.0818,
      "step": 19400
    },
    {
      "epoch": 2.8519061583577714,
      "grad_norm": 0.023590993136167526,
      "learning_rate": 1.2888563049853374e-05,
      "loss": 0.0418,
      "step": 19450
    },
    {
      "epoch": 2.8592375366568916,
      "grad_norm": 0.4306069314479828,
      "learning_rate": 1.2844574780058651e-05,
      "loss": 0.1026,
      "step": 19500
    },
    {
      "epoch": 2.866568914956012,
      "grad_norm": 0.0009055641712620854,
      "learning_rate": 1.280058651026393e-05,
      "loss": 0.0734,
      "step": 19550
    },
    {
      "epoch": 2.873900293255132,
      "grad_norm": 4.084334850311279,
      "learning_rate": 1.2756598240469208e-05,
      "loss": 0.1026,
      "step": 19600
    },
    {
      "epoch": 2.8812316715542523,
      "grad_norm": 0.004487777128815651,
      "learning_rate": 1.2712609970674488e-05,
      "loss": 0.0379,
      "step": 19650
    },
    {
      "epoch": 2.8885630498533725,
      "grad_norm": 36.84142303466797,
      "learning_rate": 1.2668621700879765e-05,
      "loss": 0.0491,
      "step": 19700
    },
    {
      "epoch": 2.8958944281524928,
      "grad_norm": 0.16636691987514496,
      "learning_rate": 1.2624633431085045e-05,
      "loss": 0.0945,
      "step": 19750
    },
    {
      "epoch": 2.903225806451613,
      "grad_norm": 0.21495968103408813,
      "learning_rate": 1.2580645161290324e-05,
      "loss": 0.0286,
      "step": 19800
    },
    {
      "epoch": 2.910557184750733,
      "grad_norm": 0.45355138182640076,
      "learning_rate": 1.2536656891495602e-05,
      "loss": 0.0676,
      "step": 19850
    },
    {
      "epoch": 2.9178885630498534,
      "grad_norm": 0.041529860347509384,
      "learning_rate": 1.2492668621700881e-05,
      "loss": 0.0655,
      "step": 19900
    },
    {
      "epoch": 2.9252199413489737,
      "grad_norm": 3.3436734676361084,
      "learning_rate": 1.2448680351906159e-05,
      "loss": 0.0283,
      "step": 19950
    },
    {
      "epoch": 2.932551319648094,
      "grad_norm": 0.022173961624503136,
      "learning_rate": 1.2404692082111438e-05,
      "loss": 0.0725,
      "step": 20000
    },
    {
      "epoch": 2.939882697947214,
      "grad_norm": 0.08559227734804153,
      "learning_rate": 1.2360703812316716e-05,
      "loss": 0.0547,
      "step": 20050
    },
    {
      "epoch": 2.9472140762463344,
      "grad_norm": 30.531827926635742,
      "learning_rate": 1.2316715542521995e-05,
      "loss": 0.0512,
      "step": 20100
    },
    {
      "epoch": 2.9545454545454546,
      "grad_norm": 0.002217718632891774,
      "learning_rate": 1.2272727272727274e-05,
      "loss": 0.0509,
      "step": 20150
    },
    {
      "epoch": 2.961876832844575,
      "grad_norm": 0.10149270296096802,
      "learning_rate": 1.2228739002932552e-05,
      "loss": 0.067,
      "step": 20200
    },
    {
      "epoch": 2.969208211143695,
      "grad_norm": 0.009237712249159813,
      "learning_rate": 1.218475073313783e-05,
      "loss": 0.0415,
      "step": 20250
    },
    {
      "epoch": 2.9765395894428153,
      "grad_norm": 0.0034376748371869326,
      "learning_rate": 1.2140762463343107e-05,
      "loss": 0.0509,
      "step": 20300
    },
    {
      "epoch": 2.9838709677419355,
      "grad_norm": 5.1251444816589355,
      "learning_rate": 1.2096774193548387e-05,
      "loss": 0.0498,
      "step": 20350
    },
    {
      "epoch": 2.9912023460410557,
      "grad_norm": 0.00856314692646265,
      "learning_rate": 1.2052785923753666e-05,
      "loss": 0.0832,
      "step": 20400
    },
    {
      "epoch": 2.998533724340176,
      "grad_norm": 55.05332946777344,
      "learning_rate": 1.2008797653958944e-05,
      "loss": 0.0485,
      "step": 20450
    },
    {
      "epoch": 3.0,
      "eval_runtime": 47.5924,
      "eval_samples_per_second": 582.131,
      "eval_steps_per_second": 36.392,
      "step": 20460
    },
    {
      "epoch": 3.005865102639296,
      "grad_norm": 0.26298633217811584,
      "learning_rate": 1.1964809384164223e-05,
      "loss": 0.046,
      "step": 20500
    },
    {
      "epoch": 3.0131964809384164,
      "grad_norm": 0.00755721889436245,
      "learning_rate": 1.19208211143695e-05,
      "loss": 0.0224,
      "step": 20550
    },
    {
      "epoch": 3.0205278592375366,
      "grad_norm": 0.0009367602178826928,
      "learning_rate": 1.187683284457478e-05,
      "loss": 0.021,
      "step": 20600
    },
    {
      "epoch": 3.027859237536657,
      "grad_norm": 7.099948406219482,
      "learning_rate": 1.1832844574780058e-05,
      "loss": 0.0374,
      "step": 20650
    },
    {
      "epoch": 3.035190615835777,
      "grad_norm": 0.01811792142689228,
      "learning_rate": 1.1788856304985337e-05,
      "loss": 0.0308,
      "step": 20700
    },
    {
      "epoch": 3.0425219941348973,
      "grad_norm": 0.0032743411138653755,
      "learning_rate": 1.1744868035190616e-05,
      "loss": 0.0381,
      "step": 20750
    },
    {
      "epoch": 3.0498533724340176,
      "grad_norm": 0.01579321175813675,
      "learning_rate": 1.1700879765395894e-05,
      "loss": 0.0555,
      "step": 20800
    },
    {
      "epoch": 3.057184750733138,
      "grad_norm": 0.029372530058026314,
      "learning_rate": 1.1656891495601173e-05,
      "loss": 0.0352,
      "step": 20850
    },
    {
      "epoch": 3.064516129032258,
      "grad_norm": 0.9267762303352356,
      "learning_rate": 1.1612903225806451e-05,
      "loss": 0.0327,
      "step": 20900
    },
    {
      "epoch": 3.0718475073313782,
      "grad_norm": 0.024505117908120155,
      "learning_rate": 1.156891495601173e-05,
      "loss": 0.0198,
      "step": 20950
    },
    {
      "epoch": 3.0791788856304985,
      "grad_norm": 2.235748767852783,
      "learning_rate": 1.1524926686217008e-05,
      "loss": 0.0136,
      "step": 21000
    },
    {
      "epoch": 3.0865102639296187,
      "grad_norm": 0.005550198256969452,
      "learning_rate": 1.1480938416422288e-05,
      "loss": 0.0152,
      "step": 21050
    },
    {
      "epoch": 3.093841642228739,
      "grad_norm": 0.0004228070902172476,
      "learning_rate": 1.1436950146627567e-05,
      "loss": 0.0381,
      "step": 21100
    },
    {
      "epoch": 3.101173020527859,
      "grad_norm": 0.0021435634698718786,
      "learning_rate": 1.1392961876832845e-05,
      "loss": 0.0243,
      "step": 21150
    },
    {
      "epoch": 3.1085043988269794,
      "grad_norm": 11.239370346069336,
      "learning_rate": 1.1348973607038124e-05,
      "loss": 0.0468,
      "step": 21200
    },
    {
      "epoch": 3.1158357771260996,
      "grad_norm": 0.010469206608831882,
      "learning_rate": 1.1304985337243402e-05,
      "loss": 0.046,
      "step": 21250
    },
    {
      "epoch": 3.12316715542522,
      "grad_norm": 0.0018556261202320457,
      "learning_rate": 1.1260997067448681e-05,
      "loss": 0.0379,
      "step": 21300
    },
    {
      "epoch": 3.13049853372434,
      "grad_norm": 0.11113923788070679,
      "learning_rate": 1.1217008797653959e-05,
      "loss": 0.0359,
      "step": 21350
    },
    {
      "epoch": 3.1378299120234603,
      "grad_norm": 0.0033001985866576433,
      "learning_rate": 1.1173020527859238e-05,
      "loss": 0.0268,
      "step": 21400
    },
    {
      "epoch": 3.1451612903225805,
      "grad_norm": 0.007501770276576281,
      "learning_rate": 1.1129032258064517e-05,
      "loss": 0.0254,
      "step": 21450
    },
    {
      "epoch": 3.1524926686217007,
      "grad_norm": 0.015182132832705975,
      "learning_rate": 1.1085043988269795e-05,
      "loss": 0.012,
      "step": 21500
    },
    {
      "epoch": 3.159824046920821,
      "grad_norm": 0.0009142034687101841,
      "learning_rate": 1.1041055718475074e-05,
      "loss": 0.0227,
      "step": 21550
    },
    {
      "epoch": 3.167155425219941,
      "grad_norm": 0.0023778097238391638,
      "learning_rate": 1.0997067448680352e-05,
      "loss": 0.0324,
      "step": 21600
    },
    {
      "epoch": 3.1744868035190614,
      "grad_norm": 0.04431147500872612,
      "learning_rate": 1.0953079178885631e-05,
      "loss": 0.022,
      "step": 21650
    },
    {
      "epoch": 3.1818181818181817,
      "grad_norm": 65.75531005859375,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 0.0656,
      "step": 21700
    },
    {
      "epoch": 3.189149560117302,
      "grad_norm": 9.260320663452148,
      "learning_rate": 1.0865102639296188e-05,
      "loss": 0.049,
      "step": 21750
    },
    {
      "epoch": 3.196480938416422,
      "grad_norm": 0.005611272528767586,
      "learning_rate": 1.0821114369501468e-05,
      "loss": 0.0225,
      "step": 21800
    },
    {
      "epoch": 3.2038123167155423,
      "grad_norm": 0.21656078100204468,
      "learning_rate": 1.0777126099706745e-05,
      "loss": 0.0356,
      "step": 21850
    },
    {
      "epoch": 3.2111436950146626,
      "grad_norm": 13.326436042785645,
      "learning_rate": 1.0733137829912025e-05,
      "loss": 0.0261,
      "step": 21900
    },
    {
      "epoch": 3.218475073313783,
      "grad_norm": 0.37496817111968994,
      "learning_rate": 1.0689149560117302e-05,
      "loss": 0.0359,
      "step": 21950
    },
    {
      "epoch": 3.225806451612903,
      "grad_norm": 4.826986789703369,
      "learning_rate": 1.0645161290322582e-05,
      "loss": 0.0259,
      "step": 22000
    },
    {
      "epoch": 3.2331378299120233,
      "grad_norm": 0.06386123597621918,
      "learning_rate": 1.060117302052786e-05,
      "loss": 0.048,
      "step": 22050
    },
    {
      "epoch": 3.2404692082111435,
      "grad_norm": 4.269768238067627,
      "learning_rate": 1.0557184750733139e-05,
      "loss": 0.0369,
      "step": 22100
    },
    {
      "epoch": 3.247800586510264,
      "grad_norm": 0.0009473109967075288,
      "learning_rate": 1.0513196480938418e-05,
      "loss": 0.0158,
      "step": 22150
    },
    {
      "epoch": 3.255131964809384,
      "grad_norm": 0.42538246512413025,
      "learning_rate": 1.0469208211143696e-05,
      "loss": 0.0235,
      "step": 22200
    },
    {
      "epoch": 3.2624633431085046,
      "grad_norm": 0.006286687217652798,
      "learning_rate": 1.0425219941348975e-05,
      "loss": 0.0298,
      "step": 22250
    },
    {
      "epoch": 3.2697947214076244,
      "grad_norm": 28.125045776367188,
      "learning_rate": 1.0381231671554253e-05,
      "loss": 0.0178,
      "step": 22300
    },
    {
      "epoch": 3.277126099706745,
      "grad_norm": 9.971052169799805,
      "learning_rate": 1.0337243401759532e-05,
      "loss": 0.0154,
      "step": 22350
    },
    {
      "epoch": 3.2844574780058653,
      "grad_norm": 1.8082687854766846,
      "learning_rate": 1.029325513196481e-05,
      "loss": 0.0289,
      "step": 22400
    },
    {
      "epoch": 3.2917888563049855,
      "grad_norm": 0.004712965339422226,
      "learning_rate": 1.0249266862170087e-05,
      "loss": 0.0478,
      "step": 22450
    },
    {
      "epoch": 3.2991202346041058,
      "grad_norm": 0.09326065331697464,
      "learning_rate": 1.0205278592375367e-05,
      "loss": 0.0353,
      "step": 22500
    },
    {
      "epoch": 3.306451612903226,
      "grad_norm": 3.281477928161621,
      "learning_rate": 1.0161290322580644e-05,
      "loss": 0.039,
      "step": 22550
    },
    {
      "epoch": 3.313782991202346,
      "grad_norm": 0.0016637458465993404,
      "learning_rate": 1.0117302052785924e-05,
      "loss": 0.022,
      "step": 22600
    },
    {
      "epoch": 3.3211143695014664,
      "grad_norm": 0.0008585674222558737,
      "learning_rate": 1.0073313782991201e-05,
      "loss": 0.0446,
      "step": 22650
    },
    {
      "epoch": 3.3284457478005867,
      "grad_norm": 0.008172969333827496,
      "learning_rate": 1.002932551319648e-05,
      "loss": 0.0246,
      "step": 22700
    },
    {
      "epoch": 3.335777126099707,
      "grad_norm": 0.8777471780776978,
      "learning_rate": 9.98533724340176e-06,
      "loss": 0.0174,
      "step": 22750
    },
    {
      "epoch": 3.343108504398827,
      "grad_norm": 0.136377215385437,
      "learning_rate": 9.941348973607038e-06,
      "loss": 0.034,
      "step": 22800
    },
    {
      "epoch": 3.3504398826979473,
      "grad_norm": 0.0006333034252747893,
      "learning_rate": 9.897360703812317e-06,
      "loss": 0.0127,
      "step": 22850
    },
    {
      "epoch": 3.3577712609970676,
      "grad_norm": 0.0006676125340163708,
      "learning_rate": 9.853372434017595e-06,
      "loss": 0.0388,
      "step": 22900
    },
    {
      "epoch": 3.365102639296188,
      "grad_norm": 0.006603796500712633,
      "learning_rate": 9.809384164222874e-06,
      "loss": 0.0454,
      "step": 22950
    },
    {
      "epoch": 3.372434017595308,
      "grad_norm": 0.005253288894891739,
      "learning_rate": 9.765395894428152e-06,
      "loss": 0.0437,
      "step": 23000
    },
    {
      "epoch": 3.3797653958944283,
      "grad_norm": 0.0015886306064203382,
      "learning_rate": 9.721407624633431e-06,
      "loss": 0.0224,
      "step": 23050
    },
    {
      "epoch": 3.3870967741935485,
      "grad_norm": 0.0059502581134438515,
      "learning_rate": 9.67741935483871e-06,
      "loss": 0.0136,
      "step": 23100
    },
    {
      "epoch": 3.3944281524926687,
      "grad_norm": 0.004541992209851742,
      "learning_rate": 9.633431085043988e-06,
      "loss": 0.0502,
      "step": 23150
    },
    {
      "epoch": 3.401759530791789,
      "grad_norm": 0.0072633046656847,
      "learning_rate": 9.589442815249267e-06,
      "loss": 0.0291,
      "step": 23200
    },
    {
      "epoch": 3.409090909090909,
      "grad_norm": 4.356080532073975,
      "learning_rate": 9.545454545454545e-06,
      "loss": 0.0541,
      "step": 23250
    },
    {
      "epoch": 3.4164222873900294,
      "grad_norm": 8.455885887145996,
      "learning_rate": 9.501466275659824e-06,
      "loss": 0.03,
      "step": 23300
    },
    {
      "epoch": 3.4237536656891496,
      "grad_norm": 30.546905517578125,
      "learning_rate": 9.457478005865102e-06,
      "loss": 0.0218,
      "step": 23350
    },
    {
      "epoch": 3.43108504398827,
      "grad_norm": 0.0004758207651320845,
      "learning_rate": 9.413489736070381e-06,
      "loss": 0.041,
      "step": 23400
    },
    {
      "epoch": 3.43841642228739,
      "grad_norm": 0.0014885147102177143,
      "learning_rate": 9.36950146627566e-06,
      "loss": 0.0185,
      "step": 23450
    },
    {
      "epoch": 3.4457478005865103,
      "grad_norm": 0.0005837099743075669,
      "learning_rate": 9.325513196480938e-06,
      "loss": 0.0214,
      "step": 23500
    },
    {
      "epoch": 3.4530791788856305,
      "grad_norm": 1.230891227722168,
      "learning_rate": 9.281524926686218e-06,
      "loss": 0.0407,
      "step": 23550
    },
    {
      "epoch": 3.4604105571847508,
      "grad_norm": 0.010735798627138138,
      "learning_rate": 9.237536656891495e-06,
      "loss": 0.0385,
      "step": 23600
    },
    {
      "epoch": 3.467741935483871,
      "grad_norm": 0.002835608785971999,
      "learning_rate": 9.193548387096775e-06,
      "loss": 0.0265,
      "step": 23650
    },
    {
      "epoch": 3.4750733137829912,
      "grad_norm": 0.06564509868621826,
      "learning_rate": 9.149560117302052e-06,
      "loss": 0.0556,
      "step": 23700
    },
    {
      "epoch": 3.4824046920821115,
      "grad_norm": 4.189058303833008,
      "learning_rate": 9.105571847507332e-06,
      "loss": 0.0544,
      "step": 23750
    },
    {
      "epoch": 3.4897360703812317,
      "grad_norm": 39.890586853027344,
      "learning_rate": 9.061583577712611e-06,
      "loss": 0.0379,
      "step": 23800
    },
    {
      "epoch": 3.497067448680352,
      "grad_norm": 0.03529768064618111,
      "learning_rate": 9.017595307917889e-06,
      "loss": 0.0212,
      "step": 23850
    },
    {
      "epoch": 3.504398826979472,
      "grad_norm": 0.005343673750758171,
      "learning_rate": 8.973607038123168e-06,
      "loss": 0.0356,
      "step": 23900
    },
    {
      "epoch": 3.5117302052785924,
      "grad_norm": 0.23486702144145966,
      "learning_rate": 8.929618768328446e-06,
      "loss": 0.0367,
      "step": 23950
    },
    {
      "epoch": 3.5190615835777126,
      "grad_norm": 0.007541406434029341,
      "learning_rate": 8.885630498533725e-06,
      "loss": 0.0599,
      "step": 24000
    },
    {
      "epoch": 3.526392961876833,
      "grad_norm": 0.0037247224245220423,
      "learning_rate": 8.841642228739003e-06,
      "loss": 0.0287,
      "step": 24050
    },
    {
      "epoch": 3.533724340175953,
      "grad_norm": 7.6746039390563965,
      "learning_rate": 8.797653958944282e-06,
      "loss": 0.0404,
      "step": 24100
    },
    {
      "epoch": 3.5410557184750733,
      "grad_norm": 0.013235507532954216,
      "learning_rate": 8.753665689149562e-06,
      "loss": 0.0382,
      "step": 24150
    },
    {
      "epoch": 3.5483870967741935,
      "grad_norm": 0.0012887517223134637,
      "learning_rate": 8.70967741935484e-06,
      "loss": 0.0443,
      "step": 24200
    },
    {
      "epoch": 3.5557184750733137,
      "grad_norm": 0.002551113022491336,
      "learning_rate": 8.665689149560119e-06,
      "loss": 0.0171,
      "step": 24250
    },
    {
      "epoch": 3.563049853372434,
      "grad_norm": 0.0017479980597272515,
      "learning_rate": 8.621700879765396e-06,
      "loss": 0.0271,
      "step": 24300
    },
    {
      "epoch": 3.570381231671554,
      "grad_norm": 0.021437635645270348,
      "learning_rate": 8.577712609970676e-06,
      "loss": 0.0578,
      "step": 24350
    },
    {
      "epoch": 3.5777126099706744,
      "grad_norm": 0.0037983465008437634,
      "learning_rate": 8.533724340175953e-06,
      "loss": 0.0228,
      "step": 24400
    },
    {
      "epoch": 3.5850439882697946,
      "grad_norm": 0.031959693878889084,
      "learning_rate": 8.489736070381233e-06,
      "loss": 0.0462,
      "step": 24450
    },
    {
      "epoch": 3.592375366568915,
      "grad_norm": 0.05409654602408409,
      "learning_rate": 8.445747800586512e-06,
      "loss": 0.0631,
      "step": 24500
    },
    {
      "epoch": 3.599706744868035,
      "grad_norm": 0.0030662850476801395,
      "learning_rate": 8.401759530791788e-06,
      "loss": 0.0125,
      "step": 24550
    },
    {
      "epoch": 3.6070381231671553,
      "grad_norm": 2.104275941848755,
      "learning_rate": 8.357771260997067e-06,
      "loss": 0.0319,
      "step": 24600
    },
    {
      "epoch": 3.6143695014662756,
      "grad_norm": 0.3163781762123108,
      "learning_rate": 8.313782991202345e-06,
      "loss": 0.0164,
      "step": 24650
    },
    {
      "epoch": 3.621700879765396,
      "grad_norm": 0.0006312422337941825,
      "learning_rate": 8.269794721407624e-06,
      "loss": 0.0019,
      "step": 24700
    },
    {
      "epoch": 3.629032258064516,
      "grad_norm": 0.00045195064740255475,
      "learning_rate": 8.225806451612904e-06,
      "loss": 0.0613,
      "step": 24750
    },
    {
      "epoch": 3.6363636363636362,
      "grad_norm": 20.33766746520996,
      "learning_rate": 8.181818181818181e-06,
      "loss": 0.0597,
      "step": 24800
    },
    {
      "epoch": 3.6436950146627565,
      "grad_norm": 23.487112045288086,
      "learning_rate": 8.13782991202346e-06,
      "loss": 0.0163,
      "step": 24850
    },
    {
      "epoch": 3.6510263929618767,
      "grad_norm": 0.0008749127737246454,
      "learning_rate": 8.093841642228738e-06,
      "loss": 0.0384,
      "step": 24900
    },
    {
      "epoch": 3.658357771260997,
      "grad_norm": 35.48154830932617,
      "learning_rate": 8.049853372434018e-06,
      "loss": 0.0091,
      "step": 24950
    },
    {
      "epoch": 3.665689149560117,
      "grad_norm": 0.03391198068857193,
      "learning_rate": 8.005865102639295e-06,
      "loss": 0.043,
      "step": 25000
    },
    {
      "epoch": 3.6730205278592374,
      "grad_norm": 0.06420151144266129,
      "learning_rate": 7.961876832844575e-06,
      "loss": 0.0097,
      "step": 25050
    },
    {
      "epoch": 3.6803519061583576,
      "grad_norm": 0.01041070930659771,
      "learning_rate": 7.917888563049854e-06,
      "loss": 0.0313,
      "step": 25100
    },
    {
      "epoch": 3.687683284457478,
      "grad_norm": 0.0018425399903208017,
      "learning_rate": 7.873900293255132e-06,
      "loss": 0.034,
      "step": 25150
    },
    {
      "epoch": 3.6950146627565985,
      "grad_norm": 39.02524185180664,
      "learning_rate": 7.829912023460411e-06,
      "loss": 0.0493,
      "step": 25200
    },
    {
      "epoch": 3.7023460410557183,
      "grad_norm": 0.009073466993868351,
      "learning_rate": 7.785923753665689e-06,
      "loss": 0.0358,
      "step": 25250
    },
    {
      "epoch": 3.709677419354839,
      "grad_norm": 0.004684448707848787,
      "learning_rate": 7.741935483870968e-06,
      "loss": 0.0193,
      "step": 25300
    },
    {
      "epoch": 3.7170087976539588,
      "grad_norm": 0.007403032388538122,
      "learning_rate": 7.697947214076246e-06,
      "loss": 0.0232,
      "step": 25350
    },
    {
      "epoch": 3.7243401759530794,
      "grad_norm": 0.00038579650572501123,
      "learning_rate": 7.653958944281525e-06,
      "loss": 0.0259,
      "step": 25400
    },
    {
      "epoch": 3.731671554252199,
      "grad_norm": 0.5016586184501648,
      "learning_rate": 7.6099706744868035e-06,
      "loss": 0.0671,
      "step": 25450
    },
    {
      "epoch": 3.73900293255132,
      "grad_norm": 2.335928201675415,
      "learning_rate": 7.565982404692082e-06,
      "loss": 0.0137,
      "step": 25500
    },
    {
      "epoch": 3.7463343108504397,
      "grad_norm": 0.018139241263270378,
      "learning_rate": 7.5219941348973605e-06,
      "loss": 0.0595,
      "step": 25550
    },
    {
      "epoch": 3.7536656891495603,
      "grad_norm": 0.0039823949337005615,
      "learning_rate": 7.47800586510264e-06,
      "loss": 0.0499,
      "step": 25600
    },
    {
      "epoch": 3.76099706744868,
      "grad_norm": 108.48162078857422,
      "learning_rate": 7.434017595307918e-06,
      "loss": 0.018,
      "step": 25650
    },
    {
      "epoch": 3.768328445747801,
      "grad_norm": 0.001082027330994606,
      "learning_rate": 7.390029325513197e-06,
      "loss": 0.0181,
      "step": 25700
    },
    {
      "epoch": 3.7756598240469206,
      "grad_norm": 0.000698536226991564,
      "learning_rate": 7.346041055718475e-06,
      "loss": 0.0448,
      "step": 25750
    },
    {
      "epoch": 3.7829912023460412,
      "grad_norm": 0.0008738565375097096,
      "learning_rate": 7.302052785923754e-06,
      "loss": 0.0378,
      "step": 25800
    },
    {
      "epoch": 3.790322580645161,
      "grad_norm": 0.025501158088445663,
      "learning_rate": 7.258064516129032e-06,
      "loss": 0.0476,
      "step": 25850
    },
    {
      "epoch": 3.7976539589442817,
      "grad_norm": 9.407361030578613,
      "learning_rate": 7.214076246334311e-06,
      "loss": 0.0092,
      "step": 25900
    },
    {
      "epoch": 3.8049853372434015,
      "grad_norm": 0.004990190267562866,
      "learning_rate": 7.17008797653959e-06,
      "loss": 0.0275,
      "step": 25950
    },
    {
      "epoch": 3.812316715542522,
      "grad_norm": 0.0021099820733070374,
      "learning_rate": 7.126099706744869e-06,
      "loss": 0.0281,
      "step": 26000
    },
    {
      "epoch": 3.8196480938416424,
      "grad_norm": 0.07003680616617203,
      "learning_rate": 7.082111436950147e-06,
      "loss": 0.0464,
      "step": 26050
    },
    {
      "epoch": 3.8269794721407626,
      "grad_norm": 112.98040008544922,
      "learning_rate": 7.038123167155426e-06,
      "loss": 0.0552,
      "step": 26100
    },
    {
      "epoch": 3.834310850439883,
      "grad_norm": 1.499161720275879,
      "learning_rate": 6.994134897360703e-06,
      "loss": 0.002,
      "step": 26150
    },
    {
      "epoch": 3.841642228739003,
      "grad_norm": 44.60114288330078,
      "learning_rate": 6.950146627565982e-06,
      "loss": 0.0326,
      "step": 26200
    },
    {
      "epoch": 3.8489736070381233,
      "grad_norm": 1.0306291580200195,
      "learning_rate": 6.906158357771261e-06,
      "loss": 0.028,
      "step": 26250
    },
    {
      "epoch": 3.8563049853372435,
      "grad_norm": 0.4873723089694977,
      "learning_rate": 6.86217008797654e-06,
      "loss": 0.0425,
      "step": 26300
    },
    {
      "epoch": 3.8636363636363638,
      "grad_norm": 0.03776349872350693,
      "learning_rate": 6.818181818181818e-06,
      "loss": 0.0125,
      "step": 26350
    },
    {
      "epoch": 3.870967741935484,
      "grad_norm": 0.04742174223065376,
      "learning_rate": 6.774193548387097e-06,
      "loss": 0.0318,
      "step": 26400
    },
    {
      "epoch": 3.878299120234604,
      "grad_norm": 0.030709505081176758,
      "learning_rate": 6.730205278592375e-06,
      "loss": 0.0444,
      "step": 26450
    },
    {
      "epoch": 3.8856304985337244,
      "grad_norm": 0.01021046657115221,
      "learning_rate": 6.686217008797654e-06,
      "loss": 0.0351,
      "step": 26500
    },
    {
      "epoch": 3.8929618768328447,
      "grad_norm": 0.0440327450633049,
      "learning_rate": 6.642228739002932e-06,
      "loss": 0.0367,
      "step": 26550
    },
    {
      "epoch": 3.900293255131965,
      "grad_norm": 0.4478243887424469,
      "learning_rate": 6.598240469208212e-06,
      "loss": 0.0199,
      "step": 26600
    },
    {
      "epoch": 3.907624633431085,
      "grad_norm": 0.0017062524566426873,
      "learning_rate": 6.55425219941349e-06,
      "loss": 0.0265,
      "step": 26650
    },
    {
      "epoch": 3.9149560117302054,
      "grad_norm": 0.00019503565272316337,
      "learning_rate": 6.510263929618769e-06,
      "loss": 0.0484,
      "step": 26700
    },
    {
      "epoch": 3.9222873900293256,
      "grad_norm": 4.091703414916992,
      "learning_rate": 6.466275659824047e-06,
      "loss": 0.0437,
      "step": 26750
    },
    {
      "epoch": 3.929618768328446,
      "grad_norm": 33.20175552368164,
      "learning_rate": 6.422287390029326e-06,
      "loss": 0.0387,
      "step": 26800
    },
    {
      "epoch": 3.936950146627566,
      "grad_norm": 0.01249715220183134,
      "learning_rate": 6.378299120234604e-06,
      "loss": 0.0436,
      "step": 26850
    },
    {
      "epoch": 3.9442815249266863,
      "grad_norm": 0.08606256544589996,
      "learning_rate": 6.334310850439883e-06,
      "loss": 0.0326,
      "step": 26900
    },
    {
      "epoch": 3.9516129032258065,
      "grad_norm": 0.005057530011981726,
      "learning_rate": 6.290322580645162e-06,
      "loss": 0.0412,
      "step": 26950
    },
    {
      "epoch": 3.9589442815249267,
      "grad_norm": 0.0018432431388646364,
      "learning_rate": 6.2463343108504405e-06,
      "loss": 0.0223,
      "step": 27000
    },
    {
      "epoch": 3.966275659824047,
      "grad_norm": 0.0023857036139816046,
      "learning_rate": 6.202346041055719e-06,
      "loss": 0.0256,
      "step": 27050
    },
    {
      "epoch": 3.973607038123167,
      "grad_norm": 0.022050775587558746,
      "learning_rate": 6.1583577712609975e-06,
      "loss": 0.0322,
      "step": 27100
    },
    {
      "epoch": 3.9809384164222874,
      "grad_norm": 6.645246982574463,
      "learning_rate": 6.114369501466276e-06,
      "loss": 0.043,
      "step": 27150
    },
    {
      "epoch": 3.9882697947214076,
      "grad_norm": 0.026118572801351547,
      "learning_rate": 6.070381231671554e-06,
      "loss": 0.0296,
      "step": 27200
    },
    {
      "epoch": 3.995601173020528,
      "grad_norm": 39.289485931396484,
      "learning_rate": 6.026392961876833e-06,
      "loss": 0.0338,
      "step": 27250
    },
    {
      "epoch": 4.0,
      "eval_runtime": 47.6304,
      "eval_samples_per_second": 581.667,
      "eval_steps_per_second": 36.363,
      "step": 27280
    },
    {
      "epoch": 4.002932551319648,
      "grad_norm": 0.006084029097110033,
      "learning_rate": 5.9824046920821116e-06,
      "loss": 0.0235,
      "step": 27300
    },
    {
      "epoch": 4.010263929618769,
      "grad_norm": 12.07438850402832,
      "learning_rate": 5.93841642228739e-06,
      "loss": 0.0178,
      "step": 27350
    },
    {
      "epoch": 4.0175953079178885,
      "grad_norm": 0.0014877918874844909,
      "learning_rate": 5.8944281524926686e-06,
      "loss": 0.0142,
      "step": 27400
    },
    {
      "epoch": 4.024926686217009,
      "grad_norm": 0.001975851831957698,
      "learning_rate": 5.850439882697947e-06,
      "loss": 0.0065,
      "step": 27450
    },
    {
      "epoch": 4.032258064516129,
      "grad_norm": 16.19452667236328,
      "learning_rate": 5.8064516129032256e-06,
      "loss": 0.0039,
      "step": 27500
    },
    {
      "epoch": 4.03958944281525,
      "grad_norm": 53.652042388916016,
      "learning_rate": 5.762463343108504e-06,
      "loss": 0.0127,
      "step": 27550
    },
    {
      "epoch": 4.0469208211143695,
      "grad_norm": 0.0012005828320980072,
      "learning_rate": 5.7184750733137834e-06,
      "loss": 0.0285,
      "step": 27600
    },
    {
      "epoch": 4.05425219941349,
      "grad_norm": 0.0004846570664085448,
      "learning_rate": 5.674486803519062e-06,
      "loss": 0.0058,
      "step": 27650
    },
    {
      "epoch": 4.06158357771261,
      "grad_norm": 0.04964317008852959,
      "learning_rate": 5.6304985337243404e-06,
      "loss": 0.0258,
      "step": 27700
    },
    {
      "epoch": 4.068914956011731,
      "grad_norm": 0.0032150116749107838,
      "learning_rate": 5.586510263929619e-06,
      "loss": 0.0246,
      "step": 27750
    },
    {
      "epoch": 4.07624633431085,
      "grad_norm": 0.0013640456600114703,
      "learning_rate": 5.5425219941348974e-06,
      "loss": 0.0162,
      "step": 27800
    },
    {
      "epoch": 4.083577712609971,
      "grad_norm": 0.009257455356419086,
      "learning_rate": 5.498533724340176e-06,
      "loss": 0.0032,
      "step": 27850
    },
    {
      "epoch": 4.090909090909091,
      "grad_norm": 22.949920654296875,
      "learning_rate": 5.4545454545454545e-06,
      "loss": 0.0083,
      "step": 27900
    },
    {
      "epoch": 4.0982404692082115,
      "grad_norm": 0.000689031439833343,
      "learning_rate": 5.410557184750734e-06,
      "loss": 0.0019,
      "step": 27950
    },
    {
      "epoch": 4.105571847507331,
      "grad_norm": 0.004659708589315414,
      "learning_rate": 5.366568914956012e-06,
      "loss": 0.0201,
      "step": 28000
    },
    {
      "epoch": 4.112903225806452,
      "grad_norm": 0.0030863562133163214,
      "learning_rate": 5.322580645161291e-06,
      "loss": 0.015,
      "step": 28050
    },
    {
      "epoch": 4.120234604105572,
      "grad_norm": 0.0015866570174694061,
      "learning_rate": 5.278592375366569e-06,
      "loss": 0.0178,
      "step": 28100
    },
    {
      "epoch": 4.127565982404692,
      "grad_norm": 0.01746983453631401,
      "learning_rate": 5.234604105571848e-06,
      "loss": 0.0086,
      "step": 28150
    },
    {
      "epoch": 4.134897360703812,
      "grad_norm": 0.002036616438999772,
      "learning_rate": 5.190615835777126e-06,
      "loss": 0.0178,
      "step": 28200
    },
    {
      "epoch": 4.142228739002933,
      "grad_norm": 0.0165146104991436,
      "learning_rate": 5.146627565982405e-06,
      "loss": 0.0258,
      "step": 28250
    },
    {
      "epoch": 4.149560117302053,
      "grad_norm": 0.029752524569630623,
      "learning_rate": 5.102639296187683e-06,
      "loss": 0.0072,
      "step": 28300
    },
    {
      "epoch": 4.156891495601173,
      "grad_norm": 0.010125681757926941,
      "learning_rate": 5.058651026392962e-06,
      "loss": 0.0247,
      "step": 28350
    },
    {
      "epoch": 4.164222873900293,
      "grad_norm": 0.0037354768719524145,
      "learning_rate": 5.01466275659824e-06,
      "loss": 0.0146,
      "step": 28400
    },
    {
      "epoch": 4.171554252199414,
      "grad_norm": 5.487244606018066,
      "learning_rate": 4.970674486803519e-06,
      "loss": 0.0025,
      "step": 28450
    },
    {
      "epoch": 4.178885630498534,
      "grad_norm": 0.0002489493926987052,
      "learning_rate": 4.926686217008797e-06,
      "loss": 0.006,
      "step": 28500
    },
    {
      "epoch": 4.186217008797654,
      "grad_norm": 0.00012009900819975883,
      "learning_rate": 4.882697947214076e-06,
      "loss": 0.0022,
      "step": 28550
    },
    {
      "epoch": 4.193548387096774,
      "grad_norm": 0.0016214016359299421,
      "learning_rate": 4.838709677419355e-06,
      "loss": 0.0169,
      "step": 28600
    },
    {
      "epoch": 4.200879765395895,
      "grad_norm": 0.005613408982753754,
      "learning_rate": 4.794721407624634e-06,
      "loss": 0.0158,
      "step": 28650
    },
    {
      "epoch": 4.2082111436950145,
      "grad_norm": 0.004499341826885939,
      "learning_rate": 4.750733137829912e-06,
      "loss": 0.0003,
      "step": 28700
    },
    {
      "epoch": 4.215542521994135,
      "grad_norm": 0.00017535265942569822,
      "learning_rate": 4.706744868035191e-06,
      "loss": 0.0351,
      "step": 28750
    },
    {
      "epoch": 4.222873900293255,
      "grad_norm": 0.0007333024987019598,
      "learning_rate": 4.662756598240469e-06,
      "loss": 0.0122,
      "step": 28800
    },
    {
      "epoch": 4.230205278592376,
      "grad_norm": 0.013409986160695553,
      "learning_rate": 4.618768328445748e-06,
      "loss": 0.0107,
      "step": 28850
    },
    {
      "epoch": 4.237536656891495,
      "grad_norm": 0.000705610669683665,
      "learning_rate": 4.574780058651026e-06,
      "loss": 0.0131,
      "step": 28900
    },
    {
      "epoch": 4.244868035190616,
      "grad_norm": 1.3258682489395142,
      "learning_rate": 4.530791788856306e-06,
      "loss": 0.005,
      "step": 28950
    },
    {
      "epoch": 4.252199413489736,
      "grad_norm": 0.0006160297198221087,
      "learning_rate": 4.486803519061584e-06,
      "loss": 0.0037,
      "step": 29000
    },
    {
      "epoch": 4.2595307917888565,
      "grad_norm": 0.003846836509183049,
      "learning_rate": 4.442815249266863e-06,
      "loss": 0.0184,
      "step": 29050
    },
    {
      "epoch": 4.266862170087976,
      "grad_norm": 0.0008214002009481192,
      "learning_rate": 4.398826979472141e-06,
      "loss": 0.0226,
      "step": 29100
    },
    {
      "epoch": 4.274193548387097,
      "grad_norm": 0.00017939941608347,
      "learning_rate": 4.35483870967742e-06,
      "loss": 0.0164,
      "step": 29150
    },
    {
      "epoch": 4.281524926686217,
      "grad_norm": 1.4670264720916748,
      "learning_rate": 4.310850439882698e-06,
      "loss": 0.0129,
      "step": 29200
    },
    {
      "epoch": 4.288856304985337,
      "grad_norm": 0.0018564872443675995,
      "learning_rate": 4.266862170087977e-06,
      "loss": 0.0006,
      "step": 29250
    },
    {
      "epoch": 4.296187683284457,
      "grad_norm": 0.0009387398604303598,
      "learning_rate": 4.222873900293256e-06,
      "loss": 0.0231,
      "step": 29300
    },
    {
      "epoch": 4.303519061583578,
      "grad_norm": 0.0002503002469893545,
      "learning_rate": 4.178885630498534e-06,
      "loss": 0.0098,
      "step": 29350
    },
    {
      "epoch": 4.310850439882698,
      "grad_norm": 0.18204936385154724,
      "learning_rate": 4.134897360703812e-06,
      "loss": 0.0047,
      "step": 29400
    },
    {
      "epoch": 4.318181818181818,
      "grad_norm": 0.0005234061391092837,
      "learning_rate": 4.090909090909091e-06,
      "loss": 0.039,
      "step": 29450
    },
    {
      "epoch": 4.325513196480938,
      "grad_norm": 0.01182236336171627,
      "learning_rate": 4.046920821114369e-06,
      "loss": 0.0043,
      "step": 29500
    },
    {
      "epoch": 4.332844574780059,
      "grad_norm": 0.00032508812728337944,
      "learning_rate": 4.002932551319648e-06,
      "loss": 0.0236,
      "step": 29550
    },
    {
      "epoch": 4.340175953079179,
      "grad_norm": 0.00013399386079981923,
      "learning_rate": 3.958944281524927e-06,
      "loss": 0.016,
      "step": 29600
    },
    {
      "epoch": 4.347507331378299,
      "grad_norm": 0.006395688746124506,
      "learning_rate": 3.9149560117302055e-06,
      "loss": 0.0049,
      "step": 29650
    },
    {
      "epoch": 4.354838709677419,
      "grad_norm": 0.0019898470491170883,
      "learning_rate": 3.870967741935484e-06,
      "loss": 0.0196,
      "step": 29700
    },
    {
      "epoch": 4.36217008797654,
      "grad_norm": 0.00014354991435538977,
      "learning_rate": 3.8269794721407625e-06,
      "loss": 0.0101,
      "step": 29750
    },
    {
      "epoch": 4.3695014662756595,
      "grad_norm": 0.014563899487257004,
      "learning_rate": 3.782991202346041e-06,
      "loss": 0.012,
      "step": 29800
    },
    {
      "epoch": 4.37683284457478,
      "grad_norm": 0.0005182959721423686,
      "learning_rate": 3.73900293255132e-06,
      "loss": 0.0209,
      "step": 29850
    },
    {
      "epoch": 4.3841642228739,
      "grad_norm": 0.35709333419799805,
      "learning_rate": 3.6950146627565984e-06,
      "loss": 0.0059,
      "step": 29900
    },
    {
      "epoch": 4.391495601173021,
      "grad_norm": 37.17420196533203,
      "learning_rate": 3.651026392961877e-06,
      "loss": 0.0041,
      "step": 29950
    },
    {
      "epoch": 4.39882697947214,
      "grad_norm": 0.0001521682715974748,
      "learning_rate": 3.6070381231671554e-06,
      "loss": 0.0095,
      "step": 30000
    },
    {
      "epoch": 4.406158357771261,
      "grad_norm": 8.520672417944297e-05,
      "learning_rate": 3.5630498533724344e-06,
      "loss": 0.0146,
      "step": 30050
    },
    {
      "epoch": 4.413489736070381,
      "grad_norm": 0.005452429875731468,
      "learning_rate": 3.519061583577713e-06,
      "loss": 0.0236,
      "step": 30100
    },
    {
      "epoch": 4.4208211143695015,
      "grad_norm": 28.99013328552246,
      "learning_rate": 3.475073313782991e-06,
      "loss": 0.0071,
      "step": 30150
    },
    {
      "epoch": 4.428152492668621,
      "grad_norm": 0.05198433995246887,
      "learning_rate": 3.43108504398827e-06,
      "loss": 0.0143,
      "step": 30200
    },
    {
      "epoch": 4.435483870967742,
      "grad_norm": 0.06551168113946915,
      "learning_rate": 3.3870967741935484e-06,
      "loss": 0.0322,
      "step": 30250
    },
    {
      "epoch": 4.442815249266862,
      "grad_norm": 0.02627783827483654,
      "learning_rate": 3.343108504398827e-06,
      "loss": 0.0104,
      "step": 30300
    },
    {
      "epoch": 4.4501466275659824,
      "grad_norm": 1.551446557044983,
      "learning_rate": 3.299120234604106e-06,
      "loss": 0.0239,
      "step": 30350
    },
    {
      "epoch": 4.457478005865102,
      "grad_norm": 8.766096289036795e-05,
      "learning_rate": 3.2551319648093843e-06,
      "loss": 0.0232,
      "step": 30400
    },
    {
      "epoch": 4.464809384164223,
      "grad_norm": 0.005122231785207987,
      "learning_rate": 3.211143695014663e-06,
      "loss": 0.0081,
      "step": 30450
    },
    {
      "epoch": 4.472140762463344,
      "grad_norm": 0.055796798318624496,
      "learning_rate": 3.1671554252199413e-06,
      "loss": 0.0008,
      "step": 30500
    },
    {
      "epoch": 4.479472140762463,
      "grad_norm": 0.0001541842648293823,
      "learning_rate": 3.1231671554252203e-06,
      "loss": 0.0056,
      "step": 30550
    },
    {
      "epoch": 4.486803519061583,
      "grad_norm": 0.044660940766334534,
      "learning_rate": 3.0791788856304988e-06,
      "loss": 0.0125,
      "step": 30600
    },
    {
      "epoch": 4.494134897360704,
      "grad_norm": 0.0012049248907715082,
      "learning_rate": 3.035190615835777e-06,
      "loss": 0.0086,
      "step": 30650
    },
    {
      "epoch": 4.5014662756598245,
      "grad_norm": 0.11200802773237228,
      "learning_rate": 2.9912023460410558e-06,
      "loss": 0.0244,
      "step": 30700
    },
    {
      "epoch": 4.508797653958944,
      "grad_norm": 2.324420213699341,
      "learning_rate": 2.9472140762463343e-06,
      "loss": 0.0051,
      "step": 30750
    },
    {
      "epoch": 4.516129032258064,
      "grad_norm": 23.369243621826172,
      "learning_rate": 2.9032258064516128e-06,
      "loss": 0.0236,
      "step": 30800
    },
    {
      "epoch": 4.523460410557185,
      "grad_norm": 0.00013886395026929677,
      "learning_rate": 2.8592375366568917e-06,
      "loss": 0.0003,
      "step": 30850
    },
    {
      "epoch": 4.530791788856305,
      "grad_norm": 0.007256098557263613,
      "learning_rate": 2.8152492668621702e-06,
      "loss": 0.0111,
      "step": 30900
    },
    {
      "epoch": 4.538123167155425,
      "grad_norm": 0.0001120775195886381,
      "learning_rate": 2.7712609970674487e-06,
      "loss": 0.0108,
      "step": 30950
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 0.009202534332871437,
      "learning_rate": 2.7272727272727272e-06,
      "loss": 0.0085,
      "step": 31000
    },
    {
      "epoch": 4.552785923753666,
      "grad_norm": 0.00014823298261035234,
      "learning_rate": 2.683284457478006e-06,
      "loss": 0.001,
      "step": 31050
    },
    {
      "epoch": 4.560117302052786,
      "grad_norm": 0.0367453470826149,
      "learning_rate": 2.6392961876832847e-06,
      "loss": 0.0208,
      "step": 31100
    },
    {
      "epoch": 4.567448680351906,
      "grad_norm": 0.0032383918296545744,
      "learning_rate": 2.595307917888563e-06,
      "loss": 0.0097,
      "step": 31150
    },
    {
      "epoch": 4.574780058651027,
      "grad_norm": 3.8491644859313965,
      "learning_rate": 2.5513196480938417e-06,
      "loss": 0.0075,
      "step": 31200
    },
    {
      "epoch": 4.5821114369501466,
      "grad_norm": 0.0004385243228171021,
      "learning_rate": 2.50733137829912e-06,
      "loss": 0.0033,
      "step": 31250
    },
    {
      "epoch": 4.589442815249267,
      "grad_norm": 1.3012521266937256,
      "learning_rate": 2.4633431085043987e-06,
      "loss": 0.0125,
      "step": 31300
    },
    {
      "epoch": 4.596774193548387,
      "grad_norm": 0.002448202343657613,
      "learning_rate": 2.4193548387096776e-06,
      "loss": 0.0164,
      "step": 31350
    },
    {
      "epoch": 4.604105571847508,
      "grad_norm": 0.0023808139376342297,
      "learning_rate": 2.375366568914956e-06,
      "loss": 0.006,
      "step": 31400
    },
    {
      "epoch": 4.6114369501466275,
      "grad_norm": 5.72933531657327e-05,
      "learning_rate": 2.3313782991202346e-06,
      "loss": 0.004,
      "step": 31450
    },
    {
      "epoch": 4.618768328445748,
      "grad_norm": 0.05648172274231911,
      "learning_rate": 2.287390029325513e-06,
      "loss": 0.0466,
      "step": 31500
    },
    {
      "epoch": 4.626099706744868,
      "grad_norm": 0.0014360990608111024,
      "learning_rate": 2.243401759530792e-06,
      "loss": 0.0153,
      "step": 31550
    },
    {
      "epoch": 4.633431085043989,
      "grad_norm": 0.033932097256183624,
      "learning_rate": 2.1994134897360705e-06,
      "loss": 0.0106,
      "step": 31600
    },
    {
      "epoch": 4.640762463343108,
      "grad_norm": 0.000541193294338882,
      "learning_rate": 2.155425219941349e-06,
      "loss": 0.0132,
      "step": 31650
    },
    {
      "epoch": 4.648093841642229,
      "grad_norm": 0.0016754594398662448,
      "learning_rate": 2.111436950146628e-06,
      "loss": 0.0012,
      "step": 31700
    },
    {
      "epoch": 4.655425219941349,
      "grad_norm": 0.00032153178472071886,
      "learning_rate": 2.067448680351906e-06,
      "loss": 0.002,
      "step": 31750
    },
    {
      "epoch": 4.6627565982404695,
      "grad_norm": 9.58617115020752,
      "learning_rate": 2.0234604105571846e-06,
      "loss": 0.0351,
      "step": 31800
    },
    {
      "epoch": 4.670087976539589,
      "grad_norm": 0.0001075776744983159,
      "learning_rate": 1.9794721407624635e-06,
      "loss": 0.0232,
      "step": 31850
    },
    {
      "epoch": 4.67741935483871,
      "grad_norm": 0.004763186909258366,
      "learning_rate": 1.935483870967742e-06,
      "loss": 0.0478,
      "step": 31900
    },
    {
      "epoch": 4.68475073313783,
      "grad_norm": 0.0019825042691081762,
      "learning_rate": 1.8914956011730205e-06,
      "loss": 0.0214,
      "step": 31950
    },
    {
      "epoch": 4.69208211143695,
      "grad_norm": 10.365830421447754,
      "learning_rate": 1.8475073313782992e-06,
      "loss": 0.0052,
      "step": 32000
    },
    {
      "epoch": 4.69941348973607,
      "grad_norm": 0.0008059352985583246,
      "learning_rate": 1.8035190615835777e-06,
      "loss": 0.0161,
      "step": 32050
    },
    {
      "epoch": 4.706744868035191,
      "grad_norm": 0.0025992991868406534,
      "learning_rate": 1.7595307917888564e-06,
      "loss": 0.0038,
      "step": 32100
    },
    {
      "epoch": 4.714076246334311,
      "grad_norm": 0.026533057913184166,
      "learning_rate": 1.715542521994135e-06,
      "loss": 0.0052,
      "step": 32150
    },
    {
      "epoch": 4.721407624633431,
      "grad_norm": 0.08669502288103104,
      "learning_rate": 1.6715542521994134e-06,
      "loss": 0.0017,
      "step": 32200
    },
    {
      "epoch": 4.728739002932551,
      "grad_norm": 0.0001708727068034932,
      "learning_rate": 1.6275659824046922e-06,
      "loss": 0.0116,
      "step": 32250
    },
    {
      "epoch": 4.736070381231672,
      "grad_norm": 21.09177017211914,
      "learning_rate": 1.5835777126099707e-06,
      "loss": 0.0043,
      "step": 32300
    },
    {
      "epoch": 4.743401759530792,
      "grad_norm": 0.0005403452669270337,
      "learning_rate": 1.5395894428152494e-06,
      "loss": 0.0101,
      "step": 32350
    },
    {
      "epoch": 4.750733137829912,
      "grad_norm": 2.438969135284424,
      "learning_rate": 1.4956011730205279e-06,
      "loss": 0.0139,
      "step": 32400
    },
    {
      "epoch": 4.758064516129032,
      "grad_norm": 12.020163536071777,
      "learning_rate": 1.4516129032258064e-06,
      "loss": 0.0071,
      "step": 32450
    },
    {
      "epoch": 4.765395894428153,
      "grad_norm": 0.00021244170784484595,
      "learning_rate": 1.4076246334310851e-06,
      "loss": 0.0041,
      "step": 32500
    },
    {
      "epoch": 4.7727272727272725,
      "grad_norm": 5.952419087407179e-05,
      "learning_rate": 1.3636363636363636e-06,
      "loss": 0.0015,
      "step": 32550
    },
    {
      "epoch": 4.780058651026393,
      "grad_norm": 0.0003293757908977568,
      "learning_rate": 1.3196480938416423e-06,
      "loss": 0.0001,
      "step": 32600
    },
    {
      "epoch": 4.787390029325513,
      "grad_norm": 5.310963153839111,
      "learning_rate": 1.2756598240469208e-06,
      "loss": 0.0111,
      "step": 32650
    },
    {
      "epoch": 4.794721407624634,
      "grad_norm": 0.004216974135488272,
      "learning_rate": 1.2316715542521993e-06,
      "loss": 0.004,
      "step": 32700
    },
    {
      "epoch": 4.802052785923753,
      "grad_norm": 0.00015754847845528275,
      "learning_rate": 1.187683284457478e-06,
      "loss": 0.0055,
      "step": 32750
    },
    {
      "epoch": 4.809384164222874,
      "grad_norm": 0.0002732596476562321,
      "learning_rate": 1.1436950146627566e-06,
      "loss": 0.0141,
      "step": 32800
    },
    {
      "epoch": 4.816715542521994,
      "grad_norm": 8.789004641585052e-05,
      "learning_rate": 1.0997067448680353e-06,
      "loss": 0.0226,
      "step": 32850
    },
    {
      "epoch": 4.8240469208211145,
      "grad_norm": 0.0018584581557661295,
      "learning_rate": 1.055718475073314e-06,
      "loss": 0.0168,
      "step": 32900
    },
    {
      "epoch": 4.831378299120234,
      "grad_norm": 0.0007808573427610099,
      "learning_rate": 1.0117302052785923e-06,
      "loss": 0.0138,
      "step": 32950
    },
    {
      "epoch": 4.838709677419355,
      "grad_norm": 0.00019607880676630884,
      "learning_rate": 9.67741935483871e-07,
      "loss": 0.0094,
      "step": 33000
    },
    {
      "epoch": 4.846041055718475,
      "grad_norm": 0.00011042544792871922,
      "learning_rate": 9.237536656891496e-07,
      "loss": 0.041,
      "step": 33050
    },
    {
      "epoch": 4.853372434017595,
      "grad_norm": 0.0005653101834468544,
      "learning_rate": 8.797653958944282e-07,
      "loss": 0.0139,
      "step": 33100
    },
    {
      "epoch": 4.860703812316715,
      "grad_norm": 0.00039907233440317214,
      "learning_rate": 8.357771260997067e-07,
      "loss": 0.0301,
      "step": 33150
    },
    {
      "epoch": 4.868035190615836,
      "grad_norm": 1.6004772186279297,
      "learning_rate": 7.917888563049853e-07,
      "loss": 0.0306,
      "step": 33200
    },
    {
      "epoch": 4.875366568914956,
      "grad_norm": 0.005884320940822363,
      "learning_rate": 7.478005865102639e-07,
      "loss": 0.0184,
      "step": 33250
    },
    {
      "epoch": 4.882697947214076,
      "grad_norm": 0.004074533935636282,
      "learning_rate": 7.038123167155426e-07,
      "loss": 0.0241,
      "step": 33300
    },
    {
      "epoch": 4.890029325513196,
      "grad_norm": 0.002917681820690632,
      "learning_rate": 6.598240469208212e-07,
      "loss": 0.0382,
      "step": 33350
    },
    {
      "epoch": 4.897360703812317,
      "grad_norm": 26.155393600463867,
      "learning_rate": 6.158357771260997e-07,
      "loss": 0.0347,
      "step": 33400
    },
    {
      "epoch": 4.904692082111437,
      "grad_norm": 91.45844268798828,
      "learning_rate": 5.718475073313783e-07,
      "loss": 0.0392,
      "step": 33450
    },
    {
      "epoch": 4.912023460410557,
      "grad_norm": 0.00017065413703676313,
      "learning_rate": 5.27859237536657e-07,
      "loss": 0.0127,
      "step": 33500
    },
    {
      "epoch": 4.919354838709677,
      "grad_norm": 0.0006549900863319635,
      "learning_rate": 4.838709677419355e-07,
      "loss": 0.014,
      "step": 33550
    },
    {
      "epoch": 4.926686217008798,
      "grad_norm": 0.002879203762859106,
      "learning_rate": 4.398826979472141e-07,
      "loss": 0.0079,
      "step": 33600
    },
    {
      "epoch": 4.9340175953079175,
      "grad_norm": 2.576244354248047,
      "learning_rate": 3.9589442815249267e-07,
      "loss": 0.0221,
      "step": 33650
    },
    {
      "epoch": 4.941348973607038,
      "grad_norm": 0.007566634099930525,
      "learning_rate": 3.519061583577713e-07,
      "loss": 0.0247,
      "step": 33700
    },
    {
      "epoch": 4.948680351906159,
      "grad_norm": 0.095868781208992,
      "learning_rate": 3.0791788856304983e-07,
      "loss": 0.025,
      "step": 33750
    },
    {
      "epoch": 4.956011730205279,
      "grad_norm": 1.029990315437317,
      "learning_rate": 2.639296187683285e-07,
      "loss": 0.0184,
      "step": 33800
    },
    {
      "epoch": 4.963343108504398,
      "grad_norm": 0.005224576685577631,
      "learning_rate": 2.1994134897360705e-07,
      "loss": 0.0327,
      "step": 33850
    },
    {
      "epoch": 4.970674486803519,
      "grad_norm": 0.0009917090646922588,
      "learning_rate": 1.7595307917888564e-07,
      "loss": 0.0006,
      "step": 33900
    },
    {
      "epoch": 4.97800586510264,
      "grad_norm": 0.0015098379226401448,
      "learning_rate": 1.3196480938416425e-07,
      "loss": 0.0186,
      "step": 33950
    },
    {
      "epoch": 4.9853372434017595,
      "grad_norm": 0.0002803550160024315,
      "learning_rate": 8.797653958944282e-08,
      "loss": 0.0196,
      "step": 34000
    }
  ],
  "logging_steps": 50,
  "max_steps": 34100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6006794207887360.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
